{
  "version": 1,
  "kind": "bank",
  "exportedAt": "2026-02-21T15:57:36.950Z",
  "subjects": [
    {
      "id": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "name": "Procesamiento del Lenguaje Natural",
      "color": "#8b5cf6",
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:24:12.667Z"
    },
    {
      "id": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "name": "Investigación y Gestión de Proyectos en Inteligencia Artificial",
      "color": "#ef4444",
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:17.340Z"
    },
    {
      "id": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "name": "Desarrollo, Optimización y Despliegue de Modelos Generativos",
      "color": "#f97316",
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T17:11:13.244Z"
    },
    {
      "id": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "name": "Visión Artificial",
      "color": "#3b82f6",
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:38.628Z"
    },
    {
      "id": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "name": "Razonamiento y Planificación Automática",
      "color": "#10b981",
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:59.130Z"
    },
    {
      "id": "befc803a-db6a-49f5-a451-941ee8738c59",
      "name": "Técnicas de Aprendizaje Automático",
      "color": "#f59e0b",
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:22:37.625Z"
    }
  ],
  "topics": [
    {
      "id": "067cd1e1-d35d-47ca-9713-f712013ed237",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 12- Implicaciones filosóficas éticas y legales en la aplicación de la inteligencia artificial",
      "order": 7,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "06bde5dd-1a90-4cec-83e5-0a03f0aa1379",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 6- Semántica léxica",
      "order": 8,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "title": "Tema 5. Automatización por eventos e integración con servicios",
      "order": 4,
      "id": "072afd6b-bd5a-417f-bd3c-30c5b25b56ec",
      "createdAt": "2026-02-20T17:12:01.168Z",
      "updatedAt": "2026-02-20T17:12:44.932Z",
      "pdfFilename": "Tema 5. Automatización por eventos e integración con servicios.pdf"
    },
    {
      "id": "07700f14-a587-41c2-9514-2a09bd2b125c",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 13- Extracción de características. Procesamientos multiescala y métodos avanzados",
      "order": 7,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:57.999Z",
      "pdfFilename": "Tema_13._Extracción_de_características._Procesamientos_multiescala_y_métodos_avanzados.pdf"
    },
    {
      "id": "0cad12a0-9e92-4602-af26-8b0138f36c88",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 3- Lógica y pensamiento humano",
      "order": 3,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:43.004Z",
      "pdfFilename": "Tema 3- Lógica y pensamiento humano.pdf"
    },
    {
      "id": "0cfd3b69-3e91-4485-a3b4-6731be7ca93c",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 12- Reparación reactiva multi agente",
      "order": 6,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:48.630Z",
      "pdfFilename": "Tema 12- Reparación reactiva multi agente.pdf"
    },
    {
      "id": "0dff3eb5-8e3d-43d5-84fc-30170a036ba6",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 5- Búsqueda informada",
      "order": 9,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:43.056Z",
      "pdfFilename": "Tema 5- Búsqueda informada.pdf"
    },
    {
      "id": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 8- Aprendizaje supervisado. Clasificación con Naïve Bayes",
      "order": 1,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:29.071Z",
      "pdfFilename": "Tema_8._ Aprendizaje_supervisado._Clasificación_con_Naïve_Bayes.pdf"
    },
    {
      "id": "1defa95d-1dfd-4747-959d-cf3fd4a2e3ac",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 15- Aplicaciones actuales del tratamiento de la señal",
      "order": 13,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:42:34.746Z",
      "pdfFilename": "Tema_15._Aplicaciones_actuales_del_tratamiento_de_la_señal.pdf"
    },
    {
      "id": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 2- Análisis de datos descriptivo y exploratorio",
      "order": 0,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:28.553Z",
      "pdfFilename": "Tema_2._Análisis_de_datos_descriptivo_y_exploratorio.pdf"
    },
    {
      "id": "22d7406c-bbaa-4cdc-9755-462e87069360",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 4- Fuentes y tipos de ruido",
      "order": 12,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:44.437Z",
      "pdfFilename": "Tema_4._Fuentes_y_tipos_de_ruido.pdf"
    },
    {
      "id": "241e24a8-9e71-4933-8c51-1fb4812b3606",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 8- Modelado neuronal del lenguaje",
      "order": 5,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "2968cd5d-b397-4859-923c-6dcfecc3f71d",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 11- Planificación por múltiples agentes",
      "order": 11,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:46.305Z",
      "pdfFilename": "Tema 11- Planificación por múltiples agentes.pdf"
    },
    {
      "id": "2fbbaa80-63ad-47d1-bdba-98f80e480839",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 7- Procesamiento de imagen. Operaciones espaciales",
      "order": 2,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:44.717Z",
      "pdfFilename": "Tema_7._Procesamiento_de_imagen._Operaciones_espaciales.pdf"
    },
    {
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "title": "Tema 4. Calidad operativa. Moderación, HITL y trazabilidad",
      "order": 3,
      "id": "33ab0c5f-8035-43a2-8314-55bdc07b4b6d",
      "createdAt": "2026-02-20T17:11:55.437Z",
      "updatedAt": "2026-02-20T17:12:41.761Z",
      "pdfFilename": "Tema 4. Calidad operativa. Moderación, HITL y trazabilidad.pdf"
    },
    {
      "id": "387e86b9-583d-4ec5-836f-24246c75b88b",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 8- Procesamiento de señales.Filtrado y análisis en frecuencia",
      "order": 9,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:44.985Z",
      "pdfFilename": "Tema_8._Procesamiento_de_señales._Filtrado_y_análisis_en_frecuencia.pdf"
    },
    {
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "title": "Tema 2. RAG en Flowise",
      "order": 1,
      "id": "388275e1-be5b-44fd-8fbd-52591fd74159",
      "createdAt": "2026-02-20T17:11:41.471Z",
      "updatedAt": "2026-02-20T17:14:56.833Z",
      "pdfFilename": "Tema 2. RAG en Flowise.pdf"
    },
    {
      "id": "38ec3285-bd93-4931-a6d4-32fc2c741d20",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 3- Etiquetado morfosintáctico (POS tagging)",
      "order": 1,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 3- Datos ausentes y normalización",
      "order": 4,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:28.569Z",
      "pdfFilename": "Tema_3._Datos_ausentes_y_normalización.pdf"
    },
    {
      "id": "3e455905-4b03-4822-be94-a82ef4467f8c",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 2- El texto como dato",
      "order": 0,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "450fb598-6a22-4be1-8621-ff78740c3973",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 6- Gestión de proyectos IA estructura de un proyecto IA y su despliegue",
      "order": 2,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 10- Aprendizaje supervisado. Regresión y clasificación con Random Forest",
      "order": 2,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:30.267Z",
      "pdfFilename": "Tema_10._Aprendizaje_supervisado._Regresión_y_clasificación_con_Random_Forest.pdf"
    },
    {
      "id": "46279c70-c904-41a7-a27a-afa6fd2ed026",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 4- Búsqueda no informada",
      "order": 8,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:43.024Z",
      "pdfFilename": "Tema 4- Búsqueda no informada.pdf"
    },
    {
      "id": "46b19090-981b-4a21-bc18-ab81be325271",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 4-  Análisis sintáctico",
      "order": 3,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "483cbb38-0e43-449b-be1b-b3d7a3ed74d1",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 7- Modelado estadístico del lenguaje",
      "order": 9,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "48e54f53-3eba-4c56-afe1-7268edc0a96b",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 1- Introducción a la toma de decisiones",
      "order": 2,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:42.982Z",
      "pdfFilename": "Tema 1- Introducción a la toma de decisiones.pdf"
    },
    {
      "id": "4961fc2e-0269-4627-b11a-8ef9a95b15d2",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 6- Procesamiento de imagen. Operaciones elementales",
      "order": 3,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:44.581Z",
      "pdfFilename": "Tema_6._Procesamiento_de_imagen._Operaciones_elementales.pdf"
    },
    {
      "id": "4a9f0b02-502c-4539-bb8d-223423ff0149",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 6- Búsqueda entre adversarios",
      "order": 0,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:43.118Z",
      "pdfFilename": "Tema 6- Búsqueda entre adversarios.pdf"
    },
    {
      "id": "502e9489-f902-45a4-8614-1f853b90f62f",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 5- Gestión de proyectos de inteligencia artificial. Enfoque metodológico",
      "order": 6,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "5b7c1734-f5fa-45fd-8985-5f5bed417f36",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 7-Gestión de proyectos IA. Recursos materiales y recursos humanos",
      "order": 10,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "title": "Tema 6. Interoperabilidad no-code con MCP",
      "order": 5,
      "id": "5f1e85f1-9f01-454f-9a3f-4c77425d32a6",
      "createdAt": "2026-02-20T17:12:08.613Z",
      "updatedAt": "2026-02-20T17:12:48.889Z",
      "pdfFilename": "Tema 6. Interoperabilidad no-code con MCP.pdf"
    },
    {
      "id": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 4- Regresión y evaluación de algoritmos de regresión",
      "order": 8,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:28.592Z",
      "pdfFilename": "Tema_4._Regresión_y_evaluación_de_algoritmos_de_regresión.pdf"
    },
    {
      "id": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 9- Combinacion de clasificadores. Bootstrapping Bagging y Boosting",
      "order": 6,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:29.487Z",
      "pdfFilename": "Tema_9._Combinacion_de_clasificadores._Bootstrapping_Bagging_y_Boosting.pdf"
    },
    {
      "id": "6805cc98-d6be-4d7d-a4a2-feb4c3af7d35",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 1- Introducción al procesamiento del lenguaje natural",
      "order": 6,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "6fece5ea-56be-4190-9eb8-0f9cce9122e3",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 5- Análisis semántico",
      "order": 7,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "7303369f-c8fc-447e-93e9-4ecfd3e7212a",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 11- Investigación en computación bioinspirada",
      "order": 5,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 6- Aprendizaje supervisado. Regresión y clasificación con árboles de decisión",
      "order": 5,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:28.705Z",
      "pdfFilename": "Tema_6._Aprendizaje_supervisado._Regresión_y_clasificación_con_árboles_de_decisión.pdf"
    },
    {
      "id": "87354853-f3e5-4c91-822f-d173f7f57c1e",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 10- Procesamiento de imagen. Crecimiento de regiones",
      "order": 5,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:46.507Z",
      "pdfFilename": "Tema_10._Procesamiento_de_imagen._Crecimiento_de_regiones.pdf"
    },
    {
      "id": "8cf93865-25e6-4ed1-8f95-9f73c139862f",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 9- Procesamiento e imagen. Morfología matemática",
      "order": 8,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:45.515Z",
      "pdfFilename": "Tema_9._Procesamiento_de_imagen._Morfología_matemática.pdf"
    },
    {
      "id": "8ef77057-143b-459b-8800-ab011ccd5b94",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 8- Sistemas basados en STRIP",
      "order": 7,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:43.476Z",
      "pdfFilename": "Tema 8- Sistemas basados en STRIP.pdf"
    },
    {
      "id": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 11- Parametrización automática y optimización de algoritmos",
      "order": 10,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:31.825Z",
      "pdfFilename": "Tema_11._Parametrización_automática_y_optimización_de_algoritmos.pdf"
    },
    {
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "title": "Tema 7. Sistemas multiagente",
      "order": 6,
      "id": "96d484d7-3f42-4d37-aa44-f73d4c6df900",
      "createdAt": "2026-02-20T17:12:15.255Z",
      "updatedAt": "2026-02-20T17:12:52.145Z",
      "pdfFilename": "Tema 7. Sistemas multiagente.pdf"
    },
    {
      "id": "971fb6e6-0b0d-4637-8d69-7db209dd146e",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 4- Publicación de resultados y redacción científica",
      "order": 0,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "9d6276cf-e9aa-48ad-a074-fe7ce913673d",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 9- Investigación en aprendizaje automático",
      "order": 9,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "a0c9fb48-c04d-495a-b7c5-4319a9a042c8",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 11- Extracción de características. Propiedades estadísticas y frecuenciales de la señal",
      "order": 10,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:48.578Z",
      "pdfFilename": "Tema_11._Extracción_de_características._Propiedades_estadísticas_y_frecuenciales_de_la_señal.pdf"
    },
    {
      "id": "a0ee552f-68ca-4b05-bf4f-9e4f2edc904c",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 8- Investigación en agentes inteligentes y sistemas expertos",
      "order": 1,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "a1245be8-e251-419a-bcdc-c822fd0e4750",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 2- Ciencia y método científico",
      "order": 3,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "a201f234-28ed-4d81-b20d-5a3e7edd54d9",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 10- Planificación multi agente",
      "order": 1,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:44.712Z",
      "pdfFilename": "Tema 10- Planificación multi agente.pdf"
    },
    {
      "id": "a6ccfde3-d77b-42db-af38-4df19e2f1b3d",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 1- Origen y evolución de la inteligencia artificial",
      "order": 8,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "title": "Tema 1. Fundamentos y evaluación de modelos de lenguaje",
      "order": 0,
      "id": "b225751e-e66f-4b40-9d10-c0b84fe478a3",
      "createdAt": "2026-02-20T17:11:32.644Z",
      "updatedAt": "2026-02-20T17:12:31.993Z",
      "pdfFilename": "Tema 1. Fundamentos y evaluación de modelos de lenguaje.pdf"
    },
    {
      "id": "b39cd408-d606-45ff-9e77-5dff8437aa2e",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 2- Elementos de un sistema de percepción",
      "order": 14,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:44.400Z",
      "pdfFilename": "Tema_2._Elementos_de_un_sistema_de_percepción.pdf"
    },
    {
      "id": "bae420cf-ae91-488c-a876-710db0be84d6",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 3- Financiación de proyectos",
      "order": 4,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "bbfe4558-ddbf-408a-8c5f-1f4880b45091",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 9- Aplicaciones del procesamiento del lenguaje natural",
      "order": 2,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "bd41142a-dbac-4d3d-a749-f1b9ca6338c4",
      "subjectId": "05db8dab-ae22-4e1e-8ab6-2b0fb70f0133",
      "title": "Tema 10- Agentes conversacionales",
      "order": 4,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "bea29b4a-68af-4309-8fa3-8b66b17a9aad",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 2- Representación del conocimiento y razonamiento",
      "order": 10,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:42.994Z",
      "pdfFilename": "Tema 2- Representación del conocimiento y razonamiento.pdf"
    },
    {
      "id": "cd44d928-a82f-42a0-9d13-c7676c9a8964",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 7- Problemas de planificación",
      "order": 4,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:43.264Z",
      "pdfFilename": "Tema 7- Problemas de planificación.pdf"
    },
    {
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "title": "Tema 3. Del chat al agente. Herramientas, memoria y enrutado",
      "order": 2,
      "id": "ce4369a8-42da-42d5-a4c2-dbbdce2a4eb0",
      "createdAt": "2026-02-20T17:11:48.516Z",
      "updatedAt": "2026-02-20T17:12:38.608Z",
      "pdfFilename": "Tema 3. Del chat al agente. Herramientas, memoria y enrutado.pdf"
    },
    {
      "id": "d0e67054-0c48-4548-a9af-aa76ae5c9d54",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 3- Captura y digitalización de señales",
      "order": 4,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:44.414Z",
      "pdfFilename": "Tema_3._Captura_y_digitalización_de_señales.pdf"
    },
    {
      "id": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 7- Máquinas de vectores de soporte",
      "order": 7,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:28.828Z",
      "pdfFilename": "Tema_7._Máquinas_de_vectores_de_soporte.pdf"
    },
    {
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "title": "Tema 8. Agentes multimodales y publicación como servicio",
      "order": 7,
      "id": "d8223347-6cc0-4cc9-ac63-7a81ecbe2782",
      "createdAt": "2026-02-20T17:12:21.801Z",
      "updatedAt": "2026-02-20T17:12:55.668Z",
      "pdfFilename": "Tema 8. Agentes multimodales y publicación como servicio.pdf"
    },
    {
      "id": "de36eadf-92af-4287-98c2-dd6751ca987f",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 12- Extracción de características. Caracterización de textura en imágenes",
      "order": 11,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:51.202Z",
      "pdfFilename": "Tema_12._Extracción_de_características._Caracterización_de_textura_en_imágenes.pdf"
    },
    {
      "id": "e50ab4a3-574f-4002-ac5f-e5912c4cf9d3",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "title": "Tema 10- Investigación en sistemas cognitivos",
      "order": 11,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "e757a383-1487-4cab-a2a0-8317613de882",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 5- Detección y cancelación de anomalías",
      "order": 0,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:44.484Z",
      "pdfFilename": "Tema_5._Detección_y_cancelación_de_anomalías.pdf"
    },
    {
      "id": "ea2d7b80-984e-436b-9e35-30cb471cb134",
      "subjectId": "8bfe1052-58e7-4f44-b5d2-483911af507d",
      "title": "Tema 9- Redes de tareas jerárquicas (HTN)",
      "order": 5,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T16:23:43.914Z",
      "pdfFilename": "Tema 9- Redes de tareas jerárquicas (HTN).pdf"
    },
    {
      "id": "ecf82f40-40b3-4430-adaa-5bbe58f1fd5d",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 14- Decisión. Principios e implementación de algoritmos de ayuda en la toma de decisiones",
      "order": 6,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:41:18.721Z",
      "pdfFilename": "Tema_14._Decisión._Principios_e_implementación_de_algoritmos_de_ayuda_en_la_toma_de_decisiones.pdf"
    },
    {
      "id": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 5- Evaluación de algoritmos de clasificación",
      "order": 9,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:28.637Z",
      "pdfFilename": "Tema_5._Evaluación_de_algoritmos_de_clasificación.pdf"
    },
    {
      "id": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "title": "Tema 1- Introducción al aprendizaje automático",
      "order": 3,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:05:28.546Z",
      "pdfFilename": "Tema_1._Introducción_al_aprendizaje_automático.pdf"
    },
    {
      "id": "ff88de98-c41d-4ecc-91cd-1f7f168bdb32",
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "title": "Tema 1- Introducción a los sistemas de percepción",
      "order": 1,
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T15:40:44.393Z",
      "pdfFilename": "Tema_1._Introducción_a_los_sistemas_de_percepción.pdf"
    }
  ],
  "questions": [
    {
      "id": "01b78e46-bdff-400a-9f0c-8744bbe53a59",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Una matriz de confusión es:",
      "explanation": "Cruza **clase real** vs **clase predicha** para contar $TP, FP, TN, FN$ y derivar métricas.",
      "difficulty": 1,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Una tabla que organiza las predicciones en función de los valores reales de los datos."
        },
        {
          "id": "b",
          "text": "Una tabla que tiene las predicciones de los diferentes clasificadores."
        },
        {
          "id": "c",
          "text": "Una tabla que contiene el valor real y el valor deseado."
        },
        {
          "id": "d",
          "text": "La matriz de confusión muestra la precisión absoluta de las predicciones."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:64a92d3551d3908d2410337dbd4e3ad6e62f6b1b0ea029e9bc7c75f9e2e60528",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "020490c2-a88e-466d-9c45-332b33c0eaf4",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones sobre los **vectores de soporte** en SVM es **falsa**?",
      "explanation": "Los vectores de soporte no se eligen al azar: aparecen como resultado de la optimización (son los puntos que caen sobre el margen o lo violan).",
      "difficulty": 2,
      "tags": [
        "svm",
        "vectores-de-soporte",
        "margen"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Los vectores de soporte en SVM son puntos de datos que se encuentran más cerca del límite de decisión (hiperplano) entre diferentes clases."
        },
        {
          "id": "b",
          "text": "La posición y la orientación del hiperplano en SVM están determinadas por los vectores de soporte."
        },
        {
          "id": "c",
          "text": "Los vectores de soporte son cruciales para definir el margen, que es la distancia entre el hiperplano y los puntos de datos más cercanos de cada clase."
        },
        {
          "id": "d",
          "text": "Los vectores de soporte en SVM se seleccionan aleatoriamente a partir de los datos de entrenamiento."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:7d1c7d5f6d1e4dc77ee0ef0a150e049918a720ad79a8fe4c972e3bc5de2dd0b0",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "03224454-0286-4fec-a549-fdfa23b7dbe6",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones describe incorrectamente el índice Gini en árboles de decisión?",
      "explanation": "✅ **D.** (incorrecta)\n\nEl **índice Gini** mide **impureza** y se usa para elegir splits minimizando esa impureza. La opción D mezcla conceptos: la **ganancia de información** se asocia típicamente a **entropía/information gain** (ID3/C4.5), no al Gini como tal.\n\n**A, B y C** describen correctamente el papel del Gini.",
      "difficulty": 3,
      "options": [
        {
          "id": "05252c66-2718-4cef-a227-464a1d04ece0",
          "text": "El índice Gini mide la impureza de un conjunto de datos, donde un valor más alto indica una mayor impureza y una mezcla más desigual de clases."
        },
        {
          "id": "05f13abd-da18-4db3-8dd5-c74aedc70871",
          "text": "El índice Gini se utiliza para seleccionar la mejor división en un nodo de un árbol de decisión, buscando minimizar la impureza en los nodos hijos."
        },
        {
          "id": "13a8ca1a-54da-486f-8669-1b8419e16658",
          "text": "El índice Gini asigna un valor de 0 cuando todos los ejemplos en un nodo pertenecen a la misma clase, lo que indica una pureza máxima."
        },
        {
          "id": "a1b589fd-527e-4021-a094-6a64d4fd6e0c",
          "text": "El índice Gini es una medida de la ganancia de información, utilizada para determinar qué característica proporciona la mayor separación entre las clases objetivo en un conjunto de datos."
        }
      ],
      "correctOptionIds": [
        "a1b589fd-527e-4021-a094-6a64d4fd6e0c"
      ],
      "createdBy": "",
      "sourcePackId": "contribution-2026-02-18-julio-modelosB-C-new-6f543832",
      "contentHash": "sha256:2b2d611bcc9e9d33cf517e5913968f61bbc477c14849aa0427bd4226637fb06c",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "052139ec-ae51-40e3-ac6c-60bc480c393c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "¿Cuál es un ejemplo de **valor atípico**?",
      "difficulty": 1,
      "options": [
        {
          "id": "a",
          "text": "Temperatura bajo 0º en invierno"
        },
        {
          "id": "b",
          "text": "Temperatura corporal de 38º"
        },
        {
          "id": "c",
          "text": "**Temperatura bajo 0º en verano**"
        },
        {
          "id": "d",
          "text": "Temperatura corporal de 36º"
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:b4933762a4292a022fdbcbdcf7b5349ff72173465c62f04ad88b68a0ac3bcf93",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "06e14409-28f4-4d33-8412-82bdba41ef4b",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "ce4369a8-42da-42d5-a4c2-dbbdce2a4eb0",
      "type": "TEST",
      "prompt": "¿Qué describe mejor el ciclo de trabajo tipo **ReAct** en un agente?",
      "explanation": "ReAct alterna razonamiento y uso de herramientas, incorporando observaciones para iterar hasta completar la tarea.",
      "difficulty": 2,
      "tags": [
        "react",
        "agentes",
        "tools",
        "bucle",
        "observacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Generar la respuesta de una vez sin consultar herramientas."
        },
        {
          "id": "b",
          "text": "Pensamiento → Acción (uso de herramienta) → Observación, repitiendo hasta resolver."
        },
        {
          "id": "c",
          "text": "Acciones en paralelo sin razonamiento intermedio."
        },
        {
          "id": "d",
          "text": "Primero observar, luego pensar, nunca actuar."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:5e9f11a7e4f7bb9b7f2b84b5c59507dfbd7eacda1b9d3c45e0a51d3c3e3b2a90",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "09844278-8a39-4589-92bf-6cf187ca6b65",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "PRACTICO",
      "prompt": "### Métricas de evaluación (árboles de decisión)\n\nDespués de entrenar un modelo se obtienen los siguientes datos de validación:\n\n- De las **110** instancias de la **clase positiva**, el modelo clasificó bien **100**.  \n- De las **60** instancias de la **clase negativa**, el modelo clasificó bien **55**.\n\nSe pide:\n\n1. Calcular **Accuracy**, **Precisión**, **Recall** y **F1-score** para **ambas clases**.  \n2. Indicar si el algoritmo responde de manera adecuada a la **detección de la clase negativa**. Justifica.  \n3. Analizar el valor de la **sensibilidad**: ¿qué significado tiene?\n\n> Origen: **Examen anterior** (UNIR, ordinaria **07–12/03/2025**, **Modelo D**).\n",
      "explanation": "A partir de **TP/TN/FP/FN** se calculan métricas globales (accuracy) y por clase. La **sensibilidad** es el *recall* de la clase positiva (TPR).",
      "difficulty": 2,
      "tags": [
        "examen-anterior",
        "unir",
        "taa",
        "2025-03",
        "modelo-d",
        "metricas",
        "confusion-matrix"
      ],
      "modelAnswer": "## 0) Matriz de confusión (tomando **positiva** como clase positiva)\n\n- **TP** = 100 (positivas bien clasificadas)  \n- **FN** = 110 − 100 = 10 (positivas mal, predichas como negativas)  \n- **TN** = 55 (negativas bien clasificadas)  \n- **FP** = 60 − 55 = 5 (negativas mal, predichas como positivas)\n\nTotal = 110 + 60 = **170**\n\n|               | Pred + | Pred − |\n|---|---:|---:|\n| Real + | TP = 100 | FN = 10 |\n| Real − | FP = 5 | TN = 55 |\n\n## 1) Métricas\n\n### Accuracy (global)\n`Accuracy = (TP + TN) / (TP + TN + FP + FN)`\n\n- Accuracy = (100 + 55) / 170 = 155/170 = **0,9118** (≈ **91,18%**)\n\n### Clase **positiva** (tratándola como “la positiva”)\n- **Precisión₊** = TP / (TP + FP) = 100 / (100 + 5) = 100/105 = **0,9524**\n- **Recall₊** (*sensibilidad*) = TP / (TP + FN) = 100 / (100 + 10) = 100/110 = **0,9091**\n- **F1₊** = 2·P·R / (P + R)  \n  = 2·0,9524·0,9091 / (0,9524 + 0,9091) = **0,9302**\n\n### Clase **negativa** (mismas métricas pero considerando “negativa” como la clase objetivo)\nEquivalencias:\n- TP₋ = TN = 55\n- FP₋ = FN = 10\n- FN₋ = FP = 5\n\n- **Precisión₋** = TP₋ / (TP₋ + FP₋) = 55 / (55 + 10) = 55/65 = **0,8462**\n- **Recall₋** = TP₋ / (TP₋ + FN₋) = 55 / (55 + 5) = 55/60 = **0,9167**\n- **F1₋** = 2·0,8462·0,9167 / (0,8462 + 0,9167) = **0,8809**\n\n> Resumen rápido:\n>\n> | Clase | Precisión | Recall | F1 |\n> |---|---:|---:|---:|\n> | Positiva | 0,9524 | 0,9091 | 0,9302 |\n> | Negativa | 0,8462 | 0,9167 | 0,8809 |\n\n## 2) ¿Detecta bien la **clase negativa**?\n\nBastante bien en **recall de la negativa**: 55/60 = **91,67%** de las negativas se detectan como negativas.\n\nEl punto “feo” es la **precisión de la negativa** (0,8462): de todo lo que el modelo marca como negativo, ~**15%** en realidad son **positivos** (FN=10). Si “fallar un positivo” es caro, esto importa.\n\nSi el objetivo explícito es “detectar negativos”, el modelo **sí responde bien** (pocos FP=5; alta especificidad/recall negativa).\n\n## 3) Sensibilidad: significado y valor aquí\n\nLa **sensibilidad** es lo mismo que **Recall de la clase positiva**:\n\n`sensibilidad = TP / (TP + FN)`\n\nAquí: 100/110 = **0,9091**.\n\nInterpretación directa:  \n> “De todos los casos **realmente positivos**, el modelo detecta correctamente ~**91%**.”\n\nEs decir, se “escapan” ~**9%** de positivos (los **FN = 10**).\n",
      "createdBy": "Luis",
      "sourcePackId": "04a1a1df-5192-4d2f-9e7e-12bf6daf1f16",
      "contentHash": "sha256:f42fb1003f4ea6d27bfe96af513ab7edbff2673b6c0f9c447d5958d8598059b9",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "0a40fb06-7b84-49ec-afd1-9face45966d7",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "En Random Forest, ¿cómo se realiza la toma de decisiones final para un problema de **clasificación**?",
      "explanation": "En **clasificación**, cada árbol predice una clase y el bosque decide por **voto mayoritario**.",
      "difficulty": 1,
      "tags": [
        "random-forest",
        "clasificacion",
        "voto-mayoritario"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Votación."
        },
        {
          "id": "b",
          "text": "Promedio."
        },
        {
          "id": "c",
          "text": "Suma ponderada."
        },
        {
          "id": "d",
          "text": "Máxima probabilidad."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:e53f6d8887d2758897d2e16c5f048657cb511c61c2d3dfce330482125a4f1d57",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "0a736ce5-bab6-4bc7-8227-a764e6e61842",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "En un árbol de decisión, ¿de qué es responsable el **nodo raíz**?",
      "explanation": "El nodo raíz realiza la **primera partición** del conjunto de datos usando la característica/split más informativo.",
      "difficulty": 1,
      "tags": [
        "arboles-de-decision",
        "nodo-raiz",
        "splits"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Hacer predicciones."
        },
        {
          "id": "b",
          "text": "Dividir los datos en subconjuntos según una característica."
        },
        {
          "id": "c",
          "text": "Poda del árbol."
        },
        {
          "id": "d",
          "text": "Almacenamiento de los valores objetivo reales."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:de50782a21a42279f784b44b9293a512f47539b30efb7acbb0da8c31a720f264",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "0cc27ffc-4d14-4fec-b3e8-e0b141ce49f7",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "DESARROLLO",
      "prompt": "### Reconocimiento y clasificación de pistachos (razonamiento teórico)\n\nEn la empresa de Alfredo quieren mejorar su eficiencia clasificando **pistachos**: saben que distintas **especies/tipos** se destinan a distintos mercados y quieren **separarlos automáticamente**.\n\n**Preguntas:**\n1. ¿Sería posible hacer un **reconocimiento de pistachos** para clasificar cada tipo?\n2. ¿Es un problema de **aprendizaje automático**? ¿Qué **tipo de problema** es?\n3. ¿Cómo se podría resolver con las **técnicas vistas en la asignatura**? Justifica.\n\n> Origen: **Examen anterior** (UNIR **TAA 2024**, **Modelo F**, código **10210068**).\n",
      "explanation": "El núcleo es: datos etiquetados + features (color/forma/textura) + un modelo de clasificación (SVM/RF) + evaluación con matriz de confusión. Es exactamente el patrón “supervisado” del Tema 1.",
      "difficulty": 3,
      "tags": [
        "examen anterior",
        "UNIR",
        "2024",
        "modelo-f",
        "visión",
        "clasificación",
        "pistachos"
      ],
      "modelAnswer": "Sí, es perfectamente viable **si** dispones de datos (normalmente imágenes o mediciones) etiquetados por tipo de pistacho.\n\n**1) ¿Es aprendizaje automático?**  \nSí: queremos aprender un modelo que, dado un pistacho (imagen/medidas), prediga su **clase** sin reglas manuales.\n\n**2) Tipo de problema**\n- Es un problema de **clasificación supervisada**:\n  - **Binaria** si solo hay “apto / no apto” o “tipo A / resto”.\n  - **Multiclase** si hay varios tipos/especies de pistacho.\n\n**3) Cómo resolverlo con técnicas de la asignatura**\n1. **Datos**:\n   - Recopilar ejemplos por clase (idealmente balanceados): fotos en condiciones controladas o con variabilidad realista.\n   - Etiquetas fiables (ground truth) por especie/tipo.\n2. **Extracción de características** (sin necesidad de deep learning):\n   - Color (histogramas), textura (descriptores), forma/tamaño, defectos visibles.\n3. **Modelos** (supervisados):\n   - **SVM** (Tema 7): suele ir muy bien en clasificación con features bien escaladas.\n   - **Árboles / Random Forest** (Temas 6 y 10): capturan no linealidades y son robustos.\n   - **Naïve Bayes** (Tema 8) como baseline rápido si las features encajan.\n4. **Preprocesado** (Tema 3):\n   - Normalización/estandarización si usas SVM.\n   - Tratamiento de faltantes si hay mediciones incompletas.\n5. **Evaluación** (Tema 5):\n   - Matriz de confusión por clase; precision/recall/F1 (macro si multiclase).\n   - Si el coste de errores es distinto (mandar pistacho “caro” al mercado barato vs al revés), ajustar objetivo o umbrales.\n6. **Puesta en producción**:\n   - Pipeline: captura → preprocesado → extracción de features → predicción → decisión.\n   - Monitorizar drift (cambios por cosecha, iluminación, cámara, etc.) y reentrenar.\n\n**Resumen:** Es **clasificación supervisada** con datos etiquetados + features + un clasificador (SVM/RF) y evaluación por métricas de clasificación.",
      "createdBy": "Luis",
      "sourcePackId": "eda08197-7337-49c1-9767-1933b50cca25",
      "contentHash": "sha256:a864b85398273565d493937f0b716f5247c722e239f24f0e099d76b86f65cefd",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "0d78f8ce-c5ae-4d56-aa0f-76cf2ec2c2c2",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones es verdadera sobre el clasificador ingenuo Naïve Bayes?",
      "explanation": "Naïve Bayes es un método de **clasificación supervisada**: aprende a partir de ejemplos etiquetados (variable *target*).",
      "difficulty": 1,
      "tags": [
        "naive-bayes",
        "supervisado",
        "clasificacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Es un algoritmo de aprendizaje supervisado."
        },
        {
          "id": "b",
          "text": "Es un algoritmo de aprendizaje no supervisado."
        },
        {
          "id": "c",
          "text": "Es un algoritmo de aprendizaje por refuerzo."
        },
        {
          "id": "d",
          "text": "No se utiliza para problemas de clasificación."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:4e8e1a4d6c35c2b1d25e05386c5f40b0cfe5b6b7df2a79f84b8b0a5c6f3db9a7",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "0d893fd4-1d69-4150-bbba-46db134e7953",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "Marca la afirmación **falsa** sobre los árboles de decisión:",
      "explanation": "Es falsa porque los árboles pueden **sobreajustar** si se dejan crecer sin restricciones (profundidad, min_samples, poda, etc.).",
      "difficulty": 2,
      "tags": [
        "arboles-de-decision",
        "overfitting",
        "generalizacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Los árboles de decisión son un método de aprendizaje supervisado que se basa en la estructura de un árbol para tomar decisiones a partir de datos, como en clasificación y regresión."
        },
        {
          "id": "b",
          "text": "La construcción de un árbol de decisión implica dividir el conjunto de datos en subconjuntos más pequeños, utilizando diferentes criterios, como la entropía o la ganancia de información."
        },
        {
          "id": "c",
          "text": "Los árboles de decisión son fáciles de interpretar y visualizar, lo que los hace útiles para comprender cómo se toman las decisiones en un modelo predictivo."
        },
        {
          "id": "d",
          "text": "Los árboles de decisión siempre producen modelos que son robustos frente al sobreajuste, lo que significa que nunca es necesario preocuparse por la generalización del modelo."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:f4f63544f9ab9b376a2aff35f1fed809c5a170bdff57ae85252cd624cb80da50",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "0daafc6e-f357-40e2-b471-69a2e677a07f",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "En el caso de los problemas de regresión:",
      "explanation": "En regresión la salida suele ser continua y se predice un valor numérico, no una categoría.",
      "difficulty": 1,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "La variable respuesta que se desea predecir es de tipo cualitativa."
        },
        {
          "id": "b",
          "text": "La variable respuesta que se desea predecir es de tipo cuantitativa."
        },
        {
          "id": "c",
          "text": "No siempre existe una variable respuesta."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:ab188b7a5df1d9f06f1f1d56a2f8ec92e7cb83c9a88b4c3a10f40fefc5c6c69a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "111dc714-8b81-42a7-8e3e-504538b7f2d8",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "Indica la afirmación **NO válida** sobre la **varianza**:",
      "explanation": "La varianza se calcula respecto a la **media**, no la mediana.",
      "difficulty": 2,
      "options": [
        {
          "id": "a",
          "text": "Indica homogeneidad o heterogeneidad"
        },
        {
          "id": "b",
          "text": "Es una medida de dispersión"
        },
        {
          "id": "c",
          "text": "**Es el promedio de desviaciones respecto a la mediana**"
        },
        {
          "id": "d",
          "text": "La suma de desviaciones es cero"
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:15277663c5ad34c1472508331fe6dedfc947afb6553fb2f6f372d008573c51bb",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "119b17fb-808e-4d11-89bf-e1dedd59ae9f",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Un científico de datos está desarrollando un modelo de clasificación utilizando Naïve Bayes para predecir si un correo electrónico es spam o no spam. Ha calculado la tabla de verosimilitud para dos palabras clave: \"oferta\" y \"urgente\". Los resultados se presentan a continuación:\n\n|  | oferta (Sí) | oferta (No) | urgente (Sí) | urgente (No) |\n|---|---|---|---|---|\n| spam | 4/20 | 16/20 | 10/20 | 10/20 |\n| No spam | 1/80 | 79/80 | 1/80 | 79/80 |\n\n\nBasándose en esta información y haciendo uso de la fórmula de la probabilidad a posteriori: P(A|B)=P(A)·P(B|A)/P(B). Responda la siguiente pregunta:\n¿Cuál es la probabilidad a posteriori de que un correo electrónico sea spam dado que contiene la palabra clave \"urgente\"?",
      "explanation": "✅ **D. 0.9**\n\nTomando los conteos como probabilidades:\n\n- Priors: `P(spam)=20/100=0.2`, `P(no_spam)=80/100=0.8`\n- Likelihoods: `P(urgente|spam)=10/20=0.5`, `P(urgente|no_spam)=1/80=0.0125`\n\nEntonces:\n\n`P(spam|urgente) = P(spam)·P(urgente|spam) / (P(spam)·P(urgente|spam) + P(no_spam)·P(urgente|no_spam))`\n\n`= 0.2·0.5 / (0.2·0.5 + 0.8·0.0125) = 0.1 / 0.11 ≈ 0.909` → **≈ 0.9**.",
      "difficulty": 4,
      "options": [
        {
          "id": "a36075ba-3b72-4305-823b-36bbe4a9d938",
          "text": "0.12"
        },
        {
          "id": "02a00543-cbec-4f76-a230-8a34ea0caf1c",
          "text": "3.63"
        },
        {
          "id": "98820223-7779-4e4b-b209-60eeeac6dac9",
          "text": "4.65"
        },
        {
          "id": "8a28c826-eb31-4704-b923-87109c3eb536",
          "text": "0.9"
        }
      ],
      "correctOptionIds": [
        "8a28c826-eb31-4704-b923-87109c3eb536"
      ],
      "createdBy": "",
      "sourcePackId": "contribution-2026-02-18-julio-modelosB-C-new-6f543832",
      "contentHash": "sha256:56e76684873f97b3262967cb743850c18da89e261534ee6369e1ac0065143f8b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "1446abb6-45a2-45ae-b4ed-a8b55d9882ca",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Un científico de datos está desarrollando un modelo de clasificación utilizando **Naïve Bayes** para predecir si un correo electrónico es **spam** o **no spam**. Ha calculado la tabla de verosimilitud para dos palabras clave: **\"oferta\"** y **\"urgente\"**. Los resultados se presentan a continuación:\n\n| Clase    | oferta (Sí) | oferta (No) | urgente (Sí) | urgente (No) |\n|----------|-------------|-------------|--------------|--------------|\n| spam     | 4/20        | 16/20       | 10/20        | 10/20        |\n| No spam  | 1/80        | 79/80       | 1/80         | 79/80        |\n\nBasándose en esta información y haciendo uso de la fórmula de la probabilidad a posteriori:\n\n`P(A|B) = P(A) · P(B|A) / P(B)`\n\n¿Cuál es la probabilidad a posteriori de que un correo electrónico sea **spam** dado que contiene **ambas** palabras clave **\"oferta\"** y **\"urgente\"**?\n",
      "explanation": "¿Qué sale realmente (bien hecho)?\n\nCon Naïve Bayes (asumiendo independencia):\n\n𝑃\n(\n𝑠\n𝑝\n𝑎\n𝑚\n)\n=\n20\n/\n100\n=\n0.2\nP(spam)=20/100=0.2, \n𝑃\n(\n𝑛\n𝑜\n)\n=\n0.8\nP(no)=0.8\n\n𝑃\n(\n𝑜\n𝑓\n𝑒\n𝑟\n𝑡\n𝑎\n∣\n𝑠\n𝑝\n𝑎\n𝑚\n)\n=\n4\n/\n20\n=\n0.2\nP(oferta∣spam)=4/20=0.2, \n𝑃\n(\n𝑢\n𝑟\n𝑔\n𝑒\n𝑛\n𝑡\n𝑒\n∣\n𝑠\n𝑝\n𝑎\n𝑚\n)\n=\n10\n/\n20\n=\n0.5\nP(urgente∣spam)=10/20=0.5 → \n𝑃\n(\n𝑎\n𝑚\n𝑏\n𝑎\n𝑠\n∣\n𝑠\n𝑝\n𝑎\n𝑚\n)\n=\n0.2\n⋅\n0.5\n=\n0.1\nP(ambas∣spam)=0.2⋅0.5=0.1\n\n𝑃\n(\n𝑜\n𝑓\n𝑒\n𝑟\n𝑡\n𝑎\n∣\n𝑛\n𝑜\n)\n=\n1\n/\n80\n=\n0.0125\nP(oferta∣no)=1/80=0.0125, \n𝑃\n(\n𝑢\n𝑟\n𝑔\n𝑒\n𝑛\n𝑡\n𝑒\n∣\n𝑛\n𝑜\n)\n=\n1\n/\n80\n=\n0.0125\nP(urgente∣no)=1/80=0.0125 → \n𝑃\n(\n𝑎\n𝑚\n𝑏\n𝑎\n𝑠\n∣\n𝑛\n𝑜\n)\n=\n0.0125\n⋅\n0.0125\n=\n0.00015625\nP(ambas∣no)=0.0125⋅0.0125=0.00015625\n\nEntonces:\n\nNumerador spam = \n0.2\n⋅\n0.1\n=\n0.02\n0.2⋅0.1=0.02\n\nNumerador no = \n0.8\n⋅\n0.00015625\n=\n0.000125\n0.8⋅0.00015625=0.000125\n\n𝑃\n(\n𝑠\n𝑝\n𝑎\n𝑚\n∣\n𝑎\n𝑚\n𝑏\n𝑎\n𝑠\n)\n=\n0.02\n/\n(\n0.02\n+\n0.000125\n)\n=\n0.9938\nP(spam∣ambas)=0.02/(0.02+0.000125)=0.9938\n\nResultado correcto ≈ 0.994, pero no está en las opciones (0.12, 3.63, 4.65, 0.48). \n\nExamen_TAA_2024_ModeloE\n\nSi HAY que elegir una opción sí o sí…\n\n✅ D. 0.48 (porque es la única “probabilidad” medianamente plausible y es la más cercana a 0.994 dentro de lo que hay). \n\nPor qué no las otras (si te estás jugando puntos)\n\nB (3.63) y C (4.65): imposibles como probabilidad (>1).\n\nA (0.12): demasiado baja; contradice los números de la tabla (con “ambas palabras” el spam debería dispararse, no caer a 0.12)",
      "difficulty": 4,
      "options": [
        {
          "id": "c24dc513-6fe1-4c3e-ae4c-f0d5e93cb02c",
          "text": "0.12"
        },
        {
          "id": "a4b6655e-3ab7-4bed-bc18-8da119babd16",
          "text": "3.63"
        },
        {
          "id": "2786387a-fefc-4834-a1b0-a58861277273",
          "text": "4.65"
        },
        {
          "id": "c6314303-81bc-40dd-a754-53c41cc11f05",
          "text": "0.48"
        }
      ],
      "correctOptionIds": [
        "c6314303-81bc-40dd-a754-53c41cc11f05"
      ],
      "createdBy": "",
      "contentHash": "sha256:61b98b737b8de45f8e6474f420a0cb3ebeff88646a8f32323a9abac04aeff703",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "159a98bf-addb-4d7e-93ae-ccdf2686bc8b",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Puede mejorar el $R^2$ (de entrenamiento) de un modelo de **regresión lineal múltiple** después de eliminar o agregar características?\n\nSeleccione una:",
      "explanation": "El $R^2$ mide la proporción de varianza explicada por el modelo. Cambiar el conjunto de variables (añadiendo relevantes o eliminando irrelevantes) puede afectar a cuánto explica el modelo y, por tanto, al $R^2$.",
      "difficulty": 2,
      "tags": [
        "r2",
        "seleccion-de-variables",
        "regresion-lineal-multiple"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Sí, el $R^2$ (de entrenamiento) de un modelo de regresión lineal múltiple puede mejorar después de eliminar o agregar características. Esto ocurre porque el valor de $R^2$ es una medida de qué tan bien las variables independientes del modelo explican la variabilidad de la variable dependiente."
        },
        {
          "id": "b",
          "text": "Sí, el $R^2$ (de entrenamiento) de un modelo de regresión lineal múltiple puede mejorar después de eliminar o agregar características. Esto ocurre porque el valor de $R^2$ es una medida sobre cuántas variables independientes explican la variabilidad de la variable dependiente."
        },
        {
          "id": "c",
          "text": "No, el $R^2$ (de entrenamiento) de un modelo de regresión lineal múltiple siempre puede empeorar después de eliminar o agregar características. Esto ocurre porque el valor de $R^2$ es una medida que está altamente correlacionada con el número de características empleadas en el entrenamiento."
        },
        {
          "id": "d",
          "text": "No, el $R^2$ (de entrenamiento) de un modelo de regresión lineal múltiple permanece estable para los diferentes conjuntos de características empleadas en el entrenamiento. Esto es debido a que $R^2$ es una medida que relaciona los datos con los resultados."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:7465de211d14b72a8e951f6652ca1e499d25ca63d0582393a1269f9a86242b2f",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "16361bc6-f451-4648-9b27-84f93bd87497",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Si decimos que la probabilidad de tener cáncer de mama es de 0.15 estamos hablando de:",
      "explanation": "✅ B. Probabilidad a priori.\n\nEs una probabilidad sin condicionar a ninguna evidencia (no hay datos observados como síntomas/prueba). La a posteriori y la condicionada dependen de una condición/evidencia.",
      "difficulty": 2,
      "options": [
        {
          "id": "52a51ff1-18ee-469c-8367-8a57521cef26",
          "text": "Probabilidad a posteriori."
        },
        {
          "id": "e0978ffb-00f6-4934-97a2-7d156a5d347a",
          "text": "Probabilidad a priori."
        },
        {
          "id": "b353f815-f1f9-41cd-bed2-35abb249d344",
          "text": "Probabilidad condicionada."
        },
        {
          "id": "56c66a62-8479-43b3-9097-1a8753d9e950",
          "text": "Probabilidad de cáncer dada una condición."
        }
      ],
      "correctOptionIds": [
        "e0978ffb-00f6-4934-97a2-7d156a5d347a"
      ],
      "createdBy": "",
      "sourcePackId": "83ed9a7f-3b02-4cb4-8f99-707db11fdbe8",
      "contentHash": "sha256:4410bc9887c891a4f638d71dfa93d297722f4dbf2750581d397d9b41af158216",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "16e7be4a-a4cc-4e18-9287-0e94077d6016",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "Son características generales del método **Stacking**:",
      "explanation": "Stacking suele combinar **modelos base heterogéneos** y usa un **meta-modelo** (nivel 2) para aprender la mejor combinación (interpretada aquí como “promedio ponderado”).",
      "difficulty": 2,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Reduce bias o sesgo, su aprendizaje base es homogéneo, su entrenamiento base es secuencial, y su método de agregación es peso promedio."
        },
        {
          "id": "b",
          "text": "Mejora exactitud, su aprendizaje base es heterogéneo, su entrenamiento base es secuencial, y su método de agregación es peso promedio."
        },
        {
          "id": "c",
          "text": "Reduce varianza, es homogéneo, el entrenamiento es en paralelo, y la predicción está dada por el voto mayoritario o promedio."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:4f8e7e5ce8b2a4c2c7b0b3d3b9b381ccba31a71d0cf1b0a59ed3a4d5c0ed4f47",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "17c97841-08a0-4c75-b36b-6a465bd34d70",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "Una empresa ha recopilado los comentarios de los clientes sobre sus productos,\ncalificándolos como seguros o inseguros, utilizando árboles de decisión. El conjunto de datos\nde entrenamiento tiene las siguientes características: identificación, fecha, revisión completa,\nresumen de revisión completo y una etiqueta binaria segura/no segura. Durante el\nentrenamiento, se eliminó cualquier muestra de datos con características faltantes. En algunos\ncasos, se descubrió que al conjunto de prueba le faltaba el campo de texto de revisión\ncompleto.\nPara este caso de uso, ¿cuál es la manera más efectiva para abordar las instancias de datos\ncon características faltantes?",
      "explanation": "Sí. En test falta una feature (“review completa”) y el pipeline necesita un valor para poder evaluar/predicir de forma consistente. La opción B es una imputación usando una variable muy correlacionada (el resumen), que es una solución razonable en este contexto.\n\nPor qué las otras no:\n\nA (mala): descartar muestras de test es perder datos y sesgar evaluación/producción; es la salida “perezosa” salvo que no haya alternativa.\n\nC (mala): cambiar a “otro algoritmo” no arregla el hecho de que tu modelo/pipeline ya espera esa feature; además el tema te plantea tratar ausentes con eliminación o imputación, no “cambio de algoritmo”. \n\nD (mala): “generar datos sintéticos” para texto es inventarte reseñas: introduce ruido/sesgo y puede empeorar más que una imputación simple.",
      "difficulty": 3,
      "options": [
        {
          "id": "408900c3-26ef-4594-be33-ab3a10dd7d6a",
          "text": "Descartar las muestras de test a las que les faltan campos de texto de revisión completos."
        },
        {
          "id": "b6f5c0e3-1d19-4d70-8847-eb6b78a3b47c",
          "text": "Copiar los campos de texto de resumen y utilizarlos para completar los campos de texto de revisión completos que faltan. "
        },
        {
          "id": "ecbc85c3-7802-413a-9d30-14e0a8bd1306",
          "text": "Usar un algoritmo que maneje los datos faltantes mejor que los árboles de decisión."
        },
        {
          "id": "58fc5d10-3c61-4ac0-afdc-80db55c1c30a",
          "text": "Generar datos sintéticos para completar los campos a los que les faltan datos."
        }
      ],
      "correctOptionIds": [
        "b6f5c0e3-1d19-4d70-8847-eb6b78a3b47c"
      ],
      "createdBy": "",
      "contentHash": "sha256:888a1858caba332332f4a7a5a6291cdfcd6b8cfb937215a8cd6763fd608ce138",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "17d341e9-8c4e-4fa7-864f-8f143a141eea",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "El algoritmo **Extra Trees** destaca por:",
      "explanation": "Extra Trees introduce **mayor aleatoriedad** en la construcción: las **divisiones** se eligen de forma más aleatoria que en Random Forest.",
      "difficulty": 2,
      "tags": [
        "extra-trees",
        "ensamble",
        "aleatoriedad"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Utilizar árboles de decisión poco profundos."
        },
        {
          "id": "b",
          "text": "Seleccionar características de manera más aleatoria durante la construcción de árboles."
        },
        {
          "id": "c",
          "text": "Utilizar técnicas avanzadas de regularización."
        },
        {
          "id": "d",
          "text": "Requiere un mayor número de árboles para converger."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:71ee3ab64147461b15c6f2d09e33b31aedb974031404694a86297081b005ca4c",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "18be8cda-b105-4a98-9aee-40835d8b8c09",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "El criterio de parada de la construcción de un árbol de decisión viene dado por:",
      "explanation": "Son criterios típicos de parada: nodo (casi) puro, falta de splits útiles, o límites como profundidad/tamaño mínimos y máximos.",
      "difficulty": 2,
      "tags": [
        "arboles-de-decision",
        "parada",
        "poda"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Todos, o casi todos, los ejemplos del nodo son de la misma clase."
        },
        {
          "id": "b",
          "text": "No existen variables para distinguir entre los ejemplos."
        },
        {
          "id": "c",
          "text": "El árbol ha alcanzado un tamaño predefinido."
        },
        {
          "id": "d",
          "text": "Todas las anteriores son correctas."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:6710ea4528b5927f4e49fdcdd3343c952346789e0345e164dfaa5a069004d571",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "1965fead-e9a9-47b8-9a90-567ae721036a",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "¿Cuál es la principal característica del método de hold-out en el contexto de validación de modelos en machine learning?",
      "explanation": "✅ B. Consiste en separar los datos disponibles en dos conjuntos: uno para entrenamiento y otro para test.\n\nHold-out = una partición simple train/test (a veces con validación aparte).",
      "difficulty": 1,
      "options": [
        {
          "id": "06c66ba6-f822-453e-a80a-ab92a12b0a19",
          "text": "Consiste en dividir los datos en k particiones para realizar múltiples iteraciones de entrenamiento y evaluación."
        },
        {
          "id": "97ac6f01-264d-4f9b-85d0-b0ab788567ce",
          "text": "Consiste en separar los datos disponibles en dos conjuntos: uno para entrenamiento y otro para test."
        },
        {
          "id": "347dad5c-a4e0-4d2b-a32b-a9f3f4c322b6",
          "text": "Se utiliza para realizar ajustes continuos de los hiperparámetros del modelo durante la fase de entrenamiento."
        },
        {
          "id": "841c37d4-3a90-44a1-a7c0-fa26aa2111c6",
          "text": "Es exclusivamente aplicable a problemas de clasificación y no a problemas de regresión."
        }
      ],
      "correctOptionIds": [
        "97ac6f01-264d-4f9b-85d0-b0ab788567ce"
      ],
      "createdBy": "",
      "sourcePackId": "9a48d918-0ffe-4d28-9f78-0c2350dcfe9c",
      "contentHash": "sha256:3dfa8de8c69f39b466e9b02ef44f12e4259d90d474f9414db9281031821d5d15",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "1af8751d-683f-458c-b4b6-d4765b1d5b10",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "La métrica F1:",
      "explanation": "F1 es la media armónica: $$F1 = 2\\,\\frac{\\text{Precision}\\cdot\\text{Recall}}{\\text{Precision}+\\text{Recall}}$$",
      "difficulty": 2,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Se trata de una forma de calcular el AUC."
        },
        {
          "id": "b",
          "text": "Combina precisión y recall."
        },
        {
          "id": "c",
          "text": "Combina sensibilidad y especificidad."
        },
        {
          "id": "d",
          "text": "Es una medida que se calcula como la suma de la precisión y el recall."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:9d4b4b89decc4dfc3a9f4a0e12f2b6d3e5128a3d6a0c7bd6b4cc1a5f0d12fe49",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "1bb162a1-75d0-4c5b-8430-4b98c4bcf80b",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "En el siguiente conjunto de datos:\n\n```python\ndata = {\n  'Id': [1, 2, 3, 4, 5, 6, 7, 7],\n  'Primer_nombre': ['Angela', 'Adrian', 'Theodoro', 'Angela', 'Adrian', 'Beatriz', 'Olivia', 'Olivia'],\n  'Primer_apellido': ['Castro', 'Guzman', 'Rivadeniera', 'Castillo', 'Casas', 'Perez', 'Apraez', 'Apraez'],\n  'Edad': [27, 31, 36, 27, 53, 48, 36, 36],\n  'Estatura': [1.67, 1.80, 1.61, 1.67, 1.88, 1.69, 1.62, 1.62]\n}\n```\n\n¿Cuántos registros duplicados existen?",
      "explanation": "Se consideran **2** registros duplicados: (1) el duplicado exacto de *Olivia Apraez* (fila repetida) y (2) un caso de duplicidad por alta coincidencia de atributos entre los registros de *Angela* (mismo nombre, edad y estatura).",
      "difficulty": 3,
      "tags": [
        "duplicados",
        "pandas"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "0."
        },
        {
          "id": "b",
          "text": "1."
        },
        {
          "id": "c",
          "text": "2."
        },
        {
          "id": "d",
          "text": "3."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:fb6aeb8a8b839646c5df7db9f4e4a4b4e26a4f56c7d1d2f78e70a1a51f2a6b78",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "1ddd2cd3-3a30-4ca4-8ad3-51441c365d4d",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Usted ha desarrollado un modelo para una tarea de clasificación donde la clase minoritaria aparece en el 10% del conjunto de datos. Ejecutó el entrenamiento en el conjunto de datos desequilibrado original y verificó el rendimiento del modelo resultante. La matriz de confusión indica que el modelo no aprendió la clase minoritaria. Usted desea mejorar el rendimiento del modelo mientras minimiza el tiempo de ejecución y mantiene las predicciones calibradas. ¿Qué debería hacer?",
      "explanation": "✅ **D.** Reducir la muestra de la clase mayoritaria y **ajustar pesos** por el factor de muestreo.\n\nSi el modelo ignora la minoritaria, necesitas “forzarle” a verla. **Downsampling** de la mayoritaria:\n- **reduce tiempo de entrenamiento** (menos datos),\n- mejora la atención a la minoritaria,\n- y el **reajuste de pesos** corrige el cambio de prior, ayudando a mantener la **calibración**.\n\n**Por qué no las otras:**\n- **A**: class weights puede ayudar, pero no garantiza calibración y no reduce tiempo.\n- **B**: calibrar/ajustar umbral puede arreglar probabilidades, pero si “no aprendió” la clase minoritaria, no lo arreglas solo moviendo el umbral.\n- **C**: upsampling suele **aumentar** tiempo (más datos) y aunque re-pese, no es la opción más rápida.",
      "difficulty": 5,
      "options": [
        {
          "id": "336ae564-f915-4318-bb2c-d5b743009aa1",
          "text": "Actualizar los pesos de la función de clasificación para penalizar clasificaciones erróneas de la clase minoritaria."
        },
        {
          "id": "6ed95309-c770-450e-854c-26469f696393",
          "text": "Ajuste el umbral de clasificación y calibre el modelo con una regresión en el conjunto de validación, de modo que la línea ajustada no sea decreciente en todas partes y se encuentre lo más cerca posible de las observaciones."
        },
        {
          "id": "f80443d3-a75b-4142-ab71-91eb8505ac62",
          "text": "Realice un muestreo ascendente de la clase minoritaria en el conjunto de entrenamiento y actualice el peso de la clase muestreada ascendentemente con el mismo factor de muestreo."
        },
        {
          "id": "c0389cde-7cd9-4d9d-9679-53b24fd8a7b3",
          "text": "Reduzca la muestra de la clase mayoritaria en el conjunto de entrenamiento y actualice el peso de la clase reducida por el mismo factor de muestreo"
        }
      ],
      "correctOptionIds": [
        "c0389cde-7cd9-4d9d-9679-53b24fd8a7b3"
      ],
      "createdBy": "",
      "sourcePackId": "contribution-2026-02-18-julio-modelosB-C-new-6f543832",
      "contentHash": "sha256:01c498780ebbe9930666101488005a9c74eac1c0afb6957f4daa7a0e76680114",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "1e536565-45be-4215-9723-64d9d4069501",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "DESARROLLO",
      "prompt": "### Las fábricas textiles (análisis completo)\n\nEn el **Anexo** final encontrarás la descripción del problema (**Las fábricas textiles**) y el conjunto de datos asociado. Debes realizar un **análisis completo**, usando los conocimientos de la asignatura.\n\n**Condiciones:**\n- Responde **sin escribir código**.\n- Cualquier aclaración o suposición que hagas debe quedar **escrita**.\n\n> Origen: **Examen anterior** (UNIR **TAA 2024**, **Modelo F**, código **10210068**).\n",
      "explanation": "Aunque no veas el anexo, el examen espera el guion completo: **definir y**, EDA, limpieza, modelos adecuados según tipo, métricas alineadas con coste y validación sin trampas.",
      "difficulty": 4,
      "tags": [
        "examen anterior",
        "UNIR",
        "2024",
        "modelo-f",
        "EDA",
        "preprocesado",
        "modelado",
        "textil"
      ],
      "modelAnswer": "*(Sin el anexo, planteo el análisis “completo” de forma general, pero dejando claro qué decidiría al ver la variable objetivo.)*\n\n## 1) Definir el objetivo (lo decide la variable y)\n- Si y es **numérica** (producción, coste, consumo, tiempo, defectos por lote…): **regresión** (Tema 4).\n- Si y es **categórica** (defectuoso/no defectuoso, tipo de tejido, nivel de calidad, riesgo alto/medio/bajo…): **clasificación** (Tema 5).\n\n## 2) EDA (Tema 2)\n- Tamaño del dataset, tipos de variables (numéricas/categóricas), cardinalidades.\n- Distribuciones, outliers, correlaciones/relaciones.\n- Si hay variables temporales (turno, fecha, línea), analizar estacionalidad y drift.\n- Si es clasificación: balanceo de clases y coste de errores (FP vs FN).\n\n## 3) Preparación de datos (Tema 3)\n- **Faltantes**: imputación (mediana/moda), o por grupos (p. ej. por fábrica/línea/turno).\n- Codificación de categóricas (one-hot).\n- Normalización/estandarización si usas modelos sensibles a escala (SVM).\n- Tratamiento de outliers (capado/winsor, o justificación de mantenerlos si son fallos reales).\n- Feature engineering:\n  - Ratios (producción por hora), interacción turno×máquina, agregados por lote.\n  - Si hay tiempo: lags/medias móviles.\n\n## 4) Modelos candidatos (Temas 6–10)\n- **Baseline**:  \n  - Regresión: media/mediana.  \n  - Clasificación: clase mayoritaria.\n- **Árbol de decisión**: interpretable (reglas claras de “por qué sale defectuoso”).\n- **Random Forest**: generaliza bien y es robusto a no linealidad.\n- **SVM**: si el problema es separable con buen escalado y no es enorme.\n- **Naïve Bayes**: baseline si las features tienen sentido probabilístico simple.\n\n## 5) Evaluación\n- Partición train/valid/test o CV (estratificada si clasificación).\n- Métricas:\n  - Regresión: MAE/RMSE + análisis de residuos (qué rango de error es aceptable).\n  - Clasificación: precision/recall/F1 + matriz de confusión; si hay desbalance, preferir F1/PR‑AUC.\n- Elegir métrica alineada con negocio:  \n  - Si “defectuoso” es crítico → priorizar **recall** de defectuoso (evitar FN).  \n  - Si parar línea por falsa alarma es caro → priorizar **precision**.\n\n## 6) Resultado y recomendación\n- Seleccionar el modelo que mejor cumpla la métrica clave en validación y confirme en test.\n- Explicar variables influyentes (importancia en RF / reglas del árbol) para que el gerente pueda actuar (mantenimiento, cambios de proceso).\n- Plan de monitorización y reentrenamiento (cambios en maquinaria, materia prima, turnos…).",
      "createdBy": "Luis",
      "sourcePackId": "eda08197-7337-49c1-9767-1933b50cca25",
      "contentHash": "sha256:f622c54c37d6ed0113bca227158705cf08e5042826931af14c2451c56274e999",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "20717dec-f11c-480c-abeb-a15b1cb2dd76",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "33ab0c5f-8035-43a2-8314-55bdc07b4b6d",
      "type": "TEST",
      "prompt": "¿Qué configuración en la fase de **generación** ayuda a reducir alucinaciones y a hacer la salida verificable?",
      "explanation": "Abstención sin evidencia + baja aleatoriedad + salida estructurada con citas obligatorias hacen la respuesta auditable y reducen invención.",
      "difficulty": 3,
      "tags": [
        "generacion",
        "alucinaciones",
        "abstencion",
        "citas",
        "contrato-salida"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Formato libre y temperatura alta."
        },
        {
          "id": "b",
          "text": "Pedir creatividad e ignorar el contexto si es insuficiente."
        },
        {
          "id": "c",
          "text": "Instrucción de abstención, temperatura baja y contrato de salida con citas obligatorias y límite de longitud."
        },
        {
          "id": "d",
          "text": "Permitir respuestas sin fuentes si «suena» convincente."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:4d3e2f1a0b9c8d7e6f5a4b3c2d1e0f9a8b7c6d5e4f3a2b1c0d9e8f7a6b5c4d3",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "207a546c-3d77-4a15-8e49-188434bcf243",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "971fb6e6-0b0d-4637-8d69-7db209dd146e",
      "type": "DESARROLLO",
      "prompt": "En un trabajo científico, explica cuál es la diferencia entre el estado del arte y el marco teórico, y explica qué tipo de referencias bibliográficas usarías en cada uno de los casos.",
      "difficulty": 2,
      "tags": [
        "redaccion-cientifica",
        "metodologia"
      ],
      "modelAnswer": "## Estado del Arte vs Marco Teórico\n\n### Estado del Arte\nRevisión exhaustiva de trabajos de investigación previos relacionados con el problema. Identifica qué se ha investigado, tendencias, resultados y brechas (gaps) de conocimiento.\n\n**Referencias**: Artículos originales en revistas indexadas (Scopus, IEEE, ACM), actas de congresos, revisiones sistemáticas. Se priorizan publicaciones recientes (últimos 5 años) y de alto impacto.\n\n### Marco Teórico\nBase conceptual que sustenta la investigación. Define conceptos clave, teorías, modelos y enfoques teóricos para analizar el problema y formular hipótesis.\n\n**Referencias**: Libros de texto, artículos teóricos fundacionales, estándares y surveys. Fuentes consolidadas; no necesariamente recientes.\n\n### Diferencias clave\n\n| | Estado del Arte | Marco Teórico |\n|---|---|---|\n| Objetivo | Qué se ha investigado | Conceptos y teorías base |\n| Temporalidad | Reciente | Puede incluir clásicos |\n| Tipo de fuente | Artículos, congresos | Libros, surveys |",
      "keywords": [
        "estado del arte",
        "marco teórico",
        "referencias bibliográficas",
        "survey",
        "gap"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:830e9b3b2d76b22b120976fbbeb2c8270236af560e6cd8c104298fd025ab1b6d",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "2232df30-4629-4d3a-8348-b50a574bacc0",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "450fb598-6a22-4be1-8621-ff78740c3973",
      "type": "DESARROLLO",
      "prompt": "Explica los pasos necesarios para integrar un modelo de inteligencia artificial en un sistema empresarial existente.",
      "difficulty": 2,
      "tags": [
        "despliegue",
        "gestion-proyectos"
      ],
      "modelAnswer": "## Integración de un Modelo de IA en un Sistema Empresarial\n\n### 1. Definición de la interfaz de integración\nDeterminar cómo comunicará el sistema con el modelo: **API REST/gRPC**, batch o librería. Definir el formato de datos (JSON, CSV, Avro).\n\n### 2. Empaquetado y serialización del modelo\nGuardar el modelo en formato portable: `.pkl` (scikit-learn), `SavedModel` (TensorFlow), `ONNX` (interoperabilidad entre frameworks).\n\n### 3. Contenerización del entorno\nUsar **Docker** para encapsular el modelo con sus dependencias. Opcionalmente **Kubernetes** para orquestación y escalado.\n\n### 4. Despliegue en infraestructura\n- **Cloud**: AWS SageMaker, Azure ML, Google Vertex AI.\n- **On-premise**: Servidores propios.\n- **Edge**: Inferencia local en tiempo real.\n\n### 5. Exposición como servicio (endpoint)\nPunto de acceso que recibe datos de entrada, invoca la inferencia y devuelve la predicción. Incluir autenticación y control de acceso.\n\n### 6. Pruebas de integración\nPruebas funcionales, de carga y de latencia (SLA de tiempo de respuesta).\n\n### 7. Monitorización continua\nDetectar *data drift*, degradación del rendimiento y errores de inferencia. Alertas y plan de reentrenamiento periódico.\n\n### 8. Documentación y gobernanza\nDocumentar la API, formato de datos, versiones del modelo y responsables del mantenimiento (MLOps).",
      "keywords": [
        "integración",
        "API REST",
        "Docker",
        "Kubernetes",
        "endpoint",
        "monitorización",
        "data drift",
        "ONNX",
        "MLOps"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:ccc5b00da5bbc3a260893f9dab5c44f3b6f78d7954cf11439b15ed9d78e194f5",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "22be231e-5e01-412c-8ad0-ed512e6d205a",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Un modelo con gran valor de recall:",
      "explanation": "Recall (sensibilidad/TPR): $$\\text{Recall} = \\frac{TP}{TP+FN}$$. Alto recall ⇒ pocos **falsos negativos**.",
      "difficulty": 2,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Captura un gran porcentaje de ejemplos negativos."
        },
        {
          "id": "b",
          "text": "Captura un gran porcentaje de ejemplos positivos."
        },
        {
          "id": "c",
          "text": "Indica que el modelo no captura bien los ejemplos negativos."
        },
        {
          "id": "d",
          "text": "Indica que el modelo no es capaz de detectar los ejemplos positivos."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:3a845c8628f1c76d9cc3f175b1bc56c8bfc19f41f0f17b0947dc37a6f5441748",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "234631a1-cbcd-4b25-9ec0-db0f66216168",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "El área bajo la curva (AUC):",
      "explanation": "El AUC (de la ROC) suele expresarse en $[0,1]$; cuanto más cerca de 1, mejor separa clases.",
      "difficulty": 2,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Es un valor comprendido entre 0 y 1."
        },
        {
          "id": "b",
          "text": "Es un valor comprendido entre 0 y 100."
        },
        {
          "id": "c",
          "text": "Es un porcentaje entre 0 y 100%."
        },
        {
          "id": "d",
          "text": "Es un valor que indica la precisión absoluta del modelo."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:7b7c0f5a71e7e5b55fe7e5c7fd2109b51b12a4fb0d3370a24d34bdc8b35f3a1e",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "23b52f93-2f60-490b-abfe-6bcc650868a0",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Qué representa el intercepto en un modelo de regresión lineal?",
      "explanation": "✅ A. El valor esperado de la variable de respuesta cuando todas las variables predictoras son cero.\n\nEl intercepto es el término independiente: la predicción cuando X=0.",
      "difficulty": 2,
      "options": [
        {
          "id": "544ce67d-9cb0-4bf9-b216-ae8303dd3235",
          "text": "El valor esperado de la variable de respuesta cuando todas las variables predictoras son cero."
        },
        {
          "id": "cc8f2569-8824-4772-8943-ac665749e3fd",
          "text": "La pendiente de la línea de regresión."
        },
        {
          "id": "a8f4b3e2-87d3-4ec0-9614-f6a05d0c3237",
          "text": "La suma de los cuadrados de los residuos."
        },
        {
          "id": "4c8d7d05-f47e-43ba-af02-27b5cfa593b8",
          "text": "La varianza explicada por el modelo."
        }
      ],
      "correctOptionIds": [
        "544ce67d-9cb0-4bf9-b216-ae8303dd3235"
      ],
      "createdBy": "",
      "sourcePackId": "9a48d918-0ffe-4d28-9f78-0c2350dcfe9c",
      "contentHash": "sha256:0b66a63e1bff791954f3dba6975de8aec65403a9e148855e0001b0a9c52a3b0c",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "24c1d2f3-5f4e-4ede-9b11-2b8a2499a2e0",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "b225751e-e66f-4b40-9d10-c0b84fe478a3",
      "type": "TEST",
      "prompt": "Para **QA factual con fuentes**, ¿qué combinación de evaluación da una señal más completa?",
      "explanation": "EM mide exactitud estricta, F1 captura coincidencias parciales y la verificación de citas comprueba que la respuesta está anclada en evidencias.",
      "difficulty": 3,
      "tags": [
        "evaluacion",
        "qa",
        "em",
        "f1",
        "citas",
        "grounding"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Solo Exact Match (EM)."
        },
        {
          "id": "b",
          "text": "Solo BLEU/ROUGE."
        },
        {
          "id": "c",
          "text": "EM + F1 a nivel de tokens + verificación de citas/soporte."
        },
        {
          "id": "d",
          "text": "Una encuesta de satisfacción de usuarios."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:0c020bafc0a6846f4d1a5a9c6dcb5a4e0f5e3a52d6d83a2aa1512fda9d6e87f3",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "259175f3-8658-4f81-96b5-f1b084a11506",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "Son características generales del método **Boosting**:",
      "explanation": "Boosting suele reducir **sesgo**, entrena **secuencialmente** y combina modelos con un esquema **ponderado**.",
      "difficulty": 2,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Reduce bias o sesgo, su aprendizaje base es homogéneo, su entrenamiento base es secuencial, y su método de agregación es peso promedio."
        },
        {
          "id": "b",
          "text": "Mejora exactitud, su aprendizaje base es heterogéneo, su entrenamiento base es secuencial, y su método de agregación es peso promedio."
        },
        {
          "id": "c",
          "text": "Reduce varianza, es homogéneo, el entrenamiento es en paralelo, y la predicción está dada por el voto mayoritario o promedio."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:3f7f0d3434d6803b89f3e6e9b1c2e7eec8c7a0f7a672b7b1a8e8c2f0b92b7b74",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "25a2d188-28f0-4c8b-aa6d-053d66c5a777",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "bae420cf-ae91-488c-a876-710db0be84d6",
      "type": "DESARROLLO",
      "prompt": "En el contexto de la financiación de proyectos de IA, explica qué elementos principales debe contener el análisis de viabilidad del proyecto.",
      "difficulty": 3,
      "tags": [
        "financiacion",
        "gestion-proyectos"
      ],
      "modelAnswer": "## Análisis de Viabilidad de un Proyecto de IA\n\n### Elementos principales de la memoria\n\n**1. Descripción del problema y justificación**\nQué problema se aborda, por qué es relevante y qué impacto tendrá. Estado del arte que justifique la necesidad.\n\n**2. Objetivos e hipótesis de investigación**\nObjetivos SMART (Específicos, Medibles, Alcanzables, Relevantes, Temporales) e hipótesis claras.\n\n**3. Diseño experimental y metodología**\nTipo de estudio, datos a recoger, variables a medir, técnicas de IA y métricas de evaluación.\n\n**4. Plan de trabajo y cronograma**\nTareas organizadas en fases con diagrama de Gantt: duración, dependencias y responsables.\n\n**5. Recursos y presupuesto**\n- Humanos: investigadores, ingenieros ML, técnicos de apoyo.\n- Materiales: infraestructura hardware/cloud, licencias de software.\n- Consumibles: almacenamiento, acceso a bases de datos.\n\n**6. Análisis económico-financiero**\n- Coste total del proyecto.\n- Fuentes de financiación: convocatorias públicas (H2020, CDTI, Plan Nacional I+D), inversión privada.\n- ROI esperado: VAN (Valor Actual Neto) y TIR (Tasa Interna de Retorno).\n\n**7. Plan de difusión y explotación de resultados**\nPublicaciones, congresos, patentes, licencias, posibles spin-off.",
      "keywords": [
        "viabilidad",
        "memoria proyecto",
        "financiación",
        "VAN",
        "TIR",
        "SMART",
        "Gantt",
        "H2020",
        "CDTI"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:d344967a6d528e34024583da7a166eaee092a7adf5c2f4a88fc17195fd18387c",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "25f176fc-bf41-4119-ad56-ccb59ea871ff",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "PRACTICO",
      "prompt": "### Evaluación de un clasificador de fraude (métricas)\n\nSupongamos que hemos utilizado un clasificador (p. ej. **SVM**) para distinguir entre transacciones bancarias **fraudulentas** (`Fr`) y **no fraudulentas** (`No`).\n\nA partir de los siguientes resultados:\n\n| Transacción | Clase real | Clase predicha |\n|---|---|---|\n| Tran1 | Fr | Fr  TP |\n| Tran2 | Fr | Fr TP |\n| Tran3 | No | No TN |\n| Tran4 | No | No TN |\n| Tran5 | Fr | No  FN |\n| Tran6 | No | No TN |\n| Tran7 | No | No TN |\n| Tran8 | Fr | Fr TP |\n| Tran9 | Fr | No FN |\n| Tran10 | No | Fr FP |\n\n\nSe pide:\n\n1. Calcular **precision**, **recall**, **accuracy** y **F1** para estos resultados de clasificación **para las dos clases**.  \n2. En base a los resultados obtenidos, explica el comportamiento del clasificador en cuanto a la **detección de transacciones fraudulentas**.\n\n> Origen: **Examen anterior** (UNIR **TAA 2024**, **Modelo E**, código **10210067**).\n",
      "explanation": "Lo relevante es la **clase Fr**: con recall 0.60 estás dejando pasar un 40% de fraude. Si el coste del FN es alto, hay que mover el objetivo hacia mayor recall aunque suban FP.",
      "difficulty": 4,
      "tags": [
        "examen anterior",
        "UNIR",
        "2024",
        "modelo-e",
        "métricas",
        "matriz de confusión",
        "fraude"
      ],
      "modelAnswer": "Primero sacamos la matriz de confusión tomando **Fr** como clase positiva:\n\n- **TP (Fr→Fr)**: Tran1, Tran2, Tran8 = **3**  \n- **FN (Fr→No)**: Tran5, Tran9 = **2**  \n- **TN (No→No)**: Tran3, Tran4, Tran6, Tran7 = **4**  \n- **FP (No→Fr)**: Tran10 = **1**  \n\nTotal = 10.\n\n## Métricas (clase positiva = Fr)\n- **Precision(Fr)** = TP / (TP+FP) = 3 / (3+1) = **0.75**\n- **Recall(Fr)** = TP / (TP+FN) = 3 / (3+2) = **0.60**\n- **Accuracy** = (TP+TN) / Total = (3+4) / 10 = **0.70**\n- **F1(Fr)** = 2·P·R / (P+R) = 2·0.75·0.60 / (0.75+0.60) = **0.67**\n\n## Métricas para la otra clase (No)\nSi calculas por clase (one-vs-rest) para **No** como “positiva”:\n\n- TP(No)=4, FP(No)=2, FN(No)=1, TN(No)=3\n\n- **Precision(No)** = 4/(4+2) = **0.67**\n- **Recall(No)** = 4/(4+1) = **0.80**\n- **F1(No)** ≈ 2·0.67·0.80/(0.67+0.80) = **0.73**\n- **Accuracy** = **0.70** (igual para ambas clases)\n\n## Interpretación (detección de fraude)\n- El modelo **se equivoca poco** comparado con el total (70%), pero eso no es lo importante si el fraude es crítico.\n- Para **fraude**, el **recall es 0.60**: se come **2 de 5** fraudes (40%).  \n  Si el objetivo empresarial es “no dejar pasar fraude”, esto es flojo.\n- La **precision de fraude 0.75** indica que cuando marca fraude suele acertar, pero aún genera algún falso positivo (1 caso).\n\n**Qué haría para mejorar detección de fraude (si es lo prioritario):**\n- Ajustar el umbral / costes (si el modelo lo permite), o **class_weight** / re-muestreo para priorizar recall de fraude.\n- Evaluar con métricas enfocadas en fraude: recall/F1 de la clase Fr, curva PR, etc.",
      "createdBy": "Luis",
      "sourcePackId": "7b705f3e-b96f-429a-8cf2-7fba79c8a0fa",
      "contentHash": "sha256:1e3cac7279c88b1518a40fb80893644a8e587b3f5dccfd2460abb1a7c6b63c2d",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "279cb986-0b59-460e-a4a3-b4921d191dc0",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes es una característica de los **diagramas de dispersión**?",
      "explanation": "Los diagramas de dispersión permiten **visualizar relaciones**, detectar tendencias y analizar si existe correlación entre variables.",
      "difficulty": 1,
      "tags": [
        "diagramas",
        "dispersión",
        "correlación"
      ],
      "options": [
        {
          "id": "a",
          "text": "Muestran una relación existente entre variables numéricas"
        },
        {
          "id": "b",
          "text": "Permiten descubrir relaciones"
        },
        {
          "id": "c",
          "text": "Permiten identificar relación de incremento o disminución entre variables"
        },
        {
          "id": "d",
          "text": "**Todas son características de los diagramas de dispersión**"
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:ca0693fbcc0e3408ead35aa589d7a3ba7d998068dc960d0eacc86705383b230d",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "27ddce11-db2a-4d11-8305-3c2fc567d8b7",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "Un científico de datos está utilizando Máquinas de Vectores de Soporte (SVM) para un problema de clasificación binaria. Después de entrenar el modelo, observa que hay un pequeño margen de separación entre las clases y sospecha que el modelo podría beneficiarse de una transformación no lineal de las características. ¿Qué técnica sería más apropiada para introducir no linealidades en el espacio de características y mejorar la capacidad del SVM para clasificar datos más complejos?",
      "explanation": "✅ **B. Utilizar la función de kernel.**\n\nEn SVM, el **kernel trick** permite trabajar en un *feature space* (implícito) donde la separación puede ser lineal aunque en el espacio original no lo sea.\n\n**Por qué no las otras:**\n- **A (C)**: cambia regularización/margen, pero no introduce no linealidad por sí sola.\n- **C**: “subir dimensión” a mano no es la idea; el kernel ya lo hace de forma implícita.\n- **D**: puede ayudar, pero no es la técnica específica para no linealidades.",
      "difficulty": 3,
      "options": [
        {
          "id": "acdb0c2b-f575-4c1b-a39d-d45cc10e890c",
          "text": "Ajustar el parámetro de regularización (C)."
        },
        {
          "id": "75fd7f13-097a-456d-bb5a-592a6743ee0c",
          "text": "Utilizar la función de kernel."
        },
        {
          "id": "40a1a980-8138-4b71-b4d3-e1afa07d291e",
          "text": "Incrementar la dimensión del espacio de características."
        },
        {
          "id": "961aa092-6c75-41b4-a58d-68f1fd9cd151",
          "text": "Reducir el ruido en los datos de entrenamiento."
        }
      ],
      "correctOptionIds": [
        "75fd7f13-097a-456d-bb5a-592a6743ee0c"
      ],
      "createdBy": "",
      "sourcePackId": "contribution-2026-02-18-julio-modelosB-C-new-6f543832",
      "contentHash": "sha256:875aa57f0cb44e192a7ca3e204a8a8b4255cce9e7a4005eb8421fe9d07583f82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "293e5a66-2b2d-496f-b008-dae1fe4058cd",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes visualizaciones es más adecuada para evaluar los **errores** en un modelo de regresión?\n\nSeleccione una:",
      "explanation": "El gráfico **residuos vs. predichos** permite detectar patrones (no linealidad), heterocedasticidad (forma de embudo) y otros problemas: ideal para diagnóstico de regresión.",
      "difficulty": 2,
      "tags": [
        "residuos",
        "diagnostico",
        "visualizacion",
        "regresion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Gráfico de barras de frecuencia de errores absolutos."
        },
        {
          "id": "b",
          "text": "Gráfico de dispersión de residuos vs. valores predichos."
        },
        {
          "id": "c",
          "text": "Gráfico de línea de errores relativos vs. iteraciones de entrenamiento."
        },
        {
          "id": "d",
          "text": "Gráfico de pastel de errores cuadráticos medios."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:f068d9087e720e2d97ddf3309328270eedbc5ab6d801a15620f549997a2bf125",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "29733545-2e53-472c-b953-f8be5a5a2df3",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "En Random Forest, ¿cómo se calcula la **importancia de las variables**?",
      "explanation": "Se basa en la **reducción de impureza** (p. ej. índice Gini) aportada por una variable en los nodos donde se usa para dividir, agregada a lo largo del bosque.",
      "difficulty": 3,
      "tags": [
        "random-forest",
        "importancia-variables",
        "gini"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Suma de las predicciones."
        },
        {
          "id": "b",
          "text": "Suma de las impurezas en los nodos donde se realiza una división."
        },
        {
          "id": "c",
          "text": "Número de nodos en los árboles."
        },
        {
          "id": "d",
          "text": "Número de variables en el conjunto de datos."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:4377892a82f6f4254489e906dca3340123649bb73bc616a9528ab238f186195f",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "2a3b878e-6411-4088-bbb3-5ad0c89a0fbe",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "En la fase de entrenamiento de los modelos:",
      "explanation": "El entrenamiento consiste en ajustar/aprender el modelo con los datos para poder usarlo después en predicción.",
      "difficulty": 1,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "Se realiza la extracción de características y se utiliza para generar posteriormente una predicción."
        },
        {
          "id": "b",
          "text": "Se elige qué modelo es el mejor."
        },
        {
          "id": "c",
          "text": "Se aprende un modelo que podrá ser utilizado posteriormente."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:f521a9be43ab6d9a9b7aef9f4f4fb5b8b745d18e3fcbf2f83ad02a9c6b13b0b8",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "2a8a62fa-1dfe-4a3b-85a9-f0b7326736e7",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "e50ab4a3-574f-4002-ac5f-e5912c4cf9d3",
      "type": "DESARROLLO",
      "prompt": "Los sistemas cognitivos requieren de grandes volúmenes de datos para generar aplicaciones eficaces. Desarrolla un caso de uso de aplicación del Big Data a sistemas cognitivos con fuentes diversas, alta velocidad y gran volumen.",
      "difficulty": 2,
      "tags": [
        "sistemas-cognitivos",
        "big-data"
      ],
      "modelAnswer": "## Big Data y Sistemas Cognitivos: Sistema de Salud Predictivo\n\n### Las 3V del Big Data en este caso\n- **Volumen**: Petabytes de datos clínicos históricos.\n- **Velocidad**: Datos generados en tiempo real por dispositivos wearables y sensores.\n- **Variedad**: Datos estructurados, texto clínico, imágenes médicas, señales biométricas.\n\n### Fuentes de datos diversas\n- **Registros médicos electrónicos (EHR)**: Historial clínico, medicación, laboratorio.\n- **Dispositivos wearables**: Frecuencia cardíaca, SpO2, tensión arterial, sueño en tiempo real.\n- **Imágenes médicas**: Radiografías, RMN, tomografías (datos no estructurados de gran tamaño).\n- **Redes sociales**: Menciones sobre síntomas, sentimiento de la población.\n- **Datos meteorológicos y ambientales**: Correlación entre contaminación/temperatura y enfermedades respiratorias.\n\n### Aplicación cognitiva\n1. **Predecir brotes de enfermedades** semanas antes de que sean evidentes.\n2. **Identificar pacientes de alto riesgo** de reingreso o complicaciones graves.\n3. **Optimizar la asignación de recursos**: Camas, personal, medicamentos.\n4. **Personalizar tratamientos** según perfil genético y respuesta histórica del paciente.\n\n### Infraestructura requerida\nPlataforma Big Data con procesamiento en streaming (Apache Kafka, Spark Streaming) para datos en tiempo real, y Data Lake en cloud para el histórico.",
      "keywords": [
        "Big Data",
        "3V",
        "sistemas cognitivos",
        "salud predictiva",
        "wearables",
        "EHR",
        "streaming",
        "Kafka"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:06e23cea90bb141c327b3fadfbb1d971ef96b4ed9066378e27eab8a25191d4e3",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "2f1c4677-3345-4082-ba78-a9923622c7b8",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "DESARROLLO",
      "prompt": "### Riesgo de obesidad (Análisis)\n\nEn el material adicional (Anexo) se proporciona un conjunto de datos sobre **riesgo/nivel de obesidad** (variable objetivo *NObeyesdad* en un problema típico de clasificación multiclase).\n\nResponde **sin escribir código**:\n\n1) ¿Qué análisis previos y tratamiento de datos harías para decidir si se puede construir un modelo fiable?  \n2) ¿Qué algoritmo(s) usarías y por qué? Explica su funcionamiento a alto nivel.  \n3) ¿Qué métricas de evaluación usarías para valorar la bondad del modelo y cómo lo evaluarías?\n\n(Justifica supuestos: tipos de variables, codificación, balanceo, outliers, etc.).",
      "explanation": "Se espera una respuesta estructurada: EDA + limpieza (tipos, nulos, outliers), elección razonada de algoritmos de clasificación (árboles/RF/SVM) y métricas apropiadas para multiclase (confusión, F1 macro/weighted, recall por clase).",
      "difficulty": 4,
      "tags": [
        "análisis exploratorio",
        "clasificación multiclase",
        "random forest",
        "métricas"
      ],
      "modelAnswer": "### 1) Análisis previos y tratamiento de datos (sin código)\n\n**Objetivo:** comprobar si los datos permiten un modelo *útil* y *fiable* y preparar el dataset.\n\n1. **Entender la variable objetivo**\n   - *NObeyesdad* suele ser **multiclase** (p. ej. *Insufficient_Weight*, *Normal_Weight*, *Overweight_Level_I/II*, *Obesity_Type_I/II/III*).  \n   - Comprobar si queremos tratarla como **ordinal** (tiene orden natural) o como **nominal** (solo categorías). En muchos modelos se trabaja como multiclase nominal.\n\n2. **Exploración descriptiva**\n   - Distribución de clases (¿balanceado? ¿clases raras?).\n   - Descriptivos de variables numéricas (media, varianza, rangos).\n   - Relaciones claras (p. ej. *Weight* vs clase; si hay *Height* y *Weight* se puede derivar **BMI** y ver si aporta).\n\n3. **Calidad del dato**\n   - **Nulos/ausentes:** si los hay, imputación (media/mediana/moda o técnicas más robustas).\n   - **Outliers:** detectar (boxplots/IQR) y decidir:  \n     - corregir si son errores,  \n     - capar/winsorizar si son extremos irreales,  \n     - o mantenerlos si son casos reales (importante en medicina).\n\n4. **Tipos de variables y codificación**\n   - **Numéricas:** *Age, Height, Weight, FCVC, CH2O, FAF, TUE…*\n   - **Categóricas binarias:** *SMOKE, SCC, family_history_with_overweight…*\n   - **Categóricas nominales:** *MTRANS…*\n   - **Ordinales:** *CAEC, CALC, NCP…* (si representan niveles/orden).\n   - Preparar codificación:\n     - One-hot para nominales (si el algoritmo lo necesita).\n     - Ordinal encoding para ordinales (si procede).\n\n5. **Normalización / escalado**\n   - **Necesario** si usamos modelos basados en distancia/hiperplano (p. ej. **SVM**).\n   - **No imprescindible** para árboles / Random Forest.\n\n6. **Partición y validación**\n   - Separar train/test y usar **validación cruzada** (estratificada por clase).  \n   - Evitar *data leakage* (cualquier transformación se ajusta solo con train).\n\n---\n\n### 2) Algoritmos y por qué\n\nComo es **clasificación multiclase** con mezcla de numéricas + categóricas:\n\n- **Árbol de decisión (baseline interpretable):**\n  - Ventaja: explicable (reglas “si… entonces…”).\n  - Riesgo: sobreajuste si no se limita profundidad/poda.\n\n- **Random Forest (recomendación principal):**\n  - Es **bagging** de muchos árboles con subconjuntos de datos y variables.\n  - Reduce varianza y suele generalizar mejor que un árbol único.\n  - Permite **importancia de variables** (explicabilidad parcial).\n\n- **SVM (alternativa):**\n  - Puede ir muy bien si el problema es separable tras un **kernel** y hay buen escalado,\n  - pero en multiclase suele requerir estrategias *one-vs-rest* y es menos interpretable.\n\nEn un contexto “médico”, el equilibrio típico es:\n- usar **Random Forest** (buen rendimiento),\n- y acompañarlo de interpretación (importancias, reglas aproximadas) para justificar.\n\n---\n\n### 3) Métricas y evaluación\n\nAl ser multiclase, **Accuracy sola es insuficiente**.\n\nUsaría:\n- **Matriz de confusión** (para ver qué clases se confunden).\n- **Precision / Recall / F1 por clase**.\n- **F1 macro** (todas las clases pesan igual) y **F1 weighted** (ponderado por soporte).\n- Si hay clases “críticas” (p. ej. obesidad severa), priorizar **Recall** de esas clases.\n- (Opcional) **Balanced accuracy** si hay desbalanceo.\n\n**Evaluación recomendada:**\n- Validación cruzada estratificada para estimar estabilidad.\n- Ajuste de hiperparámetros (p. ej. profundidad, nº árboles, max_features) con **grid search**.\n- Reportar métricas medias y desviación (robustez), no solo un número.\n\n> Importante: **R² no aplica** aquí (es de regresión). En clasificación reportamos métricas de clasificación.\n",
      "keywords": [
        "EDA",
        "multiclase",
        "codificación",
        "one-hot",
        "variables ordinales",
        "validación cruzada",
        "matriz de confusión",
        "F1 macro",
        "random forest"
      ],
      "createdBy": "Luis",
      "sourcePackId": "9f68ddcb-ee6e-4448-b804-bce7c3c45725",
      "contentHash": "sha256:90d052f89ce9c25ae57a799fea1b3a49fab2ef22f657b1518cc9d5807c18b49a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "30892949-e0b8-475f-a274-6227ae65f543",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "Indica cuál de las siguientes afirmaciones sobre **soft margin** es **falsa**.",
      "explanation": "No existe un 'siempre': si los datos son perfectamente separables y con poco ruido, *hard margin* puede funcionar igual o mejor; *soft margin* depende de $C$ y del ruido/outliers.",
      "difficulty": 3,
      "tags": [
        "svm",
        "soft-margin",
        "hard-margin",
        "C"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "SVM de *soft margin* permite cierta clasificación errónea de los puntos de datos de entrenamiento al introducir variables débiles que relajan la rigurosidad del margen."
        },
        {
          "id": "b",
          "text": "SVM de *soft margin* se utiliza cuando los datos de entrenamiento no son perfectamente separables por un hiperplano, lo que permite un límite más flexible que puede ser adecuado con datos ruidosos."
        },
        {
          "id": "c",
          "text": "El parámetro de regularización $C$ en SVM *soft margin* controla el equilibrio entre maximizar el margen y minimizar el error de clasificación en los datos de entrenamiento."
        },
        {
          "id": "d",
          "text": "SVM de *soft margin* siempre funciona mejor que SVM de *hard margin* en conjuntos de datos linealmente separables."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:4ce4c7f5f1c0d5a2c0d5d69f4b2c2dfb4b8c8b0a36f7b7d7f5e8b154f5b1d0e3",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "31e90b03-e107-4582-b039-8a2d54b6f989",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Cuando existen combinaciones desconocidas en los datos de entrada:",
      "explanation": "Si aparecen combinaciones no vistas, algunas probabilidades estimadas pueden ser **0** y el posterior queda distorsionado; se suele aplicar suavizado.",
      "difficulty": 2,
      "tags": [
        "naive-bayes",
        "laplace",
        "probabilidad-cero"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Las probabilidades a posteriori obtenidas pueden no tener sentido."
        },
        {
          "id": "b",
          "text": "El teorema de Bayes utiliza el estimador de Laplace."
        },
        {
          "id": "c",
          "text": "Se eliminan estas combinaciones de los datos de entrada."
        },
        {
          "id": "d",
          "text": "El algoritmo es capaz de ignorarlas."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:1a2b3c4d5e6f708192a3b4c5d6e7f8091a2b3c4d5e6f708192a3b4c5d6e7f809",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "357ebcf6-1782-4a10-97ba-caf10e743a0b",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones describe correctamente el overfitting en el contexto del aprendizaje automático?",
      "explanation": "Overfitting: rendimiento muy bueno en entrenamiento pero malo en datos nuevos por falta de generalización.",
      "difficulty": 1,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "El overfitting ocurre cuando el modelo se ajusta demasiado a los datos de entrenamiento y no generaliza bien a nuevos datos."
        },
        {
          "id": "b",
          "text": "El overfitting se refiere a la falta de ajuste del modelo a los datos de entrenamiento, lo que resulta en un rendimiento deficiente."
        },
        {
          "id": "c",
          "text": "El overfitting es beneficioso ya que permite al modelo adaptarse perfectamente a los datos de entrenamiento."
        },
        {
          "id": "d",
          "text": "El overfitting solo afecta a modelos lineales y no a modelos no lineales."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:0b2c3b9cf1b6c8165a2e2a0d1f9c0d741f78e3a89a2b8c8e3dbdbf5d2e7f6a19",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "36240c7b-a94e-4975-b832-064ab48292a8",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "33ab0c5f-8035-43a2-8314-55bdc07b4b6d",
      "type": "TEST",
      "prompt": "¿Qué elementos mínimos debe capturar el **tracing** para una auditoría efectiva?",
      "explanation": "Para auditar necesitas entrada (anonimizada), evidencias recuperadas, lo que se pidió al modelo, la respuesta, decisiones de moderación, versiones y métricas (tokens/latencias) por etapa. Evitar PII innecesaria.",
      "difficulty": 3,
      "tags": [
        "tracing",
        "auditoria",
        "observabilidad",
        "moderacion",
        "versionado"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Solo la respuesta final y el tiempo total."
        },
        {
          "id": "b",
          "text": "Únicamente los errores; lo demás no importa."
        },
        {
          "id": "c",
          "text": "Consulta (anonimizada), pasajes e ID recuperados, *prompt* final, respuesta, decisiones de moderación, versiones de modelo/índice, tokens y latencias por etapa."
        },
        {
          "id": "d",
          "text": "PII completa del usuario para identificarle con precisión."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:2a1b0c9d8e7f6a5b4c3d2e1f0a9b8c7d6e5f4a3b2c1d0e9f8a7b6c5d4e3f2a1b",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "3814d3bf-19d6-457a-927b-e8fd1b21ab81",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "971fb6e6-0b0d-4637-8d69-7db209dd146e",
      "type": "DESARROLLO",
      "prompt": "Explica por qué en los documentos científicos se deben incluir referencias bibliográficas y cómo deben utilizarse. Demuéstralo con un ejemplo de citación en el texto y su correspondiente referencia en la bibliografía.",
      "difficulty": 2,
      "tags": [
        "redaccion-cientifica"
      ],
      "modelAnswer": "## Referencias Bibliográficas\n\n### Por qué son necesarias\n1. **Atribución**: Reconocer la autoría de ideas y datos ajenos; evitar el plagio.\n2. **Verificabilidad**: El lector puede contrastar, ampliar o refutar la información citada.\n3. **Impacto científico**: Las citas son la principal métrica del impacto (índice h, factor de impacto).\n4. **Credibilidad**: Fundamentar afirmaciones en fuentes revisadas por pares.\n\n### Cómo utilizarlas\n- Citar inmediatamente tras usar una afirmación, dato o idea ajena.\n- Seguir el estilo de la publicación (APA, IEEE, Vancouver, Chicago).\n- Citar solo fuentes leídas en el original.\n\n### Ejemplo (estilo APA)\n\n**En el texto**:\n> \"Las redes neuronales convolucionales han demostrado resultados superiores en reconocimiento de imágenes médicas (LeCun et al., 2015).\"\n\n**En Bibliografía**:\n> LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. *Nature*, 521(7553), 436–444. https://doi.org/10.1038/nature14539",
      "keywords": [
        "referencias bibliográficas",
        "citación",
        "APA",
        "IEEE",
        "plagio",
        "impacto científico"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:124dae14adbeb9c21314004140c25ad78ab27572fcfef14a7861d67f4cfe24a3",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "3860e5f8-31f9-4d5b-bd40-9ce56ae643be",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones describe correctamente la **poda** de árboles de decisión?",
      "explanation": "La poda elimina ramas poco útiles para **reducir complejidad** y **mejorar generalización** (normalmente validación/test).",
      "difficulty": 2,
      "tags": [
        "poda",
        "overfitting",
        "regularizacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "La poda en árboles de decisión implica agregar más nodos al árbol para mejorar su capacidad de generalización y precisión en la predicción."
        },
        {
          "id": "b",
          "text": "La poda se realiza eliminando ramas del árbol que no contribuyen significativamente a mejorar su rendimiento en el conjunto de datos de prueba."
        },
        {
          "id": "c",
          "text": "La poda de árboles de decisión es un proceso que se lleva a cabo durante la etapa de construcción del árbol para mejorar su capacidad de ajuste a los datos de entrenamiento."
        },
        {
          "id": "d",
          "text": "La poda de árboles de decisión solo se aplica en casos donde el árbol ha alcanzado un tamaño excesivo y se necesita reducir su complejidad para evitar el sobreajuste."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:14333d4bff76a652ec15829ec0d9011ad39b095b5b9dae5d6248584fad8758b3",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "399b4775-8d48-4a37-8802-7f5893788933",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a0ee552f-68ca-4b05-bf4f-9e4f2edc904c",
      "type": "DESARROLLO",
      "prompt": "Describe cómo los agentes inteligentes se utilizan en la automatización del hogar (smart home) y da un ejemplo específico de su aplicación.",
      "difficulty": 2,
      "tags": [
        "agentes",
        "IoT"
      ],
      "modelAnswer": "## Agentes Inteligentes en el Hogar Inteligente\n\nLos hogares inteligentes integran dispositivos IoT controlados por agentes inteligentes que perciben el entorno mediante sensores y actúan sobre él mediante actuadores.\n\n### Tipos de agentes en el hogar\n- **Reactivos**: Responden a condiciones del entorno con reglas simples (encender luz si sensor detecta movimiento).\n- **Deliberativos (por objetivos)**: Planifican para alcanzar un objetivo (termostato que planifica temperatura considerando la localización GPS del usuario).\n- **Por utilidad**: Optimizan múltiples objetivos (minimizar factura eléctrica usando electrodomésticos en horas valle mientras mantienen confort).\n- **Sistemas multi-agente**: Coordinan termostato, persiana, riego y seguridad.\n\n### Ejemplo específico: Robot aspirador (Roomba)\n\n**Sensores**: Infrarrojos y ultrasonidos para obstáculos, sensor de suciedad, sensor de batería, mapa SLAM del hogar.\n\n**Objetivo**: Limpiar toda la superficie del hogar.\n\n**Función de utilidad**: Maximizar superficie limpiada minimizando tiempo y energía.\n\n**Comportamiento**: Calcula rutas de cobertura óptimas, evita obstáculos y regresa automáticamente a la base de carga. Los modelos modernos aprenden el mapa y los hábitos del usuario para optimizar los horarios de limpieza.",
      "keywords": [
        "smart home",
        "IoT",
        "agente reactivo",
        "automatización",
        "robot aspirador",
        "SLAM"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:2b662fbc6b7bbe423e17dd9d000aae206acf9838d90fb44dbfd006615be65d89",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "3b485573-23c5-48ae-9e18-6d3b69f61651",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a0ee552f-68ca-4b05-bf4f-9e4f2edc904c",
      "type": "DESARROLLO",
      "prompt": "Describe en qué consiste el algoritmo MINIMAX y sus campos de aplicación. Aporta un ejemplo.",
      "difficulty": 2,
      "tags": [
        "agentes",
        "algoritmos"
      ],
      "modelAnswer": "## Algoritmo Minimax\n\n### Qué es\nEl **Minimax** es un algoritmo de búsqueda adversarial en árboles de decisión para **juegos de dos jugadores de suma cero con información perfecta**. Busca la acción óptima asumiendo que el oponente también juega de forma óptima.\n\n- **MAX**: Selecciona la acción que maximiza su puntuación.\n- **MIN**: Selecciona la acción que minimiza la puntuación de MAX.\n- El algoritmo explora recursivamente el árbol hasta estados terminales, propagando valores hacia la raíz alternando MAX/MIN.\n\n### Complejidad y optimización\nExplora todos los nodos: **O(b^d)**. La **poda alfa-beta** elimina ramas que no pueden influir en la decisión, reduciendo la complejidad a **O(b^(d/2))** en el mejor caso sin alterar el resultado.\n\n### Campos de aplicación\n- **Juegos por turnos**: Ajedrez, damas, tres en raya, Othello.\n- **Negociación automática**: Anticipar respuestas del oponente.\n- **Robótica adversarial**: Planificación con agentes de objetivos opuestos.\n\n### Ejemplo: Tres en raya\nEl agente MAX (juega con X) evalúa todas las posibles jugadas. En cada turno de MIN (juega con O) se selecciona la jugada que minimiza la ganancia de MAX. Minimax garantiza que el agente nunca pierde si juega de forma óptima. La poda alfa-beta elimina ramas innecesarias haciendo el cálculo mucho más eficiente.",
      "keywords": [
        "minimax",
        "poda alfa-beta",
        "suma cero",
        "árbol decisión",
        "búsqueda adversarial",
        "ajedrez"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:1f0a1f302f27008d07c7a1a6b0a0e831b4a302d12fc45eb6da6e81315b498a59",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "3b4b0e35-50e1-4275-8c19-5845d38a0957",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "502e9489-f902-45a4-8614-1f853b90f62f",
      "type": "DESARROLLO",
      "prompt": "Explica las principales diferencias de las metodologías ágiles frente a las tradicionales en lo referente a las variables de alcance, tiempo y coste de un proyecto.",
      "difficulty": 2,
      "tags": [
        "gestion-proyectos",
        "metodologias"
      ],
      "modelAnswer": "## Metodologías Ágiles vs Tradicionales\n\n### El triángulo de restricciones\nTodo proyecto se define por: **alcance** (qué se hace), **tiempo** (cuánto tarda) y **coste** (cuánto cuesta). La diferencia fundamental: cuál es fija y cuál es flexible.\n\n### Metodologías Tradicionales (Waterfall, PMBOK)\n- **Alcance**: Definido **completamente al inicio** mediante requisitos congelados. Los cambios son costosos.\n- **Tiempo y Coste**: Se estiman a partir del alcance fijo; el equipo intenta cumplirlos.\n- **Entrega**: Un único entregable final al término del proyecto.\n- **Adecuado para**: Proyectos con requisitos estables y bien definidos (ingeniería civil, hardware).\n\n### Metodologías Ágiles (Scrum, Kanban, SAFe)\n- **Alcance**: Es la variable **flexible**. Las funcionalidades se priorizan en un *backlog* y pueden modificarse entre sprints.\n- **Tiempo y Coste**: Son **fijos** (duración del sprint y tamaño del equipo constantes).\n- **Entrega**: Entregables **incrementales y funcionales** al final de cada sprint.\n- **Adecuado para**: Proyectos con requisitos cambiantes (software, IA, startups).\n\n### Por qué las ágiles son preferidas en IA\nEn proyectos de IA, los resultados experimentales pueden cambiar la dirección del proyecto. La posibilidad de ajustar el alcance sprint a sprint permite reorientar la investigación sin los altos costes de cambio del modelo en cascada.",
      "keywords": [
        "metodologías ágiles",
        "waterfall",
        "alcance",
        "tiempo",
        "coste",
        "Scrum",
        "sprint",
        "backlog"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:9469d035a3d1f428bbcb34f87129fe84c0eca0b29123011016aad48c34c679e6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "3c3cfc5c-aeee-4804-b4cb-2a6d49b90011",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "La búsqueda aleatoria de hiperparámetros:",
      "explanation": "La búsqueda aleatoria de hiperparámetros puede no ser suficiente para encontrar la configuración óptima en modelos complejos o en problemas con conjuntos de datos particulares. En tales casos, pueden ser necesarios enfoques más avanzados, como la optimización bayesiana o la búsqueda en cuadrícula, para encontrar la mejor combinación de hiperparámetros.",
      "difficulty": 2,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "random-search",
        "limitaciones"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Siempre es suficiente."
        },
        {
          "id": "b",
          "text": "En algunos modelos complejos puede ser insuficiente."
        },
        {
          "id": "c",
          "text": "Que sea suficiente o insuficiente depende de los datos de entrenamiento."
        },
        {
          "id": "d",
          "text": "Es eficiente porque siempre encuentra la configuración óptima de hiperparámetros."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:4d5c6b7a8f9e0d1c2b3a495867768594d5c6b7a8f9e0d1c2b3a495867768594d",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "3c93acd3-c9cb-4c59-a916-c2e5034d3fa2",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "33ab0c5f-8035-43a2-8314-55bdc07b4b6d",
      "type": "TEST",
      "prompt": "¿Qué práctica reduce el riesgo de **prompt injection** al mezclar instrucciones del usuario con las del sistema?",
      "explanation": "Separar roles y sanear entrada reduce que el usuario “se haga pasar” por sistema; una *denylist* ayuda contra patrones clásicos (p. ej., “ignora instrucciones anteriores…”).",
      "difficulty": 3,
      "tags": [
        "seguridad",
        "prompt-injection",
        "delimitadores",
        "sanitizacion",
        "denylist"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Aumentar la temperatura y el tamaño de contexto."
        },
        {
          "id": "b",
          "text": "Separar roles con delimitadores, normalizar/limpiar entrada y aplicar *denylist* de frases típicas."
        },
        {
          "id": "c",
          "text": "Incrustar las políticas dentro del mensaje del usuario."
        },
        {
          "id": "d",
          "text": "Permitir que el usuario «edite» el *prompt* de sistema si lo solicita."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:4b3c2d1e0f9a8b7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b9c8d7e6f5a4b3c",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "3cbdfcd8-58bf-4c1e-938b-87ab1c151823",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Qué indica un **coeficiente de regresión negativo** en un modelo lineal?\n\nSeleccione una:",
      "explanation": "Si $\\beta<0$ en $\\hat{y}=\\beta_0+\\beta x$, al aumentar $x$ la predicción $\\hat{y}$ tiende a disminuir (relación inversa).",
      "difficulty": 1,
      "tags": [
        "regresion-lineal",
        "coeficientes",
        "interpretacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "La variable predictora tiene un efecto negativo en la variable de respuesta."
        },
        {
          "id": "b",
          "text": "No hay relación entre la variable predictora y la variable de respuesta."
        },
        {
          "id": "c",
          "text": "La variable predictora tiene un efecto positivo en la variable de respuesta."
        },
        {
          "id": "d",
          "text": "El modelo no es adecuado para hacer predicciones."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:f2427f17178330e9fea3738879df914d9105234e885e435f509d125d7b34ac61",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "3eb25634-fd5d-4b40-b531-018a3449b551",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "Los modelos de procesos gaussianos:",
      "explanation": "Los modelos de procesos gaussianos son una técnica utilizada para la optimización de hiperparámetros. Se aplican especialmente en casos donde la función objetivo es costosa de evaluar o no tiene una forma simple.",
      "difficulty": 3,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "procesos-gaussianos",
        "optimizacion-bayesiana"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Son un método de optimización de hiperparámetros basado en búsqueda cartesiana."
        },
        {
          "id": "b",
          "text": "Se utilizan para optimizar parámetros de modelos complejos."
        },
        {
          "id": "c",
          "text": "Son un tipo de automatic sequential optimization."
        },
        {
          "id": "d",
          "text": "Son un método de optimización que ralentiza la búsqueda de hiperparámetros."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:3c2b1a0f9e8d7c6b5a4f3e2d1c0b9a8f7e6d5c4b3a29108f7e6d5c4b3a29108",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "41e849c3-3a02-4162-9d01-6e0e6b5dba9c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "Es una característica del algoritmo Z-score:",
      "explanation": "El Z-score estandariza los datos, dejándolos con **media 0** y **desviación 1**; en el temario se interpreta además como paso al espacio de la normal estándar (cuando los datos siguen una distribución normal).",
      "difficulty": 2,
      "tags": [
        "z-score",
        "estandarizacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Consiste en la estandarización de un conjunto de datos."
        },
        {
          "id": "b",
          "text": "Transforma los datos en un espacio de distribución normal."
        },
        {
          "id": "c",
          "text": "La media es cero y la desviación es 1."
        },
        {
          "id": "d",
          "text": "Todas las anteriores son características del algoritmo Z-score."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:3c7b2a1f9d8e7c6b5a4f3e2d1c0b9a8f7e6d5c4b3a291827364554433221100f",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "435f5b25-9b8a-476d-9743-0884fe8f62fc",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones es una **ventaja** de los *kernels*?",
      "explanation": "La principal ventaja del *kernel trick* es poder obtener fronteras no lineales sin construir explícitamente las nuevas características en alta dimensión.",
      "difficulty": 1,
      "tags": [
        "svm",
        "kernels",
        "kernel-trick",
        "no-linealidad"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Permiten utilizar un menor volumen de información."
        },
        {
          "id": "b",
          "text": "El coste computacional es menor al utilizar *kernels*."
        },
        {
          "id": "c",
          "text": "Los *kernels* permiten obtener fronteras de decisión no lineales."
        },
        {
          "id": "d",
          "text": "Los *kernels* reducen la dimensionalidad de los datos al mapearlos a un espacio de características mayor."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:0b1a2c3d4e5f60718293a4b5c6d7e8f90123456789abcdef0123456789abcdef0",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "44bbe46b-558f-46ed-88a5-b6dd23a0b494",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "El coeficiente de correlación de **Pearson** permite comparar:",
      "explanation": "Pearson requiere variables **numéricas y continuas** para medir la relación lineal.",
      "difficulty": 2,
      "options": [
        {
          "id": "a",
          "text": "**Variables cuantitativas y continuas**"
        },
        {
          "id": "b",
          "text": "Solo variables cuantitativas"
        },
        {
          "id": "c",
          "text": "Solo variables continuas"
        },
        {
          "id": "d",
          "text": "Variables cualitativas"
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:e352407dc0ce6e2921023117956a0494aeee1b1c3f22f7825b0cee716f3f9ac5",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "4539d94b-48cf-46eb-9921-5e6418375d3f",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes métricas no es utilizada en los modelos de clasificación?",
      "explanation": "El **MSE** (*Mean Squared Error*) es típico de **regresión**. En clasificación se usan precisión, recall, F1, AUC, etc.",
      "difficulty": 1,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Precisión."
        },
        {
          "id": "b",
          "text": "Recall."
        },
        {
          "id": "c",
          "text": "MSE."
        },
        {
          "id": "d",
          "text": "F-measure."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:4dbb8f3d0b839f1a5a4cd46a3c77b6dd3779e2d7a1622d3fbe13742e3b574c86",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "47cd68c3-c882-45fb-89e3-eb334dfe137e",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a0ee552f-68ca-4b05-bf4f-9e4f2edc904c",
      "type": "DESARROLLO",
      "prompt": "Si diseñamos un agente inteligente capaz de jugar al póker, describe las características de su entorno de trabajo (observable; determinista/estocástico; secuencial/episódico; estático/dinámico; discreto/continuo).",
      "difficulty": 2,
      "tags": [
        "agentes",
        "entorno"
      ],
      "modelAnswer": "## Entorno de Trabajo del Agente Póker\n\n### 1. Observable → Parcialmente observable\nEl agente no tiene acceso a las cartas de los oponentes ni a las cartas pendientes del mazo. Solo percibe las cartas comunitarias, las apuestas y su propia mano.\n\n### 2. Determinista/Estocástico → Estocástico\nEl resultado depende de factores aleatorios incontrolables: el reparto de cartas y las decisiones de los oponentes (inciertas). El mismo estado puede conducir a resultados distintos.\n\n### 3. Secuencial/Episódico → Secuencial\nCada decisión (apostar, igualar, subir, retirarse) afecta al estado futuro. El agente debe planificar a largo plazo; sus acciones presentes condicionan las opciones futuras.\n\n### 4. Estático/Dinámico → Dinámico\nEl entorno cambia mientras el agente delibera: otros jugadores hacen apuestas y se revelan nuevas cartas comunitarias. Evoluciona independientemente de si el agente actúa.\n\n### 5. Discreto/Continuo → Discreto\nLas acciones posibles son un conjunto finito y bien definido: apostar, igualar, subir o retirarse. Los estados del juego son enumerables.\n\n### Conclusión\nEl póker es **parcialmente observable, estocástico, secuencial, dinámico y discreto**: uno de los entornos más complejos para un agente, pues combina incertidumbre, planificación a largo plazo y adaptación a un entorno cambiante.",
      "keywords": [
        "agente inteligente",
        "PEAS",
        "observable",
        "estocástico",
        "secuencial",
        "dinámico",
        "discreto",
        "póker"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:940419420201e3ad110c8461b6bd6aefea48a0d03f495033ed6d1e515fa477b8",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "4b1384b9-cbaf-4870-9e11-3571fa231fe7",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "¿Cuál es el propósito de una matriz de confusión?",
      "explanation": "La matriz de confusión resume aciertos/errores del clasificador mostrando verdaderos positivos (TP), falsos positivos (FP), verdaderos negativos (TN) y falsos negativos (FN).\n\n✅ B. Mostrar los verdaderos o falsos positivos, junto con los verdaderos o falsos negativos.\n\nPor qué las otras no:\n\nA (falsa): no es “trazar etiquetas previstas”; es una tabla cruzando real vs predicho. \n\nC (falsa): correlación entre columnas es otra cosa (EDA / correlación), no evaluación de clasificación.\n\nD (falsa): estratificar train/test es una técnica de particionado; no es el propósito de la matriz de confusión.",
      "difficulty": 2,
      "options": [
        {
          "id": "83fb7751-47ef-40da-9b1b-bb5afe04d827",
          "text": "Trazar las etiquetas del conjunto de datos previsto."
        },
        {
          "id": "292f5cd8-d023-48d2-a34d-f679ca1fe4da",
          "text": "Mostrar los verdaderos o falsos positivos, junto con los verdaderos o falsos negativos."
        },
        {
          "id": "5640268c-59b9-4aaf-8852-fa7901cd378e",
          "text": "Mostrar la correlación entre dos columnas en el conjunto de datos."
        },
        {
          "id": "14cd7ca7-be54-4c82-9968-6d4364defda7",
          "text": "Estratificar las clases a través de conjuntos de datos de entrenamiento y pruebas."
        }
      ],
      "correctOptionIds": [
        "292f5cd8-d023-48d2-a34d-f679ca1fe4da"
      ],
      "createdBy": "",
      "contentHash": "sha256:ef84a031708bf562a243cbe0fa8ab4541f2fd2833e9a127be141917d9e5f9b81",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "4c275a50-f8c8-45ea-8537-ddff49761787",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones sobre un **clasificador de margen máximo** es **falsa**?",
      "explanation": "Es falso en el sentido general de SVM: con *soft margin* se toleran errores/violaciones del margen; no requiere separabilidad perfecta.",
      "difficulty": 2,
      "tags": [
        "svm",
        "maximo-margen",
        "soft-margin"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "El clasificador de margen máximo, implementado en SVM, tiene como objetivo encontrar un hiperplano que maximice el margen entre clases."
        },
        {
          "id": "b",
          "text": "El clasificador de margen máximo selecciona el hiperplano que mejor separa los datos de entrenamiento y maximiza la distancia (margen) a los puntos de datos más cercanos de cada clase."
        },
        {
          "id": "c",
          "text": "El clasificador de margen máximo está diseñado para mejorar el rendimiento de la generalización maximizando la separación entre clases, reduciendo el riesgo de sobreajuste."
        },
        {
          "id": "d",
          "text": "El clasificador de margen máximo siempre requiere que las clases sean perfectamente separables mediante un hiperplano."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:bb51f50fd1b46d4c2f7fd2d61d5138a4c4c0d58a1e7d5d5d1ea5b0f9f69d5615",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "4cd331ef-1ae3-4727-89da-adc705f92bb6",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "¿Cuáles de los siguientes son algoritmos de tipo **Boosting**?",
      "explanation": "**AdaBoost** (Adaptive Boosting) es un algoritmo clásico de boosting.",
      "difficulty": 1,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "TotalBoost."
        },
        {
          "id": "b",
          "text": "OptimalBoosting."
        },
        {
          "id": "c",
          "text": "AdaBoost."
        },
        {
          "id": "d",
          "text": "ClatsBoost."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:3b1116dbf72e62d3f9bf7a5ed2a94aeb19b1514e5d4d1a4c68f519fb0f7bcf2c",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "4da577b4-3d04-4d7a-a06a-9fd8ea34059a",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "Indica la afirmación correcta sobre el **error cuadrático medio (MSE)**:\n\nSeleccione una:",
      "explanation": "MSE = $\\frac{1}{n}\\sum (y-\\hat{y})^2$. Al cuadrar, penaliza más los errores grandes y es sensible a atípicos.",
      "difficulty": 1,
      "tags": [
        "mse",
        "metricas",
        "error"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "MSE mide el promedio de los cuadrados de los errores."
        },
        {
          "id": "b",
          "text": "MSE es una medida robusta que ignora los valores atípicos."
        },
        {
          "id": "c",
          "text": "MSE proporciona una medida lineal de la precisión del modelo."
        },
        {
          "id": "d",
          "text": "MSE es menos sensible a los errores grandes en comparación con MAE."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:46c42b407b4ea5a2e331387fcd51f0b86b015988f47e806fdc94e665e0cb9baf",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "4dd2ee86-fe01-4dd6-ad4c-7956262cb30f",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "Dispone de un conjunto de datos históricos del precio de venta de 10.000 viviendas y las 10 características más importantes resultantes del análisis de componentes principales. Debe desarrollar un modelo que prediga si una casa se venderá en uno de los siguientes rangos de precios igualmente distribuidos: 200-300k, 300-400k, 400-500k, 500-600k o 600-700k. Desea utilizar el enfoque algorítmico y evaluativo más simple. ¿Qué debe hacer?",
      "explanation": "✅ D. Clasificación con regresión, asignando el precio promedio del rango y usando RMSE.\n\nPor qué las otras no:\n\nA: one-vs-one + F1 es posible, pero no es “lo más simple” si puedes modelar el precio como variable numérica.\n\nB: multiclase + precisión es simplón, pero pierdes orden entre rangos y precisión puede engañar si hay desbalanceo.\n\nC: predecir precio exacto “entero” no es el objetivo real (te dan rangos) y MAE/RMSE aplican mejor si defines un objetivo numérico consistente; el promedio del rango es la opción más directa.",
      "difficulty": 3,
      "options": [
        {
          "id": "4b1c4a4c-012f-4089-9478-57b0f01f63e2",
          "text": "Definir una tarea de clasificación uno contra uno donde cada rango de precio es una etiqueta categórica. Utilizar la puntuación F1 como métrica de evaluación."
        },
        {
          "id": "ffee5d28-7082-4f9c-9828-2c9b234b7088",
          "text": "Definir una tarea de clasificación de varias clases en la que cada rango de precios sea una etiqueta categórica. Utilizar la precisión como métrica de evaluación."
        },
        {
          "id": "d4139b3c-a031-4db3-9fd6-8945c1a62bd8",
          "text": "Definir una tarea de regresión donde la etiqueta sea el precio de venta representado como un número entero. Utilizar el error absoluto medio como métrica."
        },
        {
          "id": "3cb70d04-b993-40ad-9d47-c7cf582e0786",
          "text": "Definir una tarea de regresión donde la etiqueta sea el promedio del rango de precios que corresponde al precio de venta de la casa representado como un número entero. Utilizar el error cuadrático medio de la raíz como la métrica."
        }
      ],
      "correctOptionIds": [
        "3cb70d04-b993-40ad-9d47-c7cf582e0786"
      ],
      "createdBy": "",
      "contentHash": "sha256:58440fd223aec50b073d8333b3ac792cbcb8b03a144c480998069b4670ecc5dd",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "4e5f0d64-051d-4027-81c8-4044a62345c7",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "Las **medidas de dispersión** tienen como objetivo:",
      "explanation": "Miden cuánto se **alejan los datos de la media o mediana**.",
      "difficulty": 1,
      "options": [
        {
          "id": "a",
          "text": "Definir la frecuencia"
        },
        {
          "id": "b",
          "text": "**Describir la variabilidad de los datos respecto a un valor central**"
        },
        {
          "id": "c",
          "text": "Construir diagramas"
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores"
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:0ad7b00a4ff76f6578932c9eec7065ca3bbd8a59d798daa72439635289bcc194",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "507dae12-6881-42a8-bd7d-6e532f977fc9",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "Cuál de las siguientes afirmaciones describe el aprendizaje automático.",
      "explanation": "Por qué las otras no:\n\nB (floja): suena a “IA/robots” en general; no define ML (podrías tener una máquina autónoma con reglas fijas y cero aprendizaje).\nC (falsa): eso es precisamente lo contrario de ML: compilar reglas para cubrir casos (enfoque basado en reglas).\nD (falsa): eso es programación clásica: instrucciones explícitas, no aprendizaje.",
      "difficulty": 2,
      "options": [
        {
          "id": "04e06575-c7f0-4469-801b-24197b6b8e5b",
          "text": "El estudio científico de algoritmos y modelos estadísticos para realizar tareas mediante el uso de inferencia en lugar de instrucciones."
        },
        {
          "id": "6215b973-2896-4f1f-a534-7206a68601d2",
          "text": "La creación de máquinas que pueden realizar tareas de manera autónoma mediante el aprendizaje."
        },
        {
          "id": "4bc99726-c33b-4ffa-a529-430a2610e1db",
          "text": "La compilación de un gran número de reglas estadísticas que cubre todas las posibles soluciones."
        },
        {
          "id": "e5840b0c-4a59-4428-9077-b68973ce106b",
          "text": "Un conjunto de instrucciones que describen cómo lograr un resultado deseado."
        }
      ],
      "correctOptionIds": [
        "04e06575-c7f0-4469-801b-24197b6b8e5b"
      ],
      "createdBy": "",
      "contentHash": "sha256:624f20fa2952460999684456639140830ad17292643ee85dc0de4b20e3c42cb9",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "51f068cb-b1ab-4906-bb65-489e345b85e4",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Cuál es el objetivo de la **regresión**?\n\nSeleccione una:",
      "explanation": "En regresión se modela/estima la relación entre variables (predictores) y una salida continua: $Y \\approx f(X)$.",
      "difficulty": 1,
      "tags": [
        "regresion",
        "objetivo"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Comprender el valor de los predictores X."
        },
        {
          "id": "b",
          "text": "Comprender el valor del error."
        },
        {
          "id": "c",
          "text": "Comprender el valor de las salidas Y."
        },
        {
          "id": "d",
          "text": "Comprender la relación entre el predictor X y la salida Y."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:cb502a6e4a6c62d5ed6640f5904a339071922ef4dbad3d3de0291afc7e2018cb",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "529c3dee-de07-4c21-98b2-800cc98eddec",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones describe correctamente una diferencia clave entre regresión y clasificación en el contexto del aprendizaje automático?",
      "explanation": "Regresión predice valores numéricos (normalmente continuos) y clasificación asigna clases/categorías discretas.",
      "difficulty": 1,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "La regresión se utiliza para predecir valores numéricos, mientras que la clasificación se utiliza para asignar instancias a categorías discretas."
        },
        {
          "id": "b",
          "text": "Tanto la regresión como la clasificación son métodos intercambiables y se pueden utilizar de manera indistinta para cualquier tipo de problema."
        },
        {
          "id": "c",
          "text": "En la regresión, la variable de salida es siempre categórica, mientras que en la clasificación puede ser numérica."
        },
        {
          "id": "d",
          "text": "La regresión se aplica únicamente a problemas de clasificación binaria, mientras que la clasificación puede manejar problemas con más de dos clases."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:9a5f1d2fb1c9f2fbb1a5c57d0e7cc2e4d66bf14d0b1d9a3e6a90e2f9d4a7c0b1",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "546e0086-d2da-4544-b53d-72c0edc84af6",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "¿Cuáles de las siguientes afirmaciones son **verdaderas** sobre los árboles de decisión?",
      "explanation": "A es falsa (también hay árboles de **regresión**). B es falsa (no se exige pureza total). Por tanto D es falsa. La poda suele mejorar la generalización frente a crecer y cortar por criterios simples.",
      "difficulty": 3,
      "tags": [
        "arboles-de-decision",
        "poda",
        "criterios-de-parada"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Solo se pueden utilizar para clasificación."
        },
        {
          "id": "b",
          "text": "Todas las hojas deben ser puras."
        },
        {
          "id": "c",
          "text": "La poda generalmente logra una mayor precisión en los datos de test que introducir un criterio de parada."
        },
        {
          "id": "d",
          "text": "Todas las anteriores son correctas."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:d78a8eea923b4eb78a54c22453e09b142be5fd135815341b16f3ef99573f12f9",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "5684a8de-a142-49b0-9240-3e0b9712ab44",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a0ee552f-68ca-4b05-bf4f-9e4f2edc904c",
      "type": "DESARROLLO",
      "prompt": "Imagina que formas parte del equipo de diseño de un robot aspirador. Enumera tres funcionalidades basadas en IA que incorporarías, las técnicas a utilizar y la utilidad del almacenamiento en la nube de sus datos para el cliente y para terceros.",
      "difficulty": 2,
      "tags": [
        "agentes",
        "robotica",
        "IoT"
      ],
      "modelAnswer": "## Robot Aspirador con IA\n\n### Funcionalidad 1: Navegación autónoma y mapeo (SLAM)\n- **Técnica**: SLAM (Simultaneous Localization and Mapping) con filtros de partículas. Construye un mapa 2D del hogar en tiempo real y calcula rutas de cobertura óptimas.\n- **Valor**: Limpieza sistemática sin zonas sin cubrir ni recorridos repetidos.\n\n### Funcionalidad 2: Detección y clasificación de obstáculos\n- **Técnica**: CNN (Red Neuronal Convolucional) entrenada para clasificar objetos (cables, juguetes, mascotas, umbrales) y decidir si esquivar o aspirar.\n- **Valor**: Evita daños al robot y a los objetos del hogar.\n\n### Funcionalidad 3: Optimización del plan de limpieza\n- **Técnica**: Aprendizaje por refuerzo (RL) que aprende qué zonas se ensucian más y a qué horas, para programar la limpieza de forma inteligente.\n- **Valor**: Eficiencia energética y mayor satisfacción del usuario.\n\n### Utilidad del almacenamiento en la nube\n\n**Para el cliente (usuario):**\n- Acceso al historial y mapa del hogar desde el móvil.\n- Actualizaciones automáticas del firmware que mejoran la navegación.\n- Alertas predictivas de fallos mecánicos antes de que ocurran.\n\n**Para terceros (fabricante):**\n- Análisis (datos anonimizados) de patrones de fallos para mejorar futuras versiones del hardware.\n- Identificar nuevas funcionalidades demandadas basándose en uso real.\n- Ofrecer servicios de mantenimiento predictivo y venta de recambios en el momento óptimo.",
      "keywords": [
        "SLAM",
        "CNN",
        "aprendizaje refuerzo",
        "robot aspirador",
        "cloud",
        "mantenimiento predictivo"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:a40028b4ba6717b1e2be2a240721a4c6093e207c21fb52235375026def27df11",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "57934f02-7e25-498c-a97b-fbf6ee581b88",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "Son técnicas para encontrar atributos redundantes:",
      "explanation": "En el tema se proponen **correlación** y **covarianza** para variables numéricas, y pruebas para variables nominales (p. ej., chi-cuadrado) para detectar dependencia/redudancia.",
      "difficulty": 2,
      "tags": [
        "redundancia",
        "correlacion",
        "covarianza"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Correlación."
        },
        {
          "id": "b",
          "text": "Covarianza."
        },
        {
          "id": "c",
          "text": "Prueba de datos nominales."
        },
        {
          "id": "d",
          "text": "Todas las anteriores."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:65ab58f4f3e8c58c0f969c62ddc5b4de4f9a3c0b5c2dc220de8993e28a4f55fe",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "583b68ff-f677-4731-89b3-2e78b2b226a4",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Cuáles de las siguientes métricas **no** se usan para evaluar los problemas de regresión?\n\nSeleccione una:",
      "explanation": "MAE, MSE y RMSE son métricas estándar en regresión. La RMSLE existe pero no es la más común/estándar en la mayoría de contextos de evaluación.",
      "difficulty": 1,
      "tags": [
        "metricas",
        "regresion",
        "mae",
        "mse",
        "rmse",
        "rmsle"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Error absoluto medio."
        },
        {
          "id": "b",
          "text": "Error cuadrático medio."
        },
        {
          "id": "c",
          "text": "Raíz del error cuadrático medio."
        },
        {
          "id": "d",
          "text": "Raíz del error logarítmico cuadrático."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:8e2ff12b6838556496fd77b71746cd066d7759c08050197f8aaa910a9cd75e24",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "5bbf69f6-ae45-4c4d-a695-2bde4b342231",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "¿Por qué es importante intentar llenar los valores faltantes?",
      "explanation": "La mayoría de algoritmos no gestionan bien (o directamente no aceptan) valores faltantes, por lo que puede condicionar el algoritmo aplicable y el rendimiento.",
      "difficulty": 2,
      "tags": [
        "datos-ausentes",
        "preprocesado"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "No es agradable ver un conjunto de datos con valores faltantes."
        },
        {
          "id": "b",
          "text": "Porque la muestra no es representativa."
        },
        {
          "id": "c",
          "text": "Puede afectar el método de aprendizaje automático elegido."
        },
        {
          "id": "d",
          "text": "Todas son verdaderas."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:7a78c02a1ea2d1c53bd5b56f07c1066e8e68c2e1c7b8aee2b5ccfad0f9ac6a3d",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "5cf5a6e1-78e0-4b15-94f5-2c24941a8839",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "DESARROLLO",
      "prompt": "El **Hospital del Valle Inglés** ha detectado que los pacientes con **EPOC** suelen volver a ser ingresados pasados **30 días** de su alta. Creen que estos reingresos se pueden evitar si identifican a los pacientes con **alto riesgo** y se toman medidas.\n\nTe preguntan:\n\n1. ¿Se puede resolver con **aprendizaje automático**?\n2. ¿Qué **tipo de problema** es?\n3. ¿Qué **técnicas** vistas en la asignatura aplicarías?\n\nJustifica tu respuesta.",
      "explanation": "La respuesta debe identificar que hay **etiqueta histórica** (reingreso sí/no) y por tanto es **supervisado**, y justificar elección de **métricas** y **modelos** adecuados al contexto clínico.",
      "difficulty": 3,
      "tags": [
        "introducción",
        "aprendizaje supervisado",
        "clasificación",
        "salud"
      ],
      "modelAnswer": "Sí, es un problema **típico** resoluble con *aprendizaje automático*, porque se quiere **predecir** si un paciente va a **reingresar** (o la **probabilidad** de reingreso) a partir de información disponible en el alta.\n\n## 1) Tipo de problema\n- Si definimos la variable objetivo como `reingresa_en_30_dias ∈ {sí, no}`, es un problema de **aprendizaje supervisado** de **clasificación binaria**.\n- Si en lugar de etiqueta queremos una **probabilidad** o un **riesgo continuo**, se puede ver como **regresión** (pero en práctica clínica se usa mucho clasificación/probabilidad).\n\n## 2) Qué datos haría falta (inputs y etiqueta)\n- **Etiqueta (y):** reingreso en ≤ 30 días (sí/no) a partir de registros hospitalarios.\n- **Características (X):** edad, sexo, historial de reingresos, comorbilidades (Charlson u otras), severidad EPOC, medicación, pruebas (SpO2, gasometría, etc.), duración de estancia, servicios, adherencia, visitas previas, factores socioeconómicos si existen, etc.\n\n## 3) Proceso (lo mínimo serio)\n1. **Definir** el objetivo y el punto de corte (30 días) y evitar *data leakage* (usar solo variables disponibles **antes** del alta).\n2. **Preprocesado:** tratar **valores ausentes** (imputación razonable), codificar categóricas (one-hot), normalizar si el modelo lo necesita.\n3. **Partición** train/test (o validación cruzada) manteniendo la proporción de reingresos.\n4. **Entrenar** varios modelos y comparar.\n5. **Evaluar** con métricas adecuadas (no solo accuracy):\n   - Si la clase de reingreso es minoritaria, interesan **recall/sensibilidad** para reingresos, **precision** y **AUC/ROC**.\n   - Mirar matriz de confusión y elegir umbral según coste clínico (un **FN** = paciente de riesgo no detectado).\n\n## 4) Técnicas/algoritmos aplicables (de la asignatura)\n- **Baseline interpretable:** *regresión logística*.\n- **Árboles de decisión** (interpretables pero propensos a overfitting).\n- **Random Forest** (bagging + selección aleatoria de variables): suele ir muy bien en datos tabulares y da **importancia de variables**.\n- **Boosting** (p. ej. AdaBoost/Gradient Boosting) para mejorar rendimiento, ajustando pesos a ejemplos difíciles.\n- **SVM** (especialmente con kernels si hay fronteras no lineales), aunque escala peor con datasets muy grandes.\n- **Naïve Bayes** como baseline rápido si hay muchas variables categóricas/texto.\n\n## 5) Conclusión\nEs un problema de **predicción de riesgo de reingreso**, por tanto **supervisado** y principalmente de **clasificación binaria**. La estrategia razonable es comparar modelos (logística/árboles/Random Forest/boosting/SVM), y elegir el que mejor balancee **sensibilidad** (detectar pacientes de riesgo) y **precision** (no saturar recursos) según el coste clínico.",
      "keywords": [
        "aprendizaje supervisado",
        "clasificación binaria",
        "reingreso",
        "data leakage",
        "desbalanceo",
        "precision",
        "recall",
        "ROC",
        "random forest",
        "boosting"
      ],
      "createdBy": "Luis",
      "sourcePackId": "c28801ab-40f1-46bb-938b-9d886992b1a0",
      "contentHash": "sha256:a6242bfb808c9b367b57bd91b87e37add48225e0f56dd36a802a2aafa1c7f4bd",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "5d96bfd9-95cb-4efd-81ff-86bf630101af",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "Son técnicas de escalado:",
      "explanation": "En escalado se incluyen tanto la **normalización** (p. ej., Min–Max) como la **estandarización** mediante **Z-score**.",
      "difficulty": 1,
      "tags": [
        "escalado",
        "z-score"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Normalización."
        },
        {
          "id": "b",
          "text": "Z-score."
        },
        {
          "id": "c",
          "text": "A y B son ciertas."
        },
        {
          "id": "d",
          "text": "A y B son falsas."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:0b2d1f4a6a8c9e1f2d3c4b5a69788796a5b4c3d2e1f0a9b8c7d6e5f4a3b2c1d0",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "5e3a1728-5469-4857-ade5-2cecfe8a1e5a",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "La **matriz de gráficos de dispersión** facilita:",
      "explanation": "La principal ventaja es la **visualización simultánea de relaciones entre pares de variables**.",
      "difficulty": 2,
      "options": [
        {
          "id": "a",
          "text": "Graficar tres atributos en un mismo gráfico"
        },
        {
          "id": "b",
          "text": "Emparejar datos numéricos y ver si una variable afecta a otra"
        },
        {
          "id": "c",
          "text": "**Comparar variables en una sola pantalla e identificar dependencias**"
        },
        {
          "id": "d",
          "text": "Asociar múltiples variables en un espacio pequeño"
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:fcb81a1797e94c3c8105162d59eeb09acf77255e5d7ffabbf79dbe3f281d3f08",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "5e8bbb04-c304-4f85-b42c-08919ef2285a",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "067cd1e1-d35d-47ca-9713-f712013ed237",
      "type": "DESARROLLO",
      "prompt": "La IA no solo requiere algoritmos precisos, sino también explicabilidad. Desarrolla al menos tres motivos para exigir esta característica y ejemplifica uno de ellos.",
      "difficulty": 2,
      "tags": [
        "etica",
        "XAI",
        "regulacion"
      ],
      "modelAnswer": "## Explicabilidad en IA (XAI)\n\nLa **explicabilidad** es la capacidad de un sistema de IA de justificar sus decisiones de forma comprensible para los humanos.\n\n### Motivo 1: Confianza y adopción\nLos usuarios (médicos, jueces, gestores de crédito) no adoptarán un sistema en el que no confían. Sin explicación, es imposible validar si la decisión es correcta y quién asume la responsabilidad. Un modelo de \"caja negra\" genera rechazo en entornos de alto impacto.\n\n### Motivo 2: Cumplimiento legal (RGPD)\nEl RGPD (Art. 22) otorga a los ciudadanos el derecho a no ser objeto de decisiones exclusivamente automatizadas y el derecho a recibir una explicación significativa de la lógica aplicada. Las empresas están legalmente obligadas a poder explicar las decisiones que afectan a personas.\n\n### Motivo 3: Detección y corrección de sesgos\nSin explicabilidad, los sesgos en los datos de entrenamiento se perpetúan de forma invisible. Herramientas como SHAP o LIME permiten auditar los modelos y detectar variables discriminatorias.\n\n### Motivo 4: Mejora del modelo\nLa explicabilidad permite al equipo técnico identificar qué características están usando los modelos para predecir, facilitando la iteración y mejora del sistema.\n\n### Ejemplo ilustrativo (Motivo 3)\nAmazon desarrolló un sistema de selección de CVs que penalizaba a las candidatas. El modelo había aprendido el sesgo histórico de contratar más hombres. Solo gracias al análisis de importancia de variables (explicabilidad) se detectó que el género actuaba como variable influyente, lo que permitió corregir y retirar el sistema.",
      "keywords": [
        "explicabilidad",
        "XAI",
        "RGPD",
        "LIME",
        "SHAP",
        "sesgo",
        "confianza",
        "caja negra"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:d833b1452d61bfaaaafd1ae2627ecb3f8d3bcc8054e2b01ffe5deadb8a534f47",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "5f0e8e0d-a635-402a-88a6-4514e2562709",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "¿Qué puede aprender examinando las estadísticas de sus datos?",
      "explanation": "Sí. Mirar estadísticas (mínimos/máximos, cuartiles, dispersión, boxplots, etc.) sirve para identificar anomalías/valores atípicos o cosas raras en los datos.\n\nPor qué las otras no:\n\nB (falsa): que estén “formateados correctamente” es más de tipos/validación de esquema; las estadísticas te ayudan a ver rangos y rarezas, no a certificar formato.\n\nC (falsa): las estadísticas te ayudan a detectar valores atípicos, pero no “eliminarlos” (eso ya es una decisión/acción de limpieza).\n\nD (falsa): completar datos faltantes es imputación, no algo que “aprendas” solo mirando estadísticas (primero los detectas).",
      "difficulty": 2,
      "options": [
        {
          "id": "86c249dd-e806-4dad-ae8b-6a44960c3d1d",
          "text": "Identificación de anomalías en los datos."
        },
        {
          "id": "92bb1867-3e92-4f67-b2ea-ea0c436ed541",
          "text": "Verificación de que los datos estén formateados correctamente."
        },
        {
          "id": "2f561093-5291-4b55-a2d2-d10efcef601d",
          "text": "Eliminación de valores atípicos."
        },
        {
          "id": "3af7176c-5aa7-45da-a168-13486cb10c46",
          "text": "Compleción de datos faltantes."
        }
      ],
      "correctOptionIds": [
        "86c249dd-e806-4dad-ae8b-6a44960c3d1d"
      ],
      "createdBy": "",
      "contentHash": "sha256:aa9ecaad79d976c60b45c8bd1b321e6123a2742d4b0c96ee328e00c67c6b9f7b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "6003d382-3662-4147-9f03-652c70e34fc7",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "La discretización de variables:",
      "explanation": "Discretizar consiste en convertir una variable numérica continua en **intervalos (bins)** para tratarla como categórica en el modelo.",
      "difficulty": 2,
      "tags": [
        "discretizacion",
        "naive-bayes"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Es una técnica que se aplica para utilizar el clasificador Naïve Bayes con variables numéricas."
        },
        {
          "id": "b",
          "text": "Es ideal cuando hay grandes cantidades de datos."
        },
        {
          "id": "c",
          "text": "Funciona mejor cuando hay pocos datos."
        },
        {
          "id": "d",
          "text": "A y B son correctas."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:2b3c4d5e6f708192a3b4c5d6e7f8091a2b3c4d5e6f708192a3b4c5d6e7f8091a",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "600c6185-3843-4d7d-a6e1-cc0c35c14113",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "DESARROLLO",
      "prompt": "### El Tiempo en Australia (análisis completo)\n\nEn el **Anexo** final encontrarás la descripción del problema (**El Tiempo en Australia**) y el conjunto de datos asociado. Debes realizar un **análisis completo**, usando los conocimientos de la asignatura.\n\n**Condiciones:**\n- Responde **sin escribir código**.\n- Cualquier aclaración o suposición que hagas sobre el conjunto de datos debe quedar **escrita**.\n- La respuesta debe ser una **explicación y/o justificación** a las cuestiones planteadas (no basta con listar pasos).\n\n> Origen: **Examen anterior** (UNIR, ordinaria **07–12/03/2025**, **Modelo E**).",
      "explanation": "Respuesta tipo 'plantilla de examen': definir objetivo, hacer EDA, justificar preprocesado, proponer modelos del temario y explicar evaluación y tuning. Adaptable al detalle del Anexo.",
      "difficulty": 4,
      "tags": [
        "examen anterior",
        "análisis completo",
        "pipeline ML"
      ],
      "modelAnswer": "## Supuesto razonable (adaptable al Anexo)\nUn dataset típico de “tiempo en Australia” suele contener:\n- Variables meteorológicas (temperaturas, humedad, viento, presión, lluvia, etc.).\n- Variables temporales (fecha) y espaciales (localización/ciudad).\n- Un objetivo (`y`) que suele ser:\n  - **Clasificación**: “¿lloverá mañana?” (`Sí/No`) o similar.\n  - **Regresión**: “¿cuánta lluvia habrá?” (`mm`) o un índice.\n\nA partir de ahí, el **tipo de problema** se decide por el objetivo del Anexo.\n\n---\n\n## 1) Entender el objetivo y el “coste del error”\n- Si el objetivo es **predecir lluvia** (evento raro en muchos lugares), suele interesar **recall** (no perder lluvias) o un equilibrio con **precision** (evitar falsas alarmas), dependiendo del uso (agricultura, logística, etc.).\n- Si el objetivo es **cantidad de lluvia**, interesa `MAE/RMSE` y robustez ante outliers.\n\nEsto define métricas, split y qué significa “mejor”.\n\n---\n\n## 2) EDA (Tema 2): lo mínimo que hay que mirar sí o sí\n- **Distribuciones** de variables numéricas (histogramas/boxplots) para detectar:\n  - Outliers (p. ej. rachas de lluvia extrema, vientos).\n  - Variables con rango extraño (errores de sensor).\n- **Correlaciones** y relaciones útiles:\n  - Humedad ↔ probabilidad de lluvia.\n  - Presión ↔ cambios meteorológicos.\n- **Análisis temporal**:\n  - Estacionalidad (mes/estación).\n  - Tendencias o cambios por año.\n- **Balance de clases** (si es clasificación):\n  - % de días con lluvia vs sin lluvia.\n\n---\n\n## 3) Limpieza y preparación (Tema 3)\n### a) Datos ausentes\n- Medir **% de missing** por variable y por localización/fecha.\n- Estrategias:\n  - Si la variable es poco relevante y muy incompleta → **eliminar**.\n  - Si es relevante → **imputar**:\n    - Numéricas: mediana por estación/localización, KNN, o imputación por modelo.\n    - Categóricas (dirección del viento): modo o “desconocido”.\n\n**Justificación clave:** imputar sin pensar puede introducir sesgo (p. ej. imputar con media global rompe estacionalidad).\n\n### b) Variables categóricas\n- `Location`, direcciones de viento, etc. → **one-hot** (o codificación ordinal si procede).\n- Cuidado con **alta cardinalidad** (muchas ciudades): puede inflar dimensionalidad.\n\n### c) Escalado\n- Necesario para **SVM** y modelos basados en distancia (estandarización).\n- No estrictamente necesario para árboles/Random Forest.\n\n### d) Split correcto\nSi hay fecha, **evitar leakage temporal**:\n- Entrenar con periodo anterior, test con periodo posterior (validación tipo “forward chaining”).\n- No mezclar aleatoriamente si el Anexo implica predicción futura real.\n\n---\n\n## 4) Modelos candidatos (según el temario)\n### Baselines (siempre)\n- Clasificación: baseline “siempre No” (o la clase mayoritaria).\n- Regresión: predecir la media/mediana histórica (o por estación).\n\n### Modelos del temario\n- **Árbol de decisión** (Tema 6): interpretable, capta no linealidad, sensible a overfitting → regularizar (profundidad, mínimo de muestras).\n- **Random Forest** (Tema 10): suele funcionar muy bien como “caballo de batalla”.\n- **SVM** (Tema 7): buena frontera con escalado, tuning de `C` y kernel.\n- **Naïve Bayes** (Tema 8): rápido, baseline probabilístico (mejor si variables discretizadas o independencia aproximada).\n- **Ensembles** (Tema 9): bagging/boosting para mejorar estabilidad y rendimiento.\n\n---\n\n## 5) Evaluación (Temas 4 y 5)\n### Si es clasificación\n- Matriz de confusión.\n- `precision`, `recall`, `F1` (y elegir el foco según coste del error).\n- Si hay desbalance: `accuracy` puede engañar → mejor `F1` o `recall` de la clase positiva.\n\n### Si es regresión\n- `MAE` (más interpretable), `RMSE` (penaliza errores grandes), `R²` como complemento.\n\n### Validación\n- Evitar una sola partición: **validación cruzada** o validación temporal si procede.\n\n---\n\n## 6) Ajuste y selección final (Tema 11)\n- Definir qué hiperparámetros se tunearían y por qué:\n  - Árboles/RF: `max_depth`, `min_samples_leaf`, `n_estimators`, `max_features`.\n  - SVM: `C`, `gamma`, kernel.\n- Elegir el modelo final por:\n  - Métrica objetivo (p. ej. maximizar recall de lluvia).\n  - Estabilidad (varianza) y robustez (Tema 1 + Tema 9/10).\n  - Interpretabilidad mínima (importancia de variables en RF, análisis de errores).\n\n---\n\n## 7) Resultado que esperaría entregar (sin código)\n1. **Definición del objetivo** y del tipo de problema (clasificación/regresión).\n2. **Resumen EDA**: variables clave, estacionalidad, missing, outliers, balance.\n3. **Decisiones de preprocesado** justificadas.\n4. **Comparativa razonada** de 2–3 modelos del temario.\n5. **Métricas** elegidas y por qué.\n6. **Recomendación final** + riesgos (leakage temporal, deriva, desbalance).\n\nCon eso, cubres el “análisis completo” sin vender humo y alineado con el temario.",
      "keywords": [
        "EDA",
        "datos ausentes",
        "clasificación",
        "regresión",
        "validación temporal",
        "Random Forest",
        "SVM",
        "métricas"
      ],
      "createdBy": "Luis",
      "sourcePackId": "83ef5676-1384-45f7-804a-20c7d1f4690b",
      "contentHash": "sha256:a22909816b8c119ec90a2c38e9d9133ae6fcc85373a2e7c7d35a5f468274509f",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "60919b47-8111-4e3d-a2f7-9497624c1835",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a1245be8-e251-419a-bcdc-c822fd0e4750",
      "type": "DESARROLLO",
      "prompt": "Explica cómo la observación y el razonamiento son cruciales para obtener conocimiento en ciencia, y proporciona un ejemplo de cómo estos métodos se aplican en un estudio de inteligencia artificial.",
      "difficulty": 2,
      "tags": [
        "metodologia",
        "ciencia"
      ],
      "modelAnswer": "## Observación y Razonamiento en la Ciencia\n\n### La Observación\nLa observación es el punto de partida del método científico. Para ser válida debe ser:\n- **Repetible**: Otros investigadores deben obtener los mismos datos en condiciones similares.\n- **Objetiva**: Libre de interpretaciones subjetivas previas.\n- **Documentada**: Registrada con precisión para su análisis posterior.\n\n### El Razonamiento\nA partir de observaciones, el científico aplica:\n- **Razonamiento inductivo**: De observaciones específicas → generalización (hipótesis).\n- **Razonamiento deductivo**: De teorías generales → predicciones concretas.\n- **Ciclo hipotético-deductivo**: Formular hipótesis → diseñar experimentos → confirmar o refutar.\n\n### Ejemplo en IA: Detección de fraude bancario\n1. **Observación**: Se recopilan 12 meses de transacciones etiquetadas como fraudulentas o legítimas.\n2. **Razonamiento inductivo**: Las transacciones fraudulentas ocurren frecuentemente en horarios inusuales e importes atípicos → Hipótesis: estas variables son predictoras clave.\n3. **Verificación experimental**: Se entrena un clasificador y se evalúa si las variables identificadas predicen el fraude mejor que el azar (AUC-ROC).\n4. **Conclusión**: Si el modelo valida la hipótesis, se incorpora al sistema de detección en producción.",
      "keywords": [
        "observación",
        "razonamiento inductivo",
        "deductivo",
        "método científico",
        "hipótesis",
        "AUC-ROC"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:204db91ab9c7c77ed1af6338d91c604a25863b35b2efb51e8fe28fe07d5e7b1b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "6115535f-278a-4c76-9ee6-9978c9bea919",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "La expansión en forma de polinomios:",
      "explanation": "Las características polinómicas (o un *kernel* polinómico) permiten modelar fronteras no lineales al trabajar en un espacio de mayor dimensión (explícito o implícito).",
      "difficulty": 2,
      "tags": [
        "svm",
        "kernel",
        "polinomio",
        "no-linealidad"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Permite capturar relaciones no lineales entre las características originales al mapear los datos a un espacio de características de mayor dimensión."
        },
        {
          "id": "b",
          "text": "La expansión en forma de polinomios en SVM solo se puede realizar utilizando un *kernel* lineal."
        },
        {
          "id": "c",
          "text": "La expansión en forma de polinomios en SVM siempre mejora el rendimiento del modelo en comparación con un enfoque lineal."
        },
        {
          "id": "d",
          "text": "La expansión en forma de polinomios en SVM transforma automáticamente el espacio de características original a un espacio de mayor dimensión sin introducir complejidad adicional."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:2b7a6c5d4e3f2a1b0c9d8e7f6a5b4c3d2e1f0a9b8c7d6e5f4a3b2c1d0e9f8a7b",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "61608da2-0fee-470c-a672-c190744694bd",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "Indica la afirmación correcta sobre el **Error absoluto medio (MAE)**:\n\nSeleccione una:",
      "explanation": "El MAE es la media de $|y-\\hat{y}|$ (penalización lineal). No penaliza cuadráticamente (eso es MSE/RMSE) y no es “insensible” a atípicos, aunque suele ser más robusto que MSE.",
      "difficulty": 1,
      "tags": [
        "mae",
        "metricas",
        "error"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "MAE mide la diferencia promedio entre predicciones y valores reales."
        },
        {
          "id": "b",
          "text": "MAE es una medida de la precisión del modelo de regresión."
        },
        {
          "id": "c",
          "text": "MAE penaliza de manera cuadrática las diferencias entre predicciones y valores reales."
        },
        {
          "id": "d",
          "text": "MAE es insensible a los valores atípicos en los datos."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:f676b9d05a18d598710a7767429594c0f26121c3def0d589933a824e62ef34cd",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "62a4ced2-c6c1-4c98-8468-cbd21bc150cd",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones describe **incorrectamente** los árboles de decisión?",
      "explanation": "Es incorrecta porque los árboles de decisión son un método de **aprendizaje supervisado** (clasificación/regresión).",
      "difficulty": 2,
      "tags": [
        "arboles-de-decision",
        "supervisado",
        "conceptos-basicos"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Los árboles de decisión son un tipo de modelo de aprendizaje no supervisado."
        },
        {
          "id": "b",
          "text": "Los árboles de decisión pueden manejar tanto variables numéricas como categóricas, como características de entrada."
        },
        {
          "id": "c",
          "text": "Los árboles de decisión dividen el espacio de características en regiones que representan decisiones basadas en reglas if-else"
        },
        {
          "id": "d",
          "text": "Los árboles de decisión son propensos al sobreajuste cuando se construyen con poca profundidad y se les permite crecer sin restricciones."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:1275edeb8fb429e7dbd7ae16a09082130431cddfcdd32606a8bc09821d56b484",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "62dae287-a932-485d-9f1f-c0ac1ad2dcae",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "¿Cuál es una interpretación correcta del coeficiente de correlación?",
      "explanation": "`r = -1` indica relación **inversa perfecta** entre variables.",
      "difficulty": 1,
      "options": [
        {
          "id": "a",
          "text": "Si es -1, la correlación es positiva perfecta"
        },
        {
          "id": "b",
          "text": "**Si es -1, la correlación es negativa perfecta**"
        },
        {
          "id": "c",
          "text": "Si es 1, la correlación es positiva moderada"
        },
        {
          "id": "d",
          "text": "Si es 1, la correlación es fuerte"
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:95756ea9caf7aa00acd7a72446f9174694052741c0506e327b72fe72adbb3a9f",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "64729763-b42b-42d4-adc6-569b75f0019a",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "¿Por qué el clasificador Naive Bayes es llamado ingenuo?",
      "explanation": "asume independencia entre variables/características, y por eso se llama “naïve/ingenuo”.\nMatiz: lo “ingenuo” no es “igualdad de importancia”, sino la independencia (condicional) de las variables dado el valor de la clase.\n✅ B. Porque asume (independencia condicional) entre las variables/características.\n\nPor qué las otras no:\n\nA (falsa): que funcione bien con pocos datos puede pasar en algunos casos, pero no es por eso por lo que se llama “ingenuo”. \n\nC (falsa): no tiene sentido: las características no “son iguales a la clase objetivo”.\n\nD (falsa): sí hay una correcta: la independencia (condicional) es literalmente el motivo del nombre.\n",
      "difficulty": 2,
      "options": [
        {
          "id": "d4642165-6d6d-4d41-bfe5-dcb0c47d87fb",
          "text": "Porque obtiene buenos resultados con pocas instancias de datos."
        },
        {
          "id": "b390f80c-1b3c-409d-80f9-273eec650c84",
          "text": "Porque asume igualdad de importancia e independencia entre todas las variables."
        },
        {
          "id": "d1e3bd7e-60d3-46e6-8778-6d3cf8ee9234",
          "text": "Porque considera que las características son todas iguales a la clase objetivo."
        },
        {
          "id": "ef714a4a-62bd-4aa9-a70d-c01992de5bc4",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "b390f80c-1b3c-409d-80f9-273eec650c84"
      ],
      "createdBy": "",
      "contentHash": "sha256:00a90cf57ce77acc1440dc3132a5e5ff6dfa843efada9e433c2f699983197434",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "64c0a5a6-bd49-42a1-85a9-48e7cef30da6",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "388275e1-be5b-44fd-8fbd-52591fd74159",
      "type": "TEST",
      "prompt": "¿Cuál de estas políticas de **prompting** reduce alucinaciones en RAG?",
      "explanation": "El *grounding* estricto + abstención (“No consta”) evita que el modelo rellene huecos inventando cuando el contexto recuperado no soporta la respuesta.",
      "difficulty": 2,
      "tags": [
        "prompting",
        "alucinaciones",
        "abstencion",
        "grounding",
        "rag"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "«Responde con tu conocimiento general si no hay contexto»."
        },
        {
          "id": "b",
          "text": "«Responde solo con el contexto. Si no alcanza, di “No consta” y solicita ampliar el corpus»."
        },
        {
          "id": "c",
          "text": "«Siempre da una respuesta completa; evita decir “no sé”»."
        },
        {
          "id": "d",
          "text": "«Añade ejemplos creativos aunque no estén citados»."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:0dc5f9249d268c23f7d9956f7f8e8b8c7a2e8a39a9f6f9c1f07f2b67d26c7393",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "673ad883-a0cf-421d-a74b-6f2e640e8db7",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "502e9489-f902-45a4-8614-1f853b90f62f",
      "type": "DESARROLLO",
      "prompt": "Explica las etapas del ciclo de vida de un proyecto de inteligencia artificial. ¿Qué métricas utilizarías para evaluar el éxito del proyecto?",
      "difficulty": 2,
      "tags": [
        "gestion-proyectos",
        "ciclo-vida"
      ],
      "modelAnswer": "## Ciclo de Vida de un Proyecto de IA\n\n### Etapas\n\n1. **Definición del problema y objetivos**: Identificar el problema de negocio, traducirlo en problema de IA y fijar el criterio de éxito.\n2. **Adquisición y exploración de datos (EDA)**: Recopilar datos, explorar distribuciones, detectar nulos, outliers y desbalances de clase.\n3. **Preparación de datos**: Limpieza, normalización, codificación, ingeniería de características, partición train/validation/test.\n4. **Selección y diseño del modelo**: Elegir el tipo de modelo adecuado y experimentar con algoritmos.\n5. **Entrenamiento y ajuste de hiperparámetros**: Entrenamiento y optimización (Grid Search, Bayesian Optimization).\n6. **Evaluación y validación**: Evaluar sobre el conjunto de prueba. Aplicar validación cruzada.\n7. **Despliegue**: Integrar el modelo en producción (API REST, Docker, plataforma cloud).\n8. **Monitorización y mantenimiento**: Detectar data drift y reentrenar periódicamente.\n\n### Métricas de evaluación del éxito\n\n- **Técnicas de ML**: Accuracy, Precisión, Recall, F1-score, AUC-ROC (clasificación); RMSE, MAE (regresión).\n- **De negocio**: ROI del proyecto, reducción de costes, aumento de ingresos, tiempo ahorrado.\n- **Operativas**: Latencia de inferencia, uptime del servicio, coste por predicción.",
      "keywords": [
        "ciclo vida IA",
        "EDA",
        "feature engineering",
        "despliegue",
        "data drift",
        "F1-score",
        "ROI",
        "validación cruzada"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:fcd0bacab530744e07081e14af92a410426ea8724a5488544d373fbc22cc6d99",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "68a65395-8b74-4adb-9851-7a46f15e5a84",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "388275e1-be5b-44fd-8fbd-52591fd74159",
      "type": "TEST",
      "prompt": "En un **corpus bilingüe**, usas un modelo de *embeddings* monolingüe. ¿Qué efecto esperas?",
      "explanation": "Un embedder monolingüe no alinea bien significados entre idiomas: baja el *recall/precision* en el idioma no cubierto y aparecen matches erráticos.",
      "difficulty": 2,
      "tags": [
        "embeddings",
        "multilingue",
        "retrieval",
        "calidad",
        "rag"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Mejor *recall* en ambos idiomas."
        },
        {
          "id": "b",
          "text": "Pérdida de calidad en el idioma no cubierto y emparejamientos inconsistentes."
        },
        {
          "id": "c",
          "text": "No cambia nada si el LLM es multilingüe."
        },
        {
          "id": "d",
          "text": "Solo afecta la generación, no la recuperación."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:0d0a49e7b2e9a40a8f4f6a843e4e0a9ccf3e08c2c3a1a5f5f7e33dd0d2d6d62b",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "69932326-4a46-4046-bc70-08c324645940",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones sobre las máquinas de vector de soporte (SVM) es **falsa**?",
      "explanation": "Es falso que *siempre* requieran separabilidad lineal: con *soft margin* se permiten violaciones del margen y con *kernels* se puede lograr separabilidad en un espacio transformado.",
      "difficulty": 2,
      "tags": [
        "svm",
        "conceptos",
        "separabilidad",
        "kernel",
        "soft-margin"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Las SVM son eficaces para resolver problemas de clasificación binaria y también se pueden extender a problemas de regresión."
        },
        {
          "id": "b",
          "text": "El objetivo principal de las SVM es encontrar un hiperplano de separación óptimo que maximice el margen entre las clases en el espacio de características."
        },
        {
          "id": "c",
          "text": "Las SVM pueden manejar eficazmente conjuntos de datos de alta dimensionalidad y son robustas frente al sobreajuste cuando se utilizan técnicas como el margen suave y la optimización convexa."
        },
        {
          "id": "d",
          "text": "Las SVM siempre requieren que los datos sean linealmente separables en el espacio de características."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:39c7fcb929332dc8bfc200a4d39b91775f88da24690a603b5c4d9a4cd0c71d57",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "6b42a671-e8f9-45db-bdf7-be4756d6dede",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Un científico de datos está desarrollando un modelo de clasificación utilizando **Naïve Bayes** para predecir si un correo electrónico es **spam** o **no spam**. Ha calculado la tabla de verosimilitud para dos palabras clave: **\"oferta\"** y **\"urgente\"**. Los resultados se presentan a continuación:\n\n| Clase    | oferta (Sí) | oferta (No) | urgente (Sí) | urgente (No) |\n|----------|-------------|-------------|--------------|--------------|\n| spam     | 4/20        | 16/20       | 10/20        | 10/20        |\n| No spam  | 1/80        | 79/80       | 1/80         | 79/80        |\n\nBasándose en esta información y haciendo uso de la fórmula de la probabilidad a posteriori:\n\n`P(A|B) = P(A) · P(B|A) / P(B)`\n\n¿Cuál es la probabilidad a posteriori de que un correo electrónico sea **spam** dado que contiene la palabra clave **\"urgente\"**?",
      "explanation": "✅ 0.9 (aprox. 0.909)\n\nPor qué:\nDel enunciado:\n\n𝑃\n(\nspam\n)\n=\n20\n/\n100\nP(spam)=20/100, \n𝑃\n(\nno spam\n)\n=\n80\n/\n100\nP(no spam)=80/100\n\n𝑃\n(\nurgente\n∣\nspam\n)\n=\n10\n/\n20\nP(urgente∣spam)=10/20\n\n𝑃\n(\nurgente\n∣\nno spam\n)\n=\n1\n/\n80\nP(urgente∣no spam)=1/80 \n\nExamen_TAA_2024_ModeloB\n\nEntonces\n\n𝑃\n(\nurgente\n)\n=\n0.2\n⋅\n0.5\n+\n0.8\n⋅\n0.0125\n=\n0.11\nP(urgente)=0.2⋅0.5+0.8⋅0.0125=0.11\n\n𝑃\n(\nspam\n∣\nurgente\n)\n=\n(\n0.2\n⋅\n0.5\n)\n/\n0.11\n≈\n0.909\n⇒\n0.9\nP(spam∣urgente)=(0.2⋅0.5)/0.11≈0.909⇒0.9\n\nPor qué las otras no:\nA/B/C no cuadran: B y C son >1 (imposible como probabilidad) y A se queda demasiado baja para los números de la tabla.",
      "difficulty": 4,
      "options": [
        {
          "id": "9b0cd367-1a07-4a03-ae5a-1a39441b33dd",
          "text": "0.12"
        },
        {
          "id": "0667c9d3-c3d0-4da9-80d4-a14038919b42",
          "text": "3.63"
        },
        {
          "id": "72e2e0a7-25f0-4d6c-9794-0d8d2c5a70d4",
          "text": "4.65"
        },
        {
          "id": "98a5dbd8-fbc5-4870-a10d-9a0cb1d595e3",
          "text": "0.9"
        }
      ],
      "correctOptionIds": [
        "98a5dbd8-fbc5-4870-a10d-9a0cb1d595e3"
      ],
      "createdBy": "",
      "contentHash": "sha256:a4c28559768939b0c209349590eb1caeaa4086762851bab5e60b1e7282832990",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "6b4c007e-263e-449d-8ca0-e9e43a935544",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "El Out-of-Bag (OOB) error es una métrica utilizada en el método de Bagging que permite:",
      "explanation": "✅ C. Estimar la precisión de un modelo en el conjunto de prueba, utilizando únicamente las muestras que no se utilizaron en el proceso de entrenamiento.\n\nPor qué las otras no:\n\nA: OOB no es validación cruzada. \n\nB: eso describe más el bootstrap/variabilidad, pero OOB como métrica es la estimación usando “los no seleccionados”. \n\nD: suena a boosting/idea de sesgo, pero OOB no “reduce sesgo” por agregación; es una estimación de error.",
      "difficulty": 2,
      "options": [
        {
          "id": "5cd3e678-2cf9-404a-ba09-bc034ca9bb1d",
          "text": "Evaluar el rendimiento de un modelo en el conjunto de datos de entrenamiento, utilizando la técnica de validación cruzada."
        },
        {
          "id": "1a08f93c-5d14-4e48-b12d-42cc0d63646b",
          "text": "Medir la varianza del modelo mediante la generación de múltiples conjuntos de entrenamiento a partir de reemplazos aleatorios del conjunto de datos original."
        },
        {
          "id": "ade600e1-4b98-4037-ad9f-19d043e33324",
          "text": "Estimar la precisión de un modelo en el conjunto de prueba, utilizando únicamente las muestras que no se utilizaron en el proceso de entrenamiento."
        },
        {
          "id": "4b6cc99d-14b6-4206-9006-87d6d5ec7786",
          "text": "Reducir el sesgo en la estimación de un modelo mediante la agregación de múltiples clasificadores débiles."
        }
      ],
      "correctOptionIds": [
        "ade600e1-4b98-4037-ad9f-19d043e33324"
      ],
      "createdBy": "",
      "contentHash": "sha256:163b660c1a6b0144433e19f09148c882303b838f86b417f5ecc947f814f379b9",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "6b7818dd-7f9a-4d0b-887c-7ddda9c72f26",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a0ee552f-68ca-4b05-bf4f-9e4f2edc904c",
      "type": "DESARROLLO",
      "prompt": "¿Por qué es importante el contexto en el funcionamiento de los agentes inteligentes y cómo influye en su desempeño? Proporciona un ejemplo práctico.",
      "difficulty": 2,
      "tags": [
        "agentes",
        "contexto"
      ],
      "modelAnswer": "## Importancia del Contexto en los Agentes Inteligentes\n\n### Qué es el contexto\nEl **contexto** es el conjunto de información sobre el entorno, el estado actual y las circunstancias relevantes que rodean al agente: localización, tiempo, historial de interacciones, condiciones ambientales, estado de otros agentes.\n\n### Por qué es fundamental\n\n1. **Determina la acción apropiada**: La misma percepción puede requerir respuestas distintas según el contexto.\n2. **Permite la adaptación**: El agente adapta su comportamiento sin necesidad de reprogramación.\n3. **Mejora la eficiencia**: Permite priorizar acciones relevantes y descartar las irrelevantes.\n4. **Habilita la personalización**: En agentes conversacionales y recomendadores, el contexto del usuario es esencial.\n\n### Ejemplo práctico: Asistente virtual (Siri / Alexa)\n\nCuando el usuario pregunta \"¿Qué tiempo hace?\", la respuesta depende totalmente del contexto:\n\n- **Sin contexto**: El agente pide aclaración sobre la ciudad.\n- **Con contexto de localización GPS**: Responde con el tiempo en la ciudad actual del usuario.\n- **Con contexto temporal + calendario**: Si el usuario tiene un evento mañana en Madrid, el agente informa proactivamente del tiempo en Madrid mañana sin que el usuario lo solicite.\n\nEl desempeño mejora radicalmente al incorporar contexto: respuestas más precisas, relevantes y personalizadas.",
      "keywords": [
        "contexto",
        "agente inteligente",
        "adaptación",
        "personalización",
        "asistente virtual"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:5c4a761741c193747028e122481a9bf48550ba936eac34029e42f8f0dc1853d1",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "6b80f761-8d1b-430d-bd66-a337116ad209",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "e50ab4a3-574f-4002-ac5f-e5912c4cf9d3",
      "type": "DESARROLLO",
      "prompt": "Indica distintas formas (al menos 3) en las que los servicios cognitivos de IBM Watson pueden ayudar a un proyecto de aprendizaje automático con Big Data.",
      "difficulty": 2,
      "tags": [
        "sistemas-cognitivos",
        "big-data",
        "herramientas"
      ],
      "modelAnswer": "## IBM Watson para Proyectos de ML con Big Data\n\n### 1. Watson Natural Language Understanding — PLN\nAnaliza grandes volúmenes de texto no estructurado (reseñas, correos, noticias) extrayendo entidades, relaciones, sentimiento y conceptos. Transforma texto crudo en **features estructuradas** listas para alimentar modelos de clasificación o clustering.\n\n*Ejemplo*: Analizar millones de opiniones de clientes para detectar patrones de insatisfacción y predecir churn.\n\n### 2. Watson Studio / AutoAI — Machine Learning Automatizado\nIntegra **AutoML** que automatiza la selección del mejor modelo, la ingeniería de características y la optimización de hiperparámetros sobre grandes datasets. Reduce el tiempo de desarrollo sin expertise profundo en ML.\n\n*Ejemplo*: A partir de un dataset de transacciones financieras, AutoAI identifica y entrena automáticamente el mejor clasificador de fraude.\n\n### 3. Watson Machine Learning — Despliegue y Monitorización a Escala\nPermite entrenar, desplegar y monitorizar modelos a escala sobre grandes volúmenes de datos, con integración nativa con Spark y Hadoop. Facilita el despliegue en producción y la detección automática de data drift.\n\n*Ejemplo*: Entrenamiento de un modelo de mantenimiento predictivo sobre petabytes de datos de sensores industriales.\n\n### 4. Watson Discovery — Búsqueda Inteligente\nIndexa y analiza repositorios de documentos (papers, contratos) permitiendo búsquedas semánticas. Acelera enormemente la revisión del estado del arte en proyectos de investigación.\n\n### 5. Watson Visual Recognition — Visión Artificial\nAPI de clasificación de imágenes para integrar en pipelines de visión por computador sobre grandes datasets (imágenes médicas, control de calidad industrial).",
      "keywords": [
        "IBM Watson",
        "Big Data",
        "NLP",
        "AutoML",
        "Watson Studio",
        "Watson Discovery",
        "servicios cognitivos"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:e06b30546b4e2416465f6f2c6e388fa0dfc286c490eec871b9a686c81fd7c9ee",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "6c2e40f0-2a37-4c61-b33b-0928b46e8061",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "La curva ROC mide:",
      "explanation": "La ROC representa **TPR** frente a **FPR** al variar el umbral: $$TPR=\\frac{TP}{TP+FN},\\quad FPR=\\frac{FP}{FP+TN}$$",
      "difficulty": 3,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "La ratio de verdaderos positivos y falsos positivos."
        },
        {
          "id": "b",
          "text": "La ratio de verdaderos positivos y falsos negativos."
        },
        {
          "id": "c",
          "text": "La ratio de verdaderos negativos y falsos positivos."
        },
        {
          "id": "d",
          "text": "La ratio de verdaderos positivos y verdaderos negativos."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:4c4d6c6c0d8d7d3b0c1c9e82d9c17fe9a2f16c1a7f8bfc9f0cfd6c7bf0d2a24a",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "6c5ceae8-38f1-47e5-91c5-231cf20b4ec7",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "¿Cuál es la función principal del conjunto de entrenamiento y del conjunto de test en machine learning?",
      "explanation": "Train: ajuste del modelo. Test: estimar rendimiento en datos no vistos (generalización).",
      "difficulty": 1,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "El conjunto de entrenamiento se utiliza para evaluar el rendimiento del modelo, mientras que el conjunto de test se utiliza para construir y ajustar el modelo."
        },
        {
          "id": "b",
          "text": "Ambos conjuntos se utilizan para construir y ajustar el modelo durante la fase de entrenamiento."
        },
        {
          "id": "c",
          "text": "El conjunto de entrenamiento se utiliza para construir y ajustar el modelo, mientras que el conjunto de test se utiliza para evaluar el rendimiento del modelo en datos no vistos."
        },
        {
          "id": "d",
          "text": "El conjunto de test se utiliza exclusivamente para construir y ajustar el modelo durante la fase de entrenamiento."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:48dfd4a0a1dbb24da0d31d238b4a36f6e79b137aa24679c2c8b8a1f74a1e4cd0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "6cd5cf8e-ef35-4488-ab30-8b281035b679",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "Un ingeniero de aprendizaje automático está preparando un dataframe de datos para un\nproblema de aprendizaje supervisado. El ingeniero de ML se da cuenta de que las clases de\netiquetas de salida están muy desequilibradas y varias columnas de características contienen\nvalores faltantes. La proporción de valores faltantes en todo el dataframe de datos es inferior al\n5 %.\n¿Qué debe hacer el ingeniero de ML para minimizar el sesgo debido a valores faltantes?",
      "explanation": "liminar filas con faltantes puede ser viable solo si el número es pequeño y no introduce sesgo, pero aquí ya te avisan de que las clases están muy desequilibradas: borrar observaciones puede empeorar ese desequilibrio (y por tanto sesgar aún más). El tema deja claro que la eliminación solo es práctica cuando no conduce a sesgos graves.\n\n✅ C. Reemplazar cada valor que falta por la media o la mediana de los valores que no faltan en la misma columna.\n\nPor qué las otras no:\n\nA (falsa): imputar con media/mediana de la misma fila es un sinsentido en la mayoría de datasets: mezcla variables distintas (escalas/unidades distintas) y no preserva la distribución por atributo.\n\nB (mala): aunque sea <5%, con clases desbalanceadas puedes estar quitando proporcionalmente más de la minoritaria → más sesgo. Además, la eliminación solo es recomendable si no afecta el sesgo ni las métricas.\n\nD (no es “la más efectiva” aquí): imputación basada en modelos existe y puede usarse, pero para <5% normalmente se espera la solución estándar y robusta del temario: media/mediana por columna (simple, trazable y suficiente).\n",
      "difficulty": 3,
      "options": [
        {
          "id": "c1f6bf1d-be3b-4897-bef7-4f97a7efedb5",
          "text": "Reemplazar cada valor que falta por la media o la mediana de los valores que no faltan en la misma fila."
        },
        {
          "id": "3842bdf0-6292-46d2-a879-ec37b7f7b5e7",
          "text": "Eliminar las observaciones con valores faltantes ya que representan el 5% de los datos."
        },
        {
          "id": "0a1f7eaa-582f-4cbe-91bd-db0c03a72720",
          "text": "Reemplazar cada valor que falta por la media o la mediana de los valores que no faltan en la misma columna."
        },
        {
          "id": "4f2aff5f-8e74-4c4b-a7c5-655d5cbf7c21",
          "text": "Para cada característica, calcular los valores que faltan mediante aprendizaje supervisado basado en las otras características."
        }
      ],
      "correctOptionIds": [
        "0a1f7eaa-582f-4cbe-91bd-db0c03a72720"
      ],
      "createdBy": "",
      "contentHash": "sha256:d9318f97ae0b596c6e3abf1525277a34ce824911e8de37080bc6353c379cdd88",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "6f2b86fb-8ed0-4b25-8e2a-10d404aed2a0",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Qué indica un coeficiente de regresión negativo en un modelo lineal?",
      "explanation": "✅ A. La variable predictora tiene un efecto negativo en la variable de respuesta.\n\nPor qué las otras no:\n\nB: “no hay relación” sería coeficiente ~0 (o no significativo), no negativo.\n\nC: negativo ≠ positivo.\n\nD: que sea negativo no implica que el modelo sea inadecuado; solo indica dirección de relación.",
      "difficulty": 2,
      "options": [
        {
          "id": "d94dfc7b-3f9a-403d-bd4f-62b318a53e8d",
          "text": "La variable predictora tiene un efecto negativo en la variable de respuesta."
        },
        {
          "id": "30c6fc4b-51a9-4bb2-9175-b081435da164",
          "text": "No hay relación entre la variable predictora y la variable de respuesta."
        },
        {
          "id": "5b5fca40-e636-4740-8e36-39a2df79a97d",
          "text": "La variable predictora tiene un efecto positivo en la variable de respuesta."
        },
        {
          "id": "094bd8e2-d803-4097-a342-48431fe1e0de",
          "text": "El modelo no es adecuado para hacer predicciones."
        }
      ],
      "correctOptionIds": [
        "d94dfc7b-3f9a-403d-bd4f-62b318a53e8d"
      ],
      "createdBy": "",
      "contentHash": "sha256:df800e5b145ee0c3aaabd9ee63d202ce45e93fa9213a6f42e5251011c52024dc",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "70186f65-7fa9-4ca6-967d-09b641c1556e",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "9d6276cf-e9aa-48ad-a074-fe7ce913673d",
      "type": "DESARROLLO",
      "prompt": "En el contexto del aprendizaje automático, ¿qué se entiende por sesgo técnico? ¿Cuál es su relación con el sobreajuste?",
      "difficulty": 2,
      "tags": [
        "aprendizaje-automatico",
        "conceptos-clave"
      ],
      "modelAnswer": "## Sesgo y Sobreajuste en Aprendizaje Automático\n\n### Sesgo técnico (Bias)\nError sistemático por suposiciones incorrectas o excesivamente simplistas del modelo. Un modelo con **alto sesgo** es demasiado simple para capturar la complejidad real del problema.\n\n- Error alto tanto en entrenamiento como en validación.\n- Síntoma: **subajuste (underfitting)**.\n- Ejemplo: Usar regresión lineal para modelar una relación no lineal.\n\n### Sobreajuste (Overfitting)\nOcurre cuando el modelo aprende excesivamente los datos de entrenamiento, incluyendo el ruido, y pierde capacidad de generalización.\n\n- Error muy bajo en entrenamiento, alto en validación/test.\n- El modelo tiene **alta varianza**: pequeños cambios en los datos de entrenamiento causan grandes cambios en el modelo.\n- Síntoma: el rendimiento en producción es mucho peor que en entrenamiento.\n\n### El Trade-off Bias-Variance\nExiste un compromiso fundamental:\n- **Modelo simple** → Alto sesgo, baja varianza → Subajuste.\n- **Modelo complejo** → Bajo sesgo, alta varianza → Sobreajuste.\n\n> Error total = Sesgo² + Varianza + Ruido irreducible\n\n**Técnicas para reducir sobreajuste**: regularización L1/L2, dropout, early stopping, validación cruzada, aumentar el dataset, reducir la complejidad del modelo.",
      "keywords": [
        "sesgo",
        "bias",
        "sobreajuste",
        "overfitting",
        "underfitting",
        "varianza",
        "bias-variance tradeoff",
        "regularización"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:84fd71d01e5edaf7a73df441d2d3da86681e55884b3309c3e5cbd63302cfc248",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "70afb795-8fc7-46be-9f86-cd30516ab810",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "Cuál de las siguientes afirmaciones describe el aprendizaje automático.",
      "explanation": "✅ **A.** Definición estándar: algoritmos/modelos que **infieren patrones a partir de datos** en vez de reglas/instrucciones explícitas.\n\nLas otras opciones hablan de autonomía/robots o directamente de programación basada en reglas.",
      "difficulty": 2,
      "options": [
        {
          "id": "d0285816-8d40-450f-8d83-37b611398c8e",
          "text": "El estudio científico de algoritmos y modelos estadísticos para realizar tareas mediante el uso de inferencia en lugar de instrucciones."
        },
        {
          "id": "4a7eb243-5149-4726-b5dc-844fe1ebfef5",
          "text": "La creación de máquinas que pueden realizar tareas de manera autónoma mediante el aprendizaje."
        },
        {
          "id": "2906b9d3-ec41-45f4-a1ae-0533fbf54a5e",
          "text": "La compilación de un gran número de reglas estadísticas que cubre todas las posibles soluciones."
        },
        {
          "id": "f94b821a-5ca9-4ec3-abbd-3837499ea5b6",
          "text": "Un conjunto de instrucciones que describen cómo lograr un resultado deseado."
        }
      ],
      "correctOptionIds": [
        "d0285816-8d40-450f-8d83-37b611398c8e"
      ],
      "createdBy": "",
      "sourcePackId": "aa1821f9-18ef-4a2c-aabc-27494a5f97b1",
      "contentHash": "sha256:c5153dd7fd0a81f14d006452dabddf495beb7f144fc7f2768823c6a4291ed8ff",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "7120e984-6ef7-43c1-a8b0-d46f4baeb960",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "450fb598-6a22-4be1-8621-ff78740c3973",
      "type": "DESARROLLO",
      "prompt": "¿Qué aspectos o módulos deben gestionarse en el ciclo de vida de los datos en un proyecto de IA?",
      "difficulty": 2,
      "tags": [
        "datos",
        "gestion-proyectos"
      ],
      "modelAnswer": "## Gestión del Ciclo de Vida de los Datos en un Proyecto de IA\n\n### 1. Adquisición de datos\nIdentificar fuentes (bases de datos internas, APIs, scraping, sensores, datasets públicos). Evaluar calidad, cobertura y sesgos potenciales desde el origen.\n\n### 2. Almacenamiento\nElegir la infraestructura adecuada: Data Lake (datos crudos sin estructura), Data Warehouse (datos procesados para análisis), bases de datos relacionales o NoSQL según el tipo de dato.\n\n### 3. Exploración y comprensión (EDA)\nAnálisis exploratorio para entender distribuciones, detectar valores nulos, outliers, desbalances de clase y correlaciones relevantes.\n\n### 4. Preparación y limpieza\nImputación de nulos, eliminación de duplicados, normalización/estandarización, codificación de variables categóricas, feature engineering.\n\n### 5. Etiquetado (si aplica)\nPara aprendizaje supervisado: etiquetado manual o semi-automático con herramientas como Label Studio o Prodigy. Control de calidad del etiquetado.\n\n### 6. Partición y control de versiones\nDivisión train/validation/test. Versionado de datasets con herramientas como DVC para reproducibilidad.\n\n### 7. Gobernanza y cumplimiento\nAsegurar RGPD y protección de datos. Documentar linaje de datos (data lineage). Gestionar el acceso y permisos.\n\n### 8. Monitorización en producción\nDetectar *data drift* (cambios en la distribución de los datos de entrada) que pueden degradar el rendimiento del modelo.",
      "keywords": [
        "ciclo vida datos",
        "EDA",
        "data lake",
        "etiquetado",
        "data drift",
        "RGPD",
        "DVC",
        "feature engineering"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:053d262d8b00cf72047081ecbd59e1c75b20fca038c79677eccf721816089641",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "72cb9696-c89e-4588-add8-ef187ed545b5",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Las tablas de frecuencias:",
      "explanation": "Una tabla de frecuencias registra **conteos** (frecuencia absoluta/relativa) de valores/eventos en los datos.",
      "difficulty": 1,
      "tags": [
        "frecuencias",
        "estadistica"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Indican el número de veces que el evento aparece en cada una de las situaciones."
        },
        {
          "id": "b",
          "text": "Sirven para medir el éxito del modelo."
        },
        {
          "id": "c",
          "text": "Son las mismas tablas de verosimilitud."
        },
        {
          "id": "d",
          "text": "Son la base para la construcción del modelo Naïve Bayes."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:8d9e0f1a2b3c4d5e6f708192a3b4c5d6e7f8091a2b3c4d5e6f708192a3b4c5d",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "73a6b390-7561-46c9-bbc3-72a86e826172",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "Se tiene un conjunto de datos médicos de registro de signos vitales de pacientes de un servicio de UCI adulto: presión arterial, frecuencia cardiaca, temperatura y frecuencia respiratoria. En este conjunto de datos existe un 5% de datos faltantes en la presión arterial y en la frecuencia respiratoria. ¿Cuál sería la mejor estrategia para trabajar con los datos faltantes?",
      "explanation": "✅ **D.** Reemplazar por una **medición anterior del mismo paciente**.\n\nEn UCI, los signos vitales son **series temporales por paciente**. Usar el último valor válido (*forward fill*) suele preservar mejor la dinámica del paciente que imputar con un promedio global.\n\nPor qué no:\n- **A:** perderías datos sin necesidad.\n- **B:** el promedio global puede distorsionar y borrar patrones individuales.\n- **C:** la moda no tiene sentido en variables continuas.",
      "difficulty": 3,
      "options": [
        {
          "id": "f362792a-093c-407b-b141-a65b7d582cd5",
          "text": "Eliminarlos."
        },
        {
          "id": "860dd7a8-9b65-4bb6-97f5-a85af244b42a",
          "text": "Reemplazarlos por el promedio de todos los los valores de presión arterial y frecuencia respiratoria.."
        },
        {
          "id": "854fce9b-2c37-4232-9a3a-2ef2eba8a78a",
          "text": "Reemplazarlos por la moda de todos los valores de presión arterial y frecuencia respiratoria."
        },
        {
          "id": "7bec8ee5-3e70-45f7-b859-2acca4b257df",
          "text": "Reemplazar el valor faltante de presión arterial y frecuencia respiratoria por una medición anterior del mismo paciente."
        }
      ],
      "correctOptionIds": [
        "7bec8ee5-3e70-45f7-b859-2acca4b257df"
      ],
      "createdBy": "",
      "sourcePackId": "aa1821f9-18ef-4a2c-aabc-27494a5f97b1",
      "contentHash": "sha256:60153c13682b36c6128de0ecdb44e7a42a201bf096fe39f6d610c43f820d6aa9",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "73ec77d1-d04a-4c9d-bc8a-b4f72b903ea2",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "El **Out-of-Bag (OOB) error** es una métrica utilizada en el método de Bagging que permite:",
      "explanation": "En bagging, cada modelo deja fuera (~36.8%) muestras. Esas muestras **OOB** se usan como validación interna para estimar el error sin un *test* aparte.",
      "difficulty": 2,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Evaluar el rendimiento de un modelo en el conjunto de datos de entrenamiento, utilizando la técnica de validación cruzada."
        },
        {
          "id": "b",
          "text": "Medir la varianza del modelo mediante la generación de múltiples conjuntos de entrenamiento a partir de reemplazos aleatorios del conjunto de datos original."
        },
        {
          "id": "c",
          "text": "Estimar la precisión de un modelo en el conjunto de prueba, utilizando únicamente las muestras que no se utilizaron en el proceso de entrenamiento."
        },
        {
          "id": "d",
          "text": "Reducir el sesgo en la estimación de un modelo mediante la agregación de múltiples clasificadores débiles."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:7a6b5c4d3e2f1a0b9c8d7e6f5a4b3c2d1f0e9d8c7b6a59483726150493827160",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "7539c98f-909e-45ad-a644-e8a31ae771b8",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "Los árboles de decisión:",
      "explanation": "Un árbol implementa particiones sucesivas del espacio de características, generando **regiones** con predicción constante (por hoja).",
      "difficulty": 2,
      "tags": [
        "arboles-de-decision",
        "particion-del-espacio",
        "regiones"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Transforman las variables de entrada utilizando funciones kernel."
        },
        {
          "id": "b",
          "text": "Dividen el espacio de las variables en una serie de regiones."
        },
        {
          "id": "c",
          "text": "Ejecutan diversas operaciones modificando las variables de entrada."
        },
        {
          "id": "d",
          "text": "Siempre producen modelos que son óptimos en términos de precisión y generalización, independientemente del tamaño y la complejidad del conjunto de datos."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:59e20727d823c3e68d6a8d58b574b1b7d7a89bf0c7293299b5d29b976551ae00",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "7545130d-2001-467a-b0b3-b3396b6bb45d",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "DESARROLLO",
      "prompt": "### Calidad del agua en Gorgoroth (razonamiento teórico)\n\nEl acceso al **agua potable** es esencial para la salud y un componente clave de la protección sanitaria.  \nEn la zona de **Gorgoroth** quieren invertir recursos para **mejorar la calidad del agua**, pero no saben cuál es la calidad actual ni si **varía a lo largo del año**.\n\n**Pregunta:**\n1. ¿Sería posible ayudar a los responsables de Gorgoroth a **predecir la calidad del agua** para controlar su contaminación?\n2. ¿Es un problema de **aprendizaje automático**? ¿Qué **tipo de problema** es?\n3. ¿Cómo se podría resolver con las **técnicas vistas en la asignatura**? Justifica.\n\n> Origen: **Examen anterior** (UNIR **TAA 2024**, **Modelo E**, código **10210067**).\n",
      "explanation": "La clave es **tener datos históricos** y definir bien la variable objetivo. El tipo de problema (regresión vs clasificación) lo marca cómo se mide la calidad. La estacionalidad obliga a validar con particiones temporales (no aleatorias).",
      "difficulty": 3,
      "tags": [
        "examen anterior",
        "UNIR",
        "2024",
        "modelo-e",
        "agua",
        "predicción",
        "regresión",
        "clasificación"
      ],
      "modelAnswer": "Sí, es posible **si** existe (o se puede construir) un histórico de datos que relacione **mediciones** con la **calidad** del agua.\n\n**1) ¿Es un problema de aprendizaje automático?**  \nSí, porque queremos aprender una relación *a partir de datos* para **predecir** un valor/estado futuro sin programar reglas a mano.\n\n**2) ¿Qué tipo de problema es? (depende de cómo definamos “calidad”)**\n- **Regresión supervisada** si “calidad” es un valor continuo (p. ej. índice de calidad, turbidez, nitratos, E. coli, etc.).  \n- **Clasificación supervisada** si “calidad” se discretiza (p. ej. *buena / aceptable / mala*).\n- (Complementario) **detección de anomalías** si el objetivo es detectar **picos de contaminación** raros.\n\n**3) Cómo lo resolvería con lo visto en la asignatura**\n1. **Definir la variable objetivo (y)**: índice numérico o categorías. Aclarar unidades, umbrales y frecuencia (diaria, semanal…).  \n2. **Recoger variables (X)** relevantes:  \n   - Medidas físico‑químicas (pH, conductividad, turbidez, nitratos, etc.).  \n   - Contexto: temperatura, lluvias, caudal, estacionalidad (mes, semana), eventos (vertidos, obras), localización.  \n3. **EDA (Tema 2)**: distribuciones, estacionalidad, outliers, correlaciones; ver si hay patrones por estación.  \n4. **Tratamiento de datos (Tema 3)**: faltantes (imputación razonable), escalado/normalización si procede, codificación de categóricas, y *features* temporales (lags, medias móviles).  \n5. **Entrenamiento y validación**:\n   - Split **temporal** (no mezclar futuro en entrenamiento): train con meses/años anteriores y test con periodos posteriores.  \n   - Modelos base: **regresión lineal** (baseline) y modelos no lineales como **árboles / Random Forest** si hay relaciones complejas.  \n6. **Evaluación**:\n   - Regresión: MAE/RMSE y análisis de residuos.  \n   - Clasificación: matriz de confusión, precision/recall/F1 (y especial foco en “mala calidad” si es lo crítico).  \n7. **Uso operativo**: predicción diaria/semanal + alarmas por umbrales + monitorización de deriva (si cambia el patrón, reentrenar).\n\n**Resumen:** es un problema **supervisado** (regresión o clasificación) apoyado por EDA + limpieza + validación temporal; y se puede complementar con **anomalías** para detectar contaminación inesperada.",
      "createdBy": "Luis",
      "sourcePackId": "7b705f3e-b96f-429a-8cf2-7fba79c8a0fa",
      "contentHash": "sha256:ab9a467f53ee3990bc6d8959fa8389c28cca7dc723e33f49ff57f95908179a6a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "75a2a857-48b0-49cf-b7fb-fb7ce805aa99",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones describe mejor el proceso de discretización de variables en el análisis de datos?",
      "explanation": "La discretización divide una variable continua en **intervalos/categorías** discretas (p.ej. *binning*).",
      "difficulty": 1,
      "tags": [
        "discretizacion",
        "preprocesado"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Es un método utilizado para convertir variables numéricas en variables categóricas."
        },
        {
          "id": "b",
          "text": "Es un proceso utilizado para eliminar datos atípicos en un conjunto de datos."
        },
        {
          "id": "c",
          "text": "Es una técnica que se aplica para reducir la dimensionalidad de un conjunto de datos."
        },
        {
          "id": "d",
          "text": "Es un enfoque utilizado para dividir una variable continua en intervalos o categorías discretas."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:3c4d5e6f708192a3b4c5d6e7f8091a2b3c4d5e6f708192a3b4c5d6e7f8091a2b",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "771b01c2-6a06-4cb9-9910-4f3e4f987b0c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Un científico de datos utiliza la un modelo de SVM para crear un modelo de detección de fraude. El modelo tiene una exactitud del 99%, pero no detecta el 85% de los casos de fraude. ¿Qué puede estar pasando?",
      "explanation": "✅ **A.** El conjunto de datos está muy desbalanceado...\n\nUna **accuracy** del 99% puede ocurrir si casi todo son *no fraude* y el modelo predice casi siempre *no fraude*. Eso da mucha exactitud, pero **recall/sensibilidad** para fraude se desploma (no detecta la mayoría de fraudes).",
      "difficulty": 3,
      "options": [
        {
          "id": "f8a44275-f52f-4a73-ac19-202482ad0bbe",
          "text": "El conjunto de datos está muy desbalanceado y existen más instancias de transacciones no fraudulentas que fraudulentas, por eso una exactitud tan alta."
        },
        {
          "id": "31a85bb7-5b4d-4cee-90bd-50b2c3bc6e38",
          "text": "Un valor de exactitud del 99% es muy improbable, debe revisarse la forma en que se calcula está métrica."
        },
        {
          "id": "46a504e2-435a-484f-86a5-21161200c957",
          "text": "Debe existir un error en las instancias categorizadas como fraudulentas, si la exactitud es alta debería detectarlas."
        },
        {
          "id": "9b4f418b-7546-48e9-ab18-af11ca05071c",
          "text": "Debe existir un error en las instancias categorizadas como no fraudulentas."
        }
      ],
      "correctOptionIds": [
        "f8a44275-f52f-4a73-ac19-202482ad0bbe"
      ],
      "createdBy": "",
      "sourcePackId": "aa1821f9-18ef-4a2c-aabc-27494a5f97b1",
      "contentHash": "sha256:c4480cb90529186f2a747287c59b0f0d67daa18c61017e2d0532ff1756fa7dfa",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "77d9332e-bafd-40af-9e00-c089527934aa",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "Señala la afirmación correcta sobre el método de optimización evolutiva:",
      "explanation": "El método de optimización evolutiva implica la aplicación de algoritmos inspirados en la evolución biológica, como algoritmos genéticos, para buscar de manera eficiente en el espacio de hiperparámetros y encontrar la configuración óptima que maximice el rendimiento del modelo.",
      "difficulty": 3,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "optimizacion-evolutiva",
        "algoritmos-geneticos"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Consiste en ejecutar algoritmos evolutivos para encontrar el mejor conjunto de parámetros."
        },
        {
          "id": "b",
          "text": "Es una evolución del método cartesiano."
        },
        {
          "id": "c",
          "text": "Es una evolución del método bayesiano."
        },
        {
          "id": "d",
          "text": "La optimización evolutiva de hiperparámetros garantiza resultados precisos rápidamente."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:5b1e2d3c4a5f6e7d8c9b0a1f2e3d4c5b6a7f8e9d0c1b2a3f4e5d6c7b8a9f0e1d",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "7842bf12-3af0-4a5a-8ea6-69b5fef29721",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones sobre el algoritmo **XGBoost** es correcta?",
      "explanation": "XGBoost implementa **gradient boosting** con árboles (supervisado) y es conocido por su **eficiencia** y rendimiento.",
      "difficulty": 2,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "XGBoost es un algoritmo de *clustering* ampliamente utilizado en el campo del aprendizaje no supervisado."
        },
        {
          "id": "b",
          "text": "XGBoost es una técnica de reducción de dimensionalidad que busca proyectar los datos en un espacio de menor dimensión mientras conserva la estructura de la información original."
        },
        {
          "id": "c",
          "text": "XGBoost es una variante del algoritmo de regresión lineal que se utiliza para predecir valores numéricos continuos."
        },
        {
          "id": "d",
          "text": "XGBoost es un algoritmo de aprendizaje supervisado basado en árboles que se destaca por su eficiencia y alto rendimiento en competiciones de ciencia de datos."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:6e4f0d7f0f8b54c3f6d3b2a1c0e9d8f7a6b5c4d3e2f1a0b9c8d7e6f5a4b3c2d1",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "78c84da4-d42f-4994-9f94-21ec38267176",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "Señala la afirmación correcta sobre los hiperparámetros:",
      "explanation": "Los hiperparámetros son parámetros que no se aprenden directamente del conjunto de datos durante el proceso de entrenamiento del modelo, y son específicos de cada tipo de modelo.",
      "difficulty": 1,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "hiperparametros",
        "definicion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Son específicos de cada modelo."
        },
        {
          "id": "b",
          "text": "Son generales para todos los modelos."
        },
        {
          "id": "c",
          "text": "Se utilizan para mejorar el rendimiento en el conjunto de test."
        },
        {
          "id": "d",
          "text": "Los hiperparámetros no afectan el rendimiento del modelo de aprendizaje."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:dcce11c64a4c8c3e7e9a0c7f8e0c4ed8b21b6a8f03353aeab4f6f7a6d2a5d56b",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "7974cd09-ee82-44a5-97e0-2562db5bc850",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "ce4369a8-42da-42d5-a4c2-dbbdce2a4eb0",
      "type": "TEST",
      "prompt": "¿Qué convierte un «chat» en un **agente**?",
      "explanation": "Un agente decide y ejecuta acciones (tools/APIs) con feedback del entorno; no es solo generación de texto.",
      "difficulty": 1,
      "tags": [
        "agentes",
        "tools",
        "accion",
        "orquestacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Responder con párrafos más largos."
        },
        {
          "id": "b",
          "text": "Tomar decisiones y usar herramientas externas para actuar, no solo conversar."
        },
        {
          "id": "c",
          "text": "Aumentar la temperatura del modelo."
        },
        {
          "id": "d",
          "text": "Añadir emojis para generar mayor empatía."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:5b3b7e4d2c1a1a6cc2d63aa1f2e4c19c49db7c91a6db07f67d61a2b4b4e3d6b2",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "7989e71d-7e89-4f13-a1c0-90fe4fdcec7c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "En las máquinas de vectores de soporte es cierto que:",
      "explanation": "Por qué las otras no:\n\nB (falsa): SVM no está basado en un modelo probabilístico; es geométrico/optimización. \n\n7933511_full_6678_Tema_7._Máqui…\n\nC (falsa): precisamente se busca separar en un feature space (implícitamente “enriquecido” con kernels).\n\nD (falsa): no va de reducir dimensión; lo típico es lo contrario.",
      "difficulty": 3,
      "options": [
        {
          "id": "6f4a83d7-287a-4494-af72-322b6ec87ade",
          "text": "Se crea un espacio de características con una dimensionalidad superior al espacio de características de entrada."
        },
        {
          "id": "4430261f-18f5-4f58-8b43-fcc1ff93b49c",
          "text": "Se basan en modelos probabilísticos."
        },
        {
          "id": "34c75cfc-525b-4355-96bd-bcd1a3403fc8",
          "text": "No se enriquece el feature space antes de separar las clases."
        },
        {
          "id": "54b6f35a-6771-4693-9305-2f60bd69cc23",
          "text": "Se crea un espacio de características con una dimensionalidad menor al espacio de características de entrada."
        }
      ],
      "correctOptionIds": [
        "6f4a83d7-287a-4494-af72-322b6ec87ade"
      ],
      "createdBy": "",
      "contentHash": "sha256:d0502f819244b3f0c3d8e9068b6c3b3e9fcbc7402d600e9be560f0f31b784be5",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "7a98e801-4a53-4346-b522-3ac518458254",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Dos eventos son mutuamente excluyentes:",
      "explanation": "Eventos mutuamente excluyentes son **disjuntos**: no pueden ocurrir a la vez ($A\\cap B=\\varnothing$).",
      "difficulty": 1,
      "tags": [
        "probabilidad",
        "eventos",
        "mutuamente-excluyentes"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Deben ocurrir los dos."
        },
        {
          "id": "b",
          "text": "Al menos uno de los dos debe ocurrir."
        },
        {
          "id": "c",
          "text": "Si uno ocurre el otro no puede ocurrir."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores describe la exhaustividad."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:7c8d9e0f1a2b3c4d5e6f708192a3b4c5d6e7f8091a2b3c4d5e6f708192a3b4c",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "7aef192a-9695-49d4-b12f-65543ea474e4",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a0ee552f-68ca-4b05-bf4f-9e4f2edc904c",
      "type": "DESARROLLO",
      "prompt": "¿Qué son los enjambres (swarms) de agentes inteligentes? Describe sus aplicaciones, ventajas y desventajas frente a sistemas individuales.",
      "difficulty": 2,
      "tags": [
        "agentes",
        "swarm",
        "optimizacion"
      ],
      "modelAnswer": "## Enjambres de Agentes (Swarms)\n\n### Qué son\nUn enjambre es un conjunto de **agentes simples descentralizados** que interactúan entre sí y con el entorno, emergiendo comportamientos colectivos complejos sin un controlador central. Se inspiran en la naturaleza: colonias de hormigas, bandadas de pájaros, colonias de abejas.\n\n### Aplicaciones\n- **Robótica**: Enjambres de robots para exploración en catástrofes, vigilancia de perímetros, drones para agricultura de precisión.\n- **Optimización**: ACO (Ant Colony Optimization) y PSO (Particle Swarm Optimization) para el Problema del Viajante o diseño de redes.\n- **Logística**: Coordinación de flotas de vehículos autónomos.\n- **Redes de sensores**: Monitorización ambiental distribuida y tolerante a fallos.\n\n### Ventajas frente a sistemas individuales\n- **Robustez**: Si un agente falla, el sistema global sigue funcionando (sin punto único de fallo).\n- **Escalabilidad**: Se añaden o retiran agentes sin rediseñar el sistema.\n- **Paralelismo**: Múltiples agentes exploran simultáneamente distintas zonas o soluciones.\n- **Adaptabilidad**: El comportamiento emerge localmente sin reprogramación centralizada.\n\n### Desventajas\n- **Difícil predicción**: El comportamiento emergente es difícil de controlar con precisión.\n- **Coordinación compleja**: La comunicación entre agentes puede ser costosa.\n- **Sin optimalidad global garantizada**: Sin visión centralizada, la solución puede ser subóptima.\n- **Seguridad**: Un agente comprometido puede propagar comportamientos maliciosos.",
      "keywords": [
        "swarm",
        "enjambre",
        "ACO",
        "PSO",
        "emergencia",
        "descentralizado",
        "tolerancia a fallos"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:aba3d9232ea67514c39e1b45fe56c3317b40e8596dfe6a0afa9bc5b30f05b701",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "subjectId": "7ff5a1a1-0253-42e2-82cd-b6690be0187b",
      "topicId": "ff88de98-c41d-4ecc-91cd-1f7f168bdb32",
      "type": "DESARROLLO",
      "prompt": "En el contexto del filtrado espacial, se analiza el siguiente *kernel* \\(h\\):\n\n$$\nh=\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n-1 & (\\alpha+8) & -1 \\\\\n-1 & -1 & -1\n\\end{bmatrix},\n\\qquad \\alpha \\ge 0\n$$\ndonde \\(\\alpha \\ge 0\\) es una constante.\n\n**(a)** ¿Qué tipo de filtro es \\(h\\)? Justifique su respuesta en términos de su estructura y su comportamiento en el dominio espacial.\n\n**(b)** En la figura 1 se muestra una imagen original y los resultados de aplicar el filtro \\(h\\) con diferentes valores de \\(\\alpha = (0, 1, 2)\\). Relacione cada imagen filtrada con el valor de \\(\\alpha\\) correspondiente y explique cómo varía el efecto del filtro al cambiar \\(\\alpha\\).\n\n\n![](question-images/50df1e99-7647-41dd-9284-042051cc3c5b.png)\n",
      "difficulty": 3,
      "origin": "examen_anterior",
      "modelAnswer": "## 1) Kernel dado\n\n\\[\nh=\\begin{bmatrix}\n-1 & -1 & -1\\\\\n-1 & (\\alpha+8) & -1\\\\\n-1 & -1 & -1\n\\end{bmatrix},\\quad \\alpha\\ge 0\n\\]\n\n---\n\n## (a) ¿Qué tipo de filtro es \\(h\\)?\n\nEs un **filtro espacial lineal de realce (paso-alto)** basado en el **Laplaciano (derivada de 2º orden)**.\n\nSe ve por su estructura: vecinos **negativos** y centro **positivo grande**, lo que calcula diferencias y **magnifica cambios bruscos** (bordes).\n\nPuede escribirse como:\n\n\\[\nh=\n\\underbrace{\\begin{bmatrix}\n-1 & -1 & -1\\\\\n-1 & 8 & -1\\\\\n-1 & -1 & -1\n\\end{bmatrix}}_{\\text{Laplaciano (8 vecinos)}}\n+\n\\alpha\\underbrace{\\begin{bmatrix}\n0&0&0\\\\\n0&1&0\\\\\n0&0&0\n\\end{bmatrix}}_{\\delta\\ (\\text{identidad})}\n\\]\n\nLa suma de coeficientes es:\n\n\\[\n\\sum h = (\\alpha+8)-8 = \\alpha\n\\]\n\n- Si \\(\\alpha=0\\): **ganancia DC = 0** ⇒ en zonas uniformes sale ~0 (negro) y quedan sobre todo **bordes**.\n- Si \\(\\alpha>0\\): se conserva una parte de la imagen ⇒ **afilado / high-boost** (imagen + realce).\n\n---\n\n## (b) Relaciona A, B, C con \\(\\alpha = 0,1,2\\) y explica\n\n**C → \\(\\alpha=0\\)**  \nCasi negra y con contornos marcados: es **Laplaciano puro** (solo bordes, sin componente DC).\n\n**B → \\(\\alpha=1\\)**  \nSe parece a la original pero con **bordes/contraste local realzados**: **imagen + Laplaciano**.\n\n**A → \\(\\alpha=2\\)**  \nMás **brillante** (y con posible saturación en zonas claras): al subir \\(\\alpha\\) sube la **ganancia DC** y pesa más la imagen original, manteniendo el realce.\n\n### Efecto al aumentar \\(\\alpha\\)\n- Aumenta la **componente de imagen original** (DC = \\(\\alpha\\)).\n- El filtro pasa de **detector de bordes** (\\(\\alpha=0\\)) a **afilado** (\\(\\alpha>0\\)).\n- Con \\(\\alpha\\) alto puede haber **clipping/saturación** por exceso de brillo.",
      "id": "7af4d595-5a62-4363-b51b-73f4f6c2d6b8",
      "contentHash": "sha256:6fbfc31346938251d31ccf278043cdc097343ea6e7614514a102a88919a54fec",
      "createdBy": "",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T16:19:01.998Z",
      "updatedAt": "2026-02-20T16:20:42.640Z"
    },
    {
      "id": "7b27b54b-8a6f-44dd-97fb-aad68d992d5c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones es **cierta**?",
      "explanation": "En general puede haber múltiples hiperplanos que separen los datos; SVM selecciona el óptimo según el criterio de máximo margen (y penalización de errores si es *soft margin*).",
      "difficulty": 1,
      "tags": [
        "svm",
        "hiperplano",
        "maximo-margen"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Para una serie de datos de entrenamiento de un problema binario existen múltiples hiperplanos posibles."
        },
        {
          "id": "b",
          "text": "Solo existe un hiperplano posible para cada uno de los conjuntos de datos."
        },
        {
          "id": "c",
          "text": "Los hiperplanos hay que crearlos únicamente para realizar predicciones."
        },
        {
          "id": "d",
          "text": "El objetivo de SVM es encontrar el hiperplano óptimo que maximice el margen entre todos los puntos de datos sin importar el error de clasificación."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:274891a465b91bb24ba7c1d7856f785a5bdb29e7b21c8df1ea7fb0e55e815bf2",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "7b2a3578-a6c2-4cf7-a07a-6d1d1a01c1ba",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "971fb6e6-0b0d-4637-8d69-7db209dd146e",
      "type": "DESARROLLO",
      "prompt": "Al redactar un artículo académico sobre un experimento, es frecuente separar los apartados de resultados, discusión y conclusiones. Desarrolla un ejemplo con un resultado experimental describiendo en tres párrafos el resultado, su discusión y la conclusión.",
      "difficulty": 2,
      "tags": [
        "redaccion-cientifica"
      ],
      "modelAnswer": "## Ejemplo: Comparativa de clasificadores de spam\n\n### Resultados\n\nSe evaluaron tres clasificadores (Naive Bayes, SVM y Random Forest) sobre un corpus de 10.000 correos balanceado al 50% entre spam y legítimo, con partición 80/20 entrenamiento/prueba. Los resultados fueron: Naive Bayes (accuracy: 88,2%, F1: 0,86), SVM (accuracy: 94,7%, F1: 0,93) y Random Forest (accuracy: 93,1%, F1: 0,92). El tiempo de entrenamiento fue de 2 s, 47 s y 18 s respectivamente.\n\n### Discusión\n\nLa SVM alcanzó la mayor exactitud gracias a su capacidad para encontrar hiperplanos de separación óptimos en espacios de alta dimensión, propios de representaciones TF-IDF. Sin embargo, su coste computacional puede ser limitante en producción con grandes volúmenes. Random Forest ofreció rendimiento comparable con tiempo de entrenamiento notablemente menor. La diferencia entre ambos no fue contrastada con test de significación estadística, lo que constituye una limitación del estudio.\n\n### Conclusiones\n\nLos resultados demuestran que la SVM es el clasificador más preciso en el corpus analizado; sin embargo, Random Forest representa una alternativa equilibrada entre rendimiento y eficiencia. En trabajos futuros se recomienda evaluar ambos sobre datasets de mayor escala y aplicar tests estadísticos (p. ej., Wilcoxon) para determinar si las diferencias observadas son significativas.",
      "keywords": [
        "resultados",
        "discusión",
        "conclusiones",
        "IMRaD",
        "F1-score",
        "SVM",
        "Naive Bayes"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:316cf32ffd74df78ddb3000aaab794c86eb296bfb30a96b94d738e206a9ae540",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "8285ac4e-0468-4d1d-903d-9b346e30abb2",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "ce4369a8-42da-42d5-a4c2-dbbdce2a4eb0",
      "type": "TEST",
      "prompt": "¿Qué es el **enrutado** en arquitecturas de agentes (simple o multiagente)?",
      "explanation": "Enrutar es decidir a qué ruta/actor va la consulta (tool, agente especialista, supervisor…), no cómo formateas la salida.",
      "difficulty": 2,
      "tags": [
        "routing",
        "multiagente",
        "supervisor",
        "especialista"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Ordenar alfabéticamente las respuestas."
        },
        {
          "id": "b",
          "text": "Elegir siempre responder sin herramientas para ahorrar tiempo."
        },
        {
          "id": "c",
          "text": "Seleccionar la mejor vía para cada consulta: herramienta adecuada o subagente especializado (p. ej., supervisor → especialista)."
        },
        {
          "id": "d",
          "text": "Cambiar de modelo en cada turno."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:8c0a3c2d1e0f9a8b7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b9c8d7e6f5a4b",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "8447650f-5f18-4a7b-87e1-0878dc44ff67",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Qué representa el **intercepto** en un modelo de regresión lineal?\n\nSeleccione una:",
      "explanation": "El intercepto $\\beta_0$ es el valor de $\\hat{y}$ cuando $x=0$ (o cuando todos los predictores valen 0 en el caso múltiple).",
      "difficulty": 1,
      "tags": [
        "regresion-lineal",
        "intercepto",
        "interpretacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "El valor esperado de la variable de respuesta cuando todas las variables predictoras son cero."
        },
        {
          "id": "b",
          "text": "La pendiente de la línea de regresión."
        },
        {
          "id": "c",
          "text": "La suma de los cuadrados de los residuos."
        },
        {
          "id": "d",
          "text": "La varianza explicada por el modelo."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:5cc230c1392ca821733627732695a5a76f2cce4e66617f0e6a4fb92fa3d62a52",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "8556c3ad-64e4-40b8-9143-66b157522d73",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "388275e1-be5b-44fd-8fbd-52591fd74159",
      "type": "TEST",
      "prompt": "En **chunking** para RAG con secciones que incluyen tablas, ¿qué ayuda la recuperabilidad?",
      "explanation": "Metadatos (título/sección), leyendas y un solape razonable preservan contexto y estructura, mejorando el *match* semántico sin diluir la señal con chunks enormes.",
      "difficulty": 3,
      "tags": [
        "chunking",
        "tablas",
        "metadatos",
        "overlap",
        "rag"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Cortar sin encabezados ni metadatos."
        },
        {
          "id": "b",
          "text": "Fragmentos muy largos (>2000 palabras)."
        },
        {
          "id": "c",
          "text": "Fragmentos con título/sección en metadatos, leyendas de tablas y solape moderado."
        },
        {
          "id": "d",
          "text": "Eliminar por completo las tablas."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:bd0a2b48afc320b8344b1a8db3f4f6a2a1c8bcd0f1a9dbf2fe0b62f7c4cfb8d1",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "8561fb80-269d-496a-a8a9-2049249c8fb1",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "Cuál de las siguientes afirmaciones sobre el parámetro de regularización C en SVM es falsa.",
      "explanation": "✅ D. Aumentar el valor de C en SVM siempre mejora el rendimiento del modelo en datos no vistos.\n\nEs falsa porque aumentar C puede reducir errores en entrenamiento pero aumentar el riesgo de sobreajuste y empeorar en datos no vistos.\n\nLas otras describen correctamente el efecto de C (trade-off margen vs errores).",
      "difficulty": 3,
      "options": [
        {
          "id": "9f422931-edb4-4f74-9791-4d143c168c64",
          "text": "El parámetro de regularización C en SVM controla el equilibrio entre maximizar el margen y minimizar el error de clasificación en los datos de entrenamiento."
        },
        {
          "id": "cd97eb4d-c5a7-423e-992b-6bfc05fc9e83",
          "text": "Un valor más pequeño de C conduce a un margen más amplio, pero puede dar lugar a más errores de entrenamiento permitidos por el modelo."
        },
        {
          "id": "52b42299-22c5-49ae-ae29-a6b93d9bc7e2",
          "text": "Un valor mayor de C da como resultado un margen más estrecho, pero reduce la cantidad de errores de entrenamiento tolerados por el modelo, lo que podría provocar un sobreajuste de los datos de entrenamiento."
        },
        {
          "id": "616067db-850f-41ef-85aa-5151062ab13d",
          "text": "Aumentar el valor de C en SVM siempre mejora el rendimiento del modelo en datos no vistos."
        }
      ],
      "correctOptionIds": [
        "616067db-850f-41ef-85aa-5151062ab13d"
      ],
      "createdBy": "",
      "sourcePackId": "9a48d918-0ffe-4d28-9f78-0c2350dcfe9c",
      "contentHash": "sha256:d4cc82c494b40a5d5b95d8af9768773c48aeb311e3cc804aea287156d313d984",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "8653c87b-dadf-4228-be6a-ea8175bf3921",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "3. Cuál de las siguientes afirmaciones describe el aprendizaje automático.",
      "explanation": "El aprendizaje automático estudia algoritmos que **aprenden patrones a partir de datos** para hacer **predicciones/inferencia** sin ser programados con reglas explícitas para cada caso. Las otras opciones son más vagas o describen programación por reglas.",
      "difficulty": 1,
      "tags": [
        "definición",
        "aprendizaje automático",
        "inferencia",
        "programación por reglas"
      ],
      "options": [
        {
          "id": "a",
          "text": "El estudio científico de algoritmos y modelos estadísticos para realizar tareas mediante el uso de inferencia en lugar de instrucciones."
        },
        {
          "id": "b",
          "text": "La creación de máquinas que pueden realizar tareas de manera autónoma mediante el aprendizaje."
        },
        {
          "id": "c",
          "text": "La compilación de un gran número de reglas estadísticas que cubre todas las posibles soluciones."
        },
        {
          "id": "d",
          "text": "Un conjunto de instrucciones que describen cómo lograr un resultado deseado."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "createdBy": "Luis",
      "sourcePackId": "c28801ab-40f1-46bb-938b-9d886992b1a0",
      "contentHash": "sha256:dbca19efaaa9071763d1ff750ccd186b75c21edc28bee286d4e8c0f488afebd8",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "867340b3-f802-42a3-9c31-d72383057333",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "El muestreo **Bootstrap** es una técnica estadística utilizada para:",
      "explanation": "Bootstrap = **remuestreo con reemplazo** para estimar la **variabilidad** (p. ej., varianza, intervalos de confianza) del estimador/modelo.",
      "difficulty": 2,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Reducir el sesgo en la estimación de un modelo mediante la agregación de múltiples clasificadores débiles."
        },
        {
          "id": "b",
          "text": "Estimar la varianza de un modelo mediante la generación de múltiples conjuntos de entrenamiento a partir de reemplazos aleatorios del conjunto de datos original."
        },
        {
          "id": "c",
          "text": "Seleccionar características importantes de un conjunto de datos para mejorar el rendimiento del modelo."
        },
        {
          "id": "d",
          "text": "Reducir el sobreajuste en modelos de aprendizaje automático al eliminar datos atípicos."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:0b5c1d2e3f4a59687766554433221100ffeeddccbbaa99887766554433221100",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "870db6c3-7923-4297-afa1-08407dc62355",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "ce4369a8-42da-42d5-a4c2-dbbdce2a4eb0",
      "type": "TEST",
      "prompt": "¿Qué práctica facilita que el agente decida cuándo usar una **herramienta** concreta?",
      "explanation": "Definir el contrato (qué hace, inputs, outputs) reduce ambigüedad y permite selección/uso correcto de herramientas.",
      "difficulty": 2,
      "tags": [
        "tools",
        "contrato",
        "prompt",
        "agentes"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Aumentar la ventana de contexto a su máximo."
        },
        {
          "id": "b",
          "text": "Repetir el nombre de la herramienta en mayúsculas."
        },
        {
          "id": "c",
          "text": "Describir en el *prompt* la finalidad, entradas y salidas de cada herramienta disponible."
        },
        {
          "id": "d",
          "text": "Ajustar solo la temperatura a 0."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:24b3c4a187a6c4c7c29d0aab2e3cbe1c5d0dcb74f6a4e7b4a2f4b4f3a1d2c3b4",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "87246841-fc96-47d7-89f4-b50d302f43d2",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "La matriz de gráficos de dispersión facilita:",
      "explanation": "✅ **C. La comparación de las variables en una sola pantalla e identificar dependencias.**\n\nUna **matriz de dispersión** (scatterplot matrix) muestra todos los pares de variables numéricas para ver **relaciones, correlaciones, patrones y outliers** de un vistazo.\n\n**Por qué no las otras:**\n- **A**: eso es un 3D plot, no una matriz.\n- **B**: describe un solo par; la matriz es precisamente *muchos pares a la vez*.\n- **D**: es ambiguo; lo relevante es la comparación sistemática de pares (C).",
      "difficulty": 2,
      "options": [
        {
          "id": "608d5620-ce0a-4aa8-8a47-3213e08e2818",
          "text": "Graficar tres atributos o variables en un mismo gráfico."
        },
        {
          "id": "6f47737d-0814-4e8e-ba7d-9e0e761fe323",
          "text": "Emparejar datos numéricos y saber si una variable afecta a la otra."
        },
        {
          "id": "fc84fc8a-9450-4f91-a92d-7289d06ab04d",
          "text": "La comparación de las variables en una sola pantalla e identificar dependencias."
        },
        {
          "id": "feb4d671-551f-45ec-9711-58432115221b",
          "text": "En un espacio pequeño asociar múltiples variables."
        }
      ],
      "correctOptionIds": [
        "fc84fc8a-9450-4f91-a92d-7289d06ab04d"
      ],
      "createdBy": "",
      "sourcePackId": "contribution-2026-02-18-julio-modelosB-C-new-6f543832",
      "contentHash": "sha256:f12f10771a741d8c9685991ac057b9e661e8664ea1611d5e6631a1d56b7efd33",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "87d354e5-d585-496e-9cf6-5827cb8c8ee0",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "9d6276cf-e9aa-48ad-a074-fe7ce913673d",
      "type": "DESARROLLO",
      "prompt": "¿Cuándo utilizarías aprendizaje no supervisado? Pon dos ejemplos.",
      "difficulty": 2,
      "tags": [
        "aprendizaje-automatico",
        "clustering"
      ],
      "modelAnswer": "## Aprendizaje No Supervisado\n\n### Cuándo se utiliza\n- Cuando **no disponemos de datos etiquetados** y etiquetar manualmente sería imposible o prohibitivamente costoso.\n- Para **explorar y descubrir la estructura** inherente de los datos sin hipótesis previas.\n- Como paso previo al aprendizaje supervisado: segmentar datos para entrenar modelos específicos por segmento.\n- Para **reducir la dimensionalidad** antes de otra tarea (visualización, compresión).\n- Para **detectar anomalías** sin ejemplos previos de anomalías.\n\n### Ejemplo 1: Segmentación de clientes (Clustering — K-Means)\nUna empresa de retail tiene millones de transacciones sin etiquetas de comportamiento. Se aplica K-Means para agrupar clientes en segmentos según hábitos de compra (frecuencia, ticket medio, categorías preferidas). Sin definir a priori qué es un \"buen cliente\", el algoritmo descubre grupos naturales que marketing usa para personalizar campañas.\n\n### Ejemplo 2: Reducción de dimensionalidad para visualización (PCA)\nEn un proyecto de genómica, cada muestra tiene 20.000 variables (genes). Se aplica PCA para reducir a 2-3 dimensiones, permitiendo visualizar si las muestras forman grupos naturales (distintos subtipos de tumor). El análisis puede revelar patrones desconocidos que expertos validan posteriormente.",
      "keywords": [
        "aprendizaje no supervisado",
        "clustering",
        "K-Means",
        "PCA",
        "sin etiquetas",
        "anomalías",
        "reducción dimensionalidad"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:24c8477d1eb6f3cf68f0167311aa6c94ad0df486926405f7fa85f4f3ce12d975",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "88dc35a5-12b7-4bb4-acfe-46e3b58862a3",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "971fb6e6-0b0d-4637-8d69-7db209dd146e",
      "type": "DESARROLLO",
      "prompt": "Describe qué aspectos de estilo en la redacción científica son mejorables en el texto: \"El método 1 distribuye mejor, sin duda alguna, los resultados que el método 2\".",
      "difficulty": 1,
      "tags": [
        "redaccion-cientifica"
      ],
      "modelAnswer": "## Análisis del Texto\n\nLa frase presenta múltiples deficiencias de estilo científico:\n\n1. **Falta de precisión**: \"Distribuye mejor\" es ambiguo; no se especifica qué métrica define una distribución \"mejor\" (varianza, uniformidad, media…). Toda afirmación debe cuantificarse.\n\n2. **Subjetividad inaceptable**: \"Sin duda alguna\" introduce un sesgo personal. El lenguaje científico debe ser neutro; las afirmaciones se sustentan en datos, no en la certeza del autor.\n\n3. **Ausencia de evidencia**: No se aportan datos estadísticos (medias, desviaciones, p-values). Sin ellos la afirmación es inverificable.\n\n4. **Falta de rigor metodológico**: No se menciona el método de comparación ni las condiciones del experimento, impidiendo la reproducibilidad.\n\n5. **Tono informal**: La estructura es propia del lenguaje cotidiano, no del registro académico formal.\n\n### Versión corregida\n\n> \"El método 1 presentó una distribución de resultados significativamente más uniforme que el método 2, con desviación estándar de 0,23 frente a 0,47 (p < 0,05, test de Levene), sobre 500 experimentos en condiciones controladas equivalentes.\" ",
      "keywords": [
        "estilo científico",
        "objetividad",
        "precisión",
        "evidencia",
        "redacción",
        "subjetividad"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:f6bebf661a9485c83a51a7c598662ac52e31168ca1de038ffd4a980a51623b9a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "8bea6660-e234-4dcf-9739-e0e218b83494",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "Señala la afirmación verdadera sobre el método cartesian grid search:",
      "explanation": "El método cartesian grid search implica evaluar sistemáticamente todas las combinaciones posibles de hiperparámetros dentro de un conjunto predefinido de valores. Por lo tanto, es una búsqueda exhaustiva que explora todo el espacio de hiperparámetros.",
      "difficulty": 2,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "grid-search",
        "busqueda-exhaustiva"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Consiste en una búsqueda aleatoria de los parámetros."
        },
        {
          "id": "b",
          "text": "Consiste en una búsqueda exhaustiva de los parámetros."
        },
        {
          "id": "c",
          "text": "Consiste en una búsqueda estocástica de los parámetros."
        },
        {
          "id": "d",
          "text": "Consiste en una búsqueda exhaustiva acotada de los parámetros."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:99dcfe1ffb90d5b9d820aa447db7e8b45d7a85d37a7dfb0b2e8b33fbb25d1d05",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "8c3f2907-4231-418e-b35d-cc50520cb238",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a0ee552f-68ca-4b05-bf4f-9e4f2edc904c",
      "type": "DESARROLLO",
      "prompt": "Describe brevemente las diferencias entre agentes reactivos, agentes basados en objetivos y agentes basados en función de utilidad.",
      "difficulty": 2,
      "tags": [
        "agentes",
        "tipos-agentes"
      ],
      "modelAnswer": "## Tipos de Agentes Inteligentes\n\n### Agentes Reactivos\nActúan directamente según la **percepción actual**, sin memoria ni planificación. Implementan reglas condición-acción: *SI [percepción] → ENTONCES [acción]*.\n\n- **Ventajas**: Simples, rápidos, predecibles.\n- **Limitación**: Inflexibles ante situaciones no previstas.\n- **Ejemplo**: Termostato (si temperatura < 20°C → encender calefacción).\n\n### Agentes Basados en Objetivos\nTienen representación del **estado actual y del estado meta**. Seleccionan acciones que los acerquen al objetivo mediante búsqueda y planificación.\n\n- **Ventajas**: Flexibles; pueden replantear el plan si el entorno cambia.\n- **Limitación**: No distinguen entre diferentes formas de alcanzar el mismo objetivo.\n- **Ejemplo**: GPS que planifica ruta al destino; recalcula si hay tráfico.\n\n### Agentes Basados en Función de Utilidad\nNo solo buscan el objetivo, sino hacerlo de la **mejor manera posible**. La función de utilidad cuantifica la preferencia entre estados y gestiona objetivos en conflicto.\n\n- **Ventajas**: Optimizan bajo incertidumbre; toman decisiones racionales.\n- **Limitación**: Mayor complejidad computacional; requieren diseñar bien la función de utilidad.\n- **Ejemplo**: Agente de trading que maximiza beneficio esperado ponderando riesgo y rendimiento.\n\n| | Reactivo | Por objetivos | Por utilidad |\n|---|---|---|---|\n| Memoria | No | Sí | Sí |\n| Planificación | No | Sí | Sí |\n| Optimización | No | No | Sí |",
      "keywords": [
        "agente reactivo",
        "por objetivos",
        "función de utilidad",
        "condición-acción",
        "planificación"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:1efd19f163c14723a1e24a816d9628b4b08c7477722c30c61bdcbc548a1d3855",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "8d0ea51a-4f81-4a0f-b2bc-8bc0c7e4101a",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones describe **incorrectamente** el índice **Gini** en árboles de decisión?",
      "explanation": "Gini es una **medida de impureza**. La **ganancia de información** se define típicamente con **entropía** (ID3/C4.5).",
      "difficulty": 3,
      "tags": [
        "gini",
        "impureza",
        "ganancia-de-informacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "El índice Gini mide la impureza de un conjunto de datos, donde un valor más alto indica una mayor impureza y una mezcla más desigual de clases."
        },
        {
          "id": "b",
          "text": "El índice Gini se utiliza para seleccionar la mejor división en un nodo de un árbol de decisión, buscando minimizar la impureza en los nodos hijos."
        },
        {
          "id": "c",
          "text": "El índice Gini asigna un valor de 0 cuando todos los ejemplos en un nodo pertenecen a la misma clase, lo que indica una pureza máxima."
        },
        {
          "id": "d",
          "text": "El índice Gini es una medida de la ganancia de información, utilizada para determinar qué característica proporciona la mayor separación entre las clases objetivo en un conjunto de datos."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:5bd7f30a7a42c4d533f067f871d1fb80eadd30c3724e032dbfe4d0f9b4ef8625",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "8d801c40-b302-4852-b784-62b4378f4aac",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "¿Cuál es el propósito principal de **Random Forest** en aprendizaje automático?",
      "explanation": "Al ser un método basado en *bagging* (agregación de múltiples árboles), su efecto principal es **reducir la varianza** y mejorar la generalización.",
      "difficulty": 1,
      "tags": [
        "random-forest",
        "bagging",
        "sesgo-varianza"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Reducir el sesgo."
        },
        {
          "id": "b",
          "text": "Reducir la varianza."
        },
        {
          "id": "c",
          "text": "Aumentar el sesgo."
        },
        {
          "id": "d",
          "text": "Aumentar la varianza."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:4cac0a7397e0d6a3e80b937525aac06c001b3a7de478c7331cec201930d83f7d",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "8d9a02a3-70f7-46d3-9aab-2293c16dbaaf",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "Es una ventaja que se tiene al transformar una variable nominal a una numérica:",
      "explanation": "Muchos algoritmos requieren entradas numéricas. Al codificar variables nominales (one-hot, label encoding, etc.) el modelo puede entrenarse y operar con esos atributos.",
      "difficulty": 2,
      "tags": [
        "nominal",
        "one-hot",
        "preprocesado"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Las redes neuronales no pueden lidiar con atributos nominales."
        },
        {
          "id": "b",
          "text": "Las máquinas de vector de soporte no trabajan correctamente con atributos nominales."
        },
        {
          "id": "c",
          "text": "Varios algoritmos no pueden lidiar con valores nominales y cuando se transforman los datos se pueden ejecutar."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores respuestas es una ventaja."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:8f7e6d5c4b3a29182736455443322110ffeeddccbbaa99887766554433221100",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "8e8c9c9d-86c8-4d0d-9b5f-d09918da227b",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "En cada iteración de AdaBoost, la penalización por clasificación errónea para una observación de entrenamiento en particular aumenta pasando de la ronda t a la ronda t + 1 si la observación fue:",
      "explanation": "✅ **A.** Clasificada incorrectamente por el **modelo débil** entrenado en la ronda *t*.\n\nEn AdaBoost, tras entrenar el clasificador débil de la ronda *t*, se **aumenta el peso** de las observaciones que ese débil **ha fallado**, para que la siguiente ronda se enfoque en ellas.",
      "difficulty": 3,
      "options": [
        {
          "id": "40d5d802-2467-4a63-8073-499dc906a634",
          "text": "Clasificada incorrectamente por el modelo débil entrenado en la ronda t."
        },
        {
          "id": "107b046c-1a2e-4e77-88a2-78771d25a267",
          "text": "Clasificada incorrectamente por el conjunto completo entrenado hasta la ronda t."
        },
        {
          "id": "63bc9e84-be69-4a45-aabc-647561e2ee0a",
          "text": "Clasificada incorrectamente por la mayoría de los modelos débiles entrenados hasta la ronda t."
        },
        {
          "id": "01f1c880-0043-483e-8a8b-57a2793ae5dd",
          "text": "B y C son correctas."
        }
      ],
      "correctOptionIds": [
        "40d5d802-2467-4a63-8073-499dc906a634"
      ],
      "createdBy": "",
      "sourcePackId": "aa1821f9-18ef-4a2c-aabc-27494a5f97b1",
      "contentHash": "sha256:2b51327bac3c1fb01fdfc2fa456ae03d37c2d53568093059411b66ca6a81bf20",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "8f3c232a-c066-4ca2-b2af-4b09ea7a6a89",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "La optimización de hiperparámetros:",
      "explanation": "La optimización de hiperparámetros no se utiliza directamente para controlar el overfitting o el underfitting. Su objetivo principal es encontrar la configuración óptima de hiperparámetros que maximice el rendimiento del modelo en un conjunto de datos de prueba o validación.",
      "difficulty": 2,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "optimizacion",
        "overfitting",
        "underfitting"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Permite controlar y resolver el overfitting."
        },
        {
          "id": "b",
          "text": "Permite controlar y resolver el underfitting."
        },
        {
          "id": "c",
          "text": "La optimización de hiperparámetros no tiene impacto en el rendimiento del modelo."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:10fa0a39f4cf49f3c6d2f7cda2a7f9a9bb8c9f6e0d2b63a4c3d1a8c9b1a7d2b6",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "9032a4b2-b6fd-4e4c-838a-c01bcffcb3de",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Señala la afirmación correcta: «Los algoritmos de clasificación tienen como objetivo…»",
      "explanation": "En **clasificación** el objetivo habitual es asignar una **etiqueta de clase** (la clase más probable) a cada instancia. Predecir un valor numérico es **regresión**.",
      "difficulty": 1,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Predecir la clase más probable de entre varias posibles."
        },
        {
          "id": "b",
          "text": "Predecir la distribución de probabilidad de las clases de cada instancia."
        },
        {
          "id": "c",
          "text": "Predecir un valor numérico como variable objetivo."
        },
        {
          "id": "d",
          "text": "Ordenar las etiquetas de clase de un conjunto de datos."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:71a4f43d2fcbac69bc28a8f8503547fcb47a1edddf5d593a3ef3372d1737c651",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "9135a834-43aa-4f40-b8be-e79602a0c6ee",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "5. El kernel lineal es la única opción eficaz en SVM para manejar conjuntos de datos no linealmente separables.",
      "explanation": "Si los datos **no son separables linealmente**, SVM suele manejarlo con **kernels no lineales** (p. ej. **polinómico** o **RBF**), que inducen una separación lineal en un *feature space* transformado.",
      "difficulty": 2,
      "tags": [
        "SVM",
        "kernel trick",
        "RBF",
        "polinómico",
        "no lineal"
      ],
      "options": [
        {
          "id": "a",
          "text": "Falso. SVM con kernels no lineales, como el polinómico o el radial, son opciones efectivas para manejar conjuntos de datos no linealmente separables."
        },
        {
          "id": "b",
          "text": "Verdadero. Las funciones de kernel lineal en SVM, a pesar de su aparente simplicidad, demuestran ser eficaces en escenarios donde la relación entre las características no es lineal."
        },
        {
          "id": "c",
          "text": "Falso. El kernel lineal realiza una transformación en los datos de entrada para trabajar con datos complejos y con relaciones no lineales."
        },
        {
          "id": "d",
          "text": "Verdadero. Las funciones de kernel lineal en Máquinas de Soporte Vectorial (SVM) ofrecen simplicidad y eficiencia computacional al proporcionar una solución elegante para conjuntos de datos no linealmente separables."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "createdBy": "Luis",
      "sourcePackId": "c28801ab-40f1-46bb-938b-9d886992b1a0",
      "contentHash": "sha256:3968059c23f7f424cbbdac5ab0c7aa843d4b11bfda4520f91858a3107c7b1774",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "9135c584-ca68-4585-8e83-6f980dfa6724",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "¿Cuál es el propósito principal de utilizar múltiples árboles en un bosque de Random Forest?",
      "explanation": "Combinar muchos árboles reduce la **variabilidad** del modelo (varianza) frente a un árbol único y mejora la **capacidad de generalización**.",
      "difficulty": 2,
      "tags": [
        "random-forest",
        "ensamble",
        "generalizacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Aumentar la complejidad del modelo."
        },
        {
          "id": "b",
          "text": "Aumentar el sesgo."
        },
        {
          "id": "c",
          "text": "Reducir la varianza y generalizar el modelo."
        },
        {
          "id": "d",
          "text": "Reducir el sesgo."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:99ddfcda923afd5ed78cd720c97e16594691806fba0cd3d2dc8071d3ae9460ce",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "91d8699e-1314-4ebc-a8ac-e32701cb349b",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "El método k-cross validation:",
      "explanation": "En k-fold se divide el dataset en k folds lo más iguales posible y se rota el fold de validación k veces.",
      "difficulty": 2,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "Consiste en dividir los datos disponibles k grupos de tamaño variable cada uno de ellos."
        },
        {
          "id": "b",
          "text": "Consiste en dividir los datos disponibles en k grupos del mismo tamaño."
        },
        {
          "id": "c",
          "text": "Garantiza la representación equitativa de todas las clases en cada conjunto de validación, lo que puede llevar a una evaluación sesgada en problemas desbalanceados."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:8b2d5f73c76fa42e2d2c1d2b0d62f2f55f8b2b1b1b5973d4c32df4fbf4a7f0d8",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "91f9945b-3606-44c6-8522-89a2b01c4191",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "¿Cuáles de las siguientes afirmaciones son correctas?",
      "explanation": "En aprendizaje supervisado se entrena con ejemplos de entrada y salida conocidas para aprender la relación entre ambas.",
      "difficulty": 1,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "El aprendizaje automático utiliza siempre ejemplos con clases conocidas previamente."
        },
        {
          "id": "b",
          "text": "El aprendizaje automático sirve únicamente para resolver problemas de predicción numérica."
        },
        {
          "id": "c",
          "text": "El aprendizaje supervisado busca automáticamente los mecanismos que relacionan una entrada con una salida."
        },
        {
          "id": "d",
          "text": "B y C son correctas."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:94c5f1fb1d8b7d4d2de2317e0e5df15e1b9e4f0d6f3ac7e24942e14660f98965",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "921b7f37-9d23-4be5-ae1b-f26a2add201c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "Bootstrapping significa:",
      "explanation": "Por qué las otras no:\n\nA: “remuestreo aleatorio simple” es ambiguo y normalmente se entiende sin enfatizar con reemplazo (que es la clave del bootstrap).\n\nC: eso describe tests de significación, no bootstrap.\n\nD: bootstrap se usa en ensembles como bagging, pero no es “un método de ensamble”; es la técnica de muestreo.",
      "difficulty": 2,
      "options": [
        {
          "id": "39c3f458-3bd1-4e3d-b477-339fdae54a69",
          "text": "Método de remuestreo aleatorio simple."
        },
        {
          "id": "6b3f9fbf-301d-4781-96b7-f17d0983c341",
          "text": "Método estadístico de muestreo con reemplazamiento."
        },
        {
          "id": "f9be05ee-0f81-4140-9d7c-d70678a878de",
          "text": "Método estadístico para ver cuánto de significativo es un resultado."
        },
        {
          "id": "7bc9a432-4670-4d3b-9a22-42687e7f8a8a",
          "text": "Método de ensamble de modelos que utiliza datos aleatorios con reemplazo"
        }
      ],
      "correctOptionIds": [
        "6b3f9fbf-301d-4781-96b7-f17d0983c341"
      ],
      "createdBy": "",
      "contentHash": "sha256:622e085363e657000f58070e8543028c25675a453ed89346262511cf071b68ab",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "92c116df-5a52-4eb2-82a0-ffa1b444f8fa",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones sobre la función sigmoide es **falsa**?",
      "explanation": "Ningún *kernel* es el mejor *siempre*: el rendimiento depende del problema, los datos y la elección de hiperparámetros.",
      "difficulty": 2,
      "tags": [
        "svm",
        "kernel-sigmoide",
        "tanh",
        "seleccion-de-kernel"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "La función de *kernel* sigmoide en SVM se define como $k(x,x')=\\\\tanh(\\\\alpha\\\\,x^T x' + c)$, donde $\\\\alpha$ y $c$ son parámetros ajustables."
        },
        {
          "id": "b",
          "text": "La función de *kernel* sigmoide puede ser útil para modelar relaciones no lineales en SVM y puede capturar patrones complejos en los datos."
        },
        {
          "id": "c",
          "text": "La función de *kernel* sigmoide transforma los datos a un espacio de características de mayor dimensión utilizando una función sigmoide para facilitar la separación lineal de clases."
        },
        {
          "id": "d",
          "text": "La función de *kernel* sigmoide en SVM siempre produce un mejor rendimiento que otros *kernels*, como el *kernel* lineal o el *kernel* polinomial."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:8e7d6c5b4a3f2e1d0c9b8a7f6e5d4c3b2a1908f7e6d5c4b3a2f1e0d9c8b7a6f",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "93098db5-bb9e-46e7-83cb-17b0e70809d6",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "971fb6e6-0b0d-4637-8d69-7db209dd146e",
      "type": "DESARROLLO",
      "prompt": "Describe qué es el ESTADO DEL ARTE en un documento científico y por qué es relevante dentro de cualquier avance de investigación.",
      "difficulty": 2,
      "tags": [
        "redaccion-cientifica"
      ],
      "modelAnswer": "## Estado del Arte\n\nEl **estado del arte** es una revisión crítica y estructurada del conocimiento existente sobre el tema de investigación. Analiza, sintetiza y evalúa los trabajos más relevantes publicados, identificando qué se ha hecho, qué metodologías se han empleado, qué resultados se han obtenido y qué lagunas quedan por explorar.\n\n### Por qué es relevante\n\n- **Contextualización**: Sitúa la investigación dentro del campo, evitando replicar trabajo ya realizado.\n- **Justificación de la necesidad**: Demuestra que el problema no ha sido resuelto satisfactoriamente.\n- **Marco de comparación**: Permite comparar los propios resultados con trabajos previos.\n- **Detección de brechas (gaps)**: Identifica áreas no exploradas que la nueva investigación puede abordar.\n- **Rigor científico**: Garantiza que la investigación parte de una base sólida.\n- **Credibilidad**: Demuestra conocimiento profundo del campo.\n\nEl estado del arte es la garantía de que una investigación es **original, relevante y rigurosa**.",
      "keywords": [
        "estado del arte",
        "revisión bibliográfica",
        "gap",
        "brechas",
        "originalidad"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:184cca9269b8514c04ad7e4348e144d607d0f4beae306588f3ddd1b828718b84",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "94f24f8d-c090-425f-88b7-b9a273f49fc0",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "¿Cuál es la principal característica del método de hold-out en el contexto de validación de modelos en machine learning?",
      "explanation": "Hold-out es una partición única del dataset en entrenamiento y test para evaluar el modelo.",
      "difficulty": 2,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "Consiste en dividir los datos en k particiones para realizar múltiples iteraciones de entrenamiento y evaluación."
        },
        {
          "id": "b",
          "text": "Consiste en separar los datos disponibles en dos conjuntos: uno para entrenamiento y otro para test."
        },
        {
          "id": "c",
          "text": "Se utiliza para realizar ajustes continuos de los hiperparámetros del modelo durante la fase de entrenamiento."
        },
        {
          "id": "d",
          "text": "Es exclusivamente aplicable a problemas de clasificación y no a problemas de regresión."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:92f47f6eb1a7d62d6ec4f3bd70c079b38b1c3b26d7f5fb6f82b0d6f3f9b5cb6f",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "979d018c-1dc9-4aa6-a130-b9a44348c015",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "450fb598-6a22-4be1-8621-ff78740c3973",
      "type": "DESARROLLO",
      "prompt": "En el contexto de la anonimización de datos personales, explica brevemente la diferencia entre tokenizar y aplicar una función hash.",
      "difficulty": 2,
      "tags": [
        "datos",
        "privacidad",
        "seguridad"
      ],
      "modelAnswer": "## Tokenización vs Función Hash\n\n### Tokenización\n- Sustituye el dato original por un **token** (valor aleatorio sin relación matemática con el original).\n- La correspondencia token ↔ dato original se guarda en un **vault** (almacén seguro).\n- Es **reversible**: con acceso autorizado al vault se puede recuperar el original.\n- **Ejemplo**: DNI \"12345678A\" → Token \"TKN-9834-XQZL\".\n- **Uso**: Pagos con tarjeta (PCI-DSS), historial clínico donde se necesita recuperar el dato original.\n\n### Función Hash\n- Aplica una **función matemática unidireccional** (SHA-256, bcrypt, Argon2) que transforma el dato en un valor de longitud fija.\n- Es **irreversible por diseño**: no existe función inversa.\n- El mismo input siempre produce el mismo hash (*determinista*).\n- **Vulnerabilidad**: Susceptible a ataques de *rainbow tables* sin **salt** (sal).\n- **Ejemplo**: SHA256(\"12345678A\" + salt) = \"a3f9d8c2...\"\n- **Uso**: Almacenamiento de contraseñas, verificación de integridad.\n\n### Resumen\n\n| | Tokenización | Hash |\n|---|---|---|\n| Reversible | ✅ (con vault) | ❌ |\n| Relación matemática | No (aleatoria) | Sí (one-way) |\n| Caso de uso | Datos recuperables | Contraseñas, verificación |",
      "keywords": [
        "tokenización",
        "hash",
        "SHA-256",
        "vault",
        "salt",
        "one-way",
        "rainbow tables",
        "anonimización"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:f7c128464df218f01fade610e34960e33d91e0b94249d9fcf34e9d536ad143a8",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "97c9203e-6a98-4b93-a22d-927d04ecd19e",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "PRACTICO",
      "prompt": "### Evaluación de un clasificador de fraude (métricas)\n\nSupongamos que hemos utilizado un **clasificador** (p. ej. una **SVM**) para distinguir entre transacciones bancarias **fraudulentas** (`Fr`) y **no fraudulentas** (`No`).\n\nA partir de los siguientes resultados:\n\n| Transacción | Clase real | Clase predicha |\n|---|---|---|\n| Tran1 | Fr | Fr |\n| Tran2 | Fr | Fr |\n| Tran3 | No | No |\n| Tran4 | No | No |\n| Tran5 | Fr | No |\n| Tran6 | No | No |\n| Tran7 | No | No |\n| Tran8 | Fr | Fr |\n| Tran9 | Fr | No |\n| Tran10 | No | Fr |\n\nSe pide:\n\n1. Calcular **precision**, **recall**, **accuracy** y **F1** para estos resultados de clasificación **para las dos clases**.  \n2. En base a los resultados obtenidos, explica el comportamiento del clasificador en cuanto a la **detección de transacciones fraudulentas**.\n\n> Origen: **Examen anterior** (UNIR, ordinaria **07–12/03/2025**, **Modelo E**).",
      "explanation": "Se calculan TP/TN/FP/FN a partir de la tabla, y después las métricas para cada clase. La interpretación se centra en la detección de fraude (prioridad típica: recall).",
      "difficulty": 2,
      "tags": [
        "examen anterior",
        "métricas",
        "clasificación binaria"
      ],
      "modelAnswer": "## 1) Matriz de confusión (tomando **Fr** como clase positiva)\n\n- **TP (Fr→Fr)** = 3  \n- **FN (Fr→No)** = 2  \n- **TN (No→No)** = 4  \n- **FP (No→Fr)** = 1  \n\n| | Pred: Fr | Pred: No |\n|---|---:|---:|\n| **Real: Fr** | TP = 3 | FN = 2 |\n| **Real: No** | FP = 1 | TN = 4 |\n\nTotal = 10\n\n---\n\n## 2) Métricas para la clase **Fr** (fraude)\n\n- **Precision(Fr)** = TP / (TP + FP) = 3/(3+1) = **0.75**\n- **Recall(Fr)** = TP / (TP + FN) = 3/(3+2) = **0.60**\n- **F1(Fr)** = 2·P·R / (P+R) = **0.67**\n- **Accuracy (global)** = (TP + TN) / total = (3+4)/10 = **0.70**\n\n---\n\n## 3) Métricas para la clase **No** (no fraude)\n\nPara evaluar “No” como clase de interés, tratamos **No** como positiva:\n\n- TP(No) = 4 (No→No)  \n- FP(No) = 2 (Fr→No)  \n- FN(No) = 1 (No→Fr)\n\n- **Precision(No)** = TP(No) / (TP(No) + FP(No)) = 4/(4+2) = **0.67**\n- **Recall(No)** = TP(No) / (TP(No) + FN(No)) = 4/(4+1) = **0.80**\n- **F1(No)** = **0.73**\n- **Accuracy (global)** = **0.70** (la misma, porque es global)\n\n---\n\n## 4) Interpretación: ¿qué tal detecta fraude?\n\n- **Recall(Fr) = 0.60** → se le escapan **2 de 5** fraudes (**40%**).  \n  Para fraude, esto suele ser **peligroso**: el coste de un FN suele ser alto.\n- **Precision(Fr) = 0.75** → cuando marca “fraude”, acierta **3 de 4** veces (25% falsas alarmas).  \n  No es terrible, pero genera **ruido** operativo.\n\n**Conclusión práctica:** el clasificador es “aceptable” en acierto global (**accuracy 0.70**), pero para el objetivo real (cazar fraude) su **recall es bajo**. Si el negocio prioriza no perder fraudes, habría que **subir recall** (aunque baje algo la precision).\n\n### Cómo mejorar (desde lo visto en la asignatura)\n- Ajustar el **umbral** de decisión (trade-off precision/recall).\n- Entrenamiento **coste-sensible** / `class_weight` para penalizar más los FN de fraude.\n- Técnicas de **re-muestreo** si hay desbalance (y validación correcta).\n- Probar modelos con mejor generalización: **árboles / Random Forest / ensembles** y **tuning** (Temas 6, 9, 10, 11).\n",
      "keywords": [
        "matriz de confusión",
        "precision",
        "recall",
        "F1",
        "accuracy",
        "fraude",
        "SVM"
      ],
      "createdBy": "Luis",
      "sourcePackId": "83ef5676-1384-45f7-804a-20c7d1f4690b",
      "contentHash": "sha256:03ca2b66df648d07d231fcb98969707aa8cf1f630a83d9df6e75d844fc4f0cee",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "980d4877-e8a5-40fa-ae5c-48681a4a7cca",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "¿Qué tipo de entrenamiento describe una aplicación de aprendizaje automático que\ninteractúa con su entorno y aprende a tomar decisiones que maximicen recompensas?",
      "explanation": "Por qué las otras no:\n\nA (falsa): supervisado = aprende con ejemplos etiquetados (entrada → salida conocida), no con recompensas del entorno. \n\nB (falsa): no supervisado = no hay etiquetas/objetivo; suele ser clustering/anomalías, no “recompensas”. \n\n\nD (falsa): aprendizaje profundo es un tipo de modelos (redes profundas), no un paradigma por sí mismo; puede usarse dentro de RL, pero no lo define. \n",
      "difficulty": 1,
      "options": [
        {
          "id": "65fd0e29-5bb8-4eff-81df-530f739ac389",
          "text": "Aprendizaje supervisado."
        },
        {
          "id": "4bf84bd7-de4f-4eac-8975-ff9586f2a770",
          "text": "Aprendizaje no supervisado."
        },
        {
          "id": "263dad99-2936-493b-bc08-aa38a3283ee6",
          "text": "Aprendizaje por refuerzo."
        },
        {
          "id": "4d0057b9-d7fc-4cbe-8a77-012d0c98319c",
          "text": "Aprendizaje profundo."
        }
      ],
      "correctOptionIds": [
        "263dad99-2936-493b-bc08-aa38a3283ee6"
      ],
      "createdBy": "",
      "contentHash": "sha256:ef4eca6ba0afc1b8fd0fc40918931ea8225888b745169bc313955fa1a14ae68e",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "990d42a5-0317-4a53-81ee-f1b27e5353cd",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "971fb6e6-0b0d-4637-8d69-7db209dd146e",
      "type": "DESARROLLO",
      "prompt": "Explica brevemente en qué consiste el peer review en las publicaciones científicas, por qué es importante y cuál es al menos un inconveniente.",
      "difficulty": 2,
      "tags": [
        "publicacion",
        "metodologia"
      ],
      "modelAnswer": "## Peer Review (Revisión por Pares)\n\nEl **peer review** es el proceso por el que un artículo es evaluado por expertos independientes del mismo campo antes de su publicación. Modalidades principales:\n- **Simple ciego**: El autor desconoce quiénes son los revisores.\n- **Doble ciego**: Ni autor ni revisores se conocen (mayor imparcialidad).\n- **Abierto**: Ambas partes son conocidas y las revisiones pueden publicarse.\n\n### Por qué es importante\n- Garantiza el **rigor científico** antes de que el trabajo llegue a la comunidad.\n- Filtra errores, afirmaciones infundadas y resultados no reproducibles.\n- Mejora la calidad mediante feedback experto.\n- Principal **mecanismo de control de calidad** de la ciencia.\n\n### Inconvenientes\n- **Sesgo del revisor**: Puede favorecer trabajos afines o penalizar enfoques novedosos.\n- **Lentitud**: El proceso puede durar meses o años.\n- **Carga no remunerada**: Revisores sin compensación pueden restar profundidad a las revisiones.\n- **Reproducibilidad no verificada**: El peer review no garantiza reproducibilidad de resultados.",
      "keywords": [
        "peer review",
        "revisión por pares",
        "doble ciego",
        "rigor científico",
        "sesgo"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:a26e566ad9a3da9d0396c9afb32ddb978fc40ba1a786f916d3b394e47fd812c6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "9bd6b10d-f959-4dda-b706-b5cc1a22c46b",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "388275e1-be5b-44fd-8fbd-52591fd74159",
      "type": "TEST",
      "prompt": "Para medir la calidad de la **recuperación**, ¿qué combinación de métricas es más recomendable?",
      "explanation": "*Recall@k* mide si lo relevante entra en el top-*k* (cobertura) y *NDCG* pondera la posición/ordenación de los pasajes relevantes.",
      "difficulty": 3,
      "tags": [
        "retrieval",
        "metricas",
        "recall@k",
        "ndcg",
        "ranking"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Perplejidad y BLEU."
        },
        {
          "id": "b",
          "text": "Exact Match (EM) y WER."
        },
        {
          "id": "c",
          "text": "*Recall@k* (cobertura) y *NDCG* (ordenación)."
        },
        {
          "id": "d",
          "text": "*Sentiment score* y CTR."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b9c8d7e6f5a4b3c2d1e0f9a8b7c6d5e4",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "9d141d19-0b7a-45c5-a730-2423fb6d11d8",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes métricas MAE, MSE o RMSE de los modelos de regresión es más robusta a los valores anómalos?",
      "explanation": "✅ **C.** **MAE** es la más robusta a outliers.\n\nMAE usa **error absoluto** (penalización lineal). En cambio **MSE/RMSE** elevan al cuadrado, y por eso los errores grandes (outliers) pesan muchísimo más.",
      "difficulty": 3,
      "options": [
        {
          "id": "a2550a11-b9b3-4fc8-b5b1-5b41746a65e1",
          "text": "La métrica más robusta es el MAE ya que El MAE penaliza de manera significativa los errores grandes en las predicciones, asignando un peso proporcional al cuadrado de la diferencia entre la predicción y el valor real."
        },
        {
          "id": "6fc2ad96-5bf1-4b1c-ba7a-575e60bdbe41",
          "text": "Las métricas más robustas son MSE o RMSE dado que no se ven afectadas por los valores extremos debido al término del cuadrado."
        },
        {
          "id": "7724d155-839f-4813-bb2a-dd30253a6439",
          "text": "La métrica más robusta es el MAE dado que se calcula tomando el promedio de las diferencias absolutas de las predicciones y los valores reales."
        },
        {
          "id": "eb6bad5d-ea7b-4001-be6e-cec388892880",
          "text": "El RMSE siempre produce un valor más pequeño que MAE, lo que demuestra que es una métrica más precisa y robusta en todos los casos de evaluación de modelos de regresión."
        }
      ],
      "correctOptionIds": [
        "7724d155-839f-4813-bb2a-dd30253a6439"
      ],
      "createdBy": "",
      "sourcePackId": "aa1821f9-18ef-4a2c-aabc-27494a5f97b1",
      "contentHash": "sha256:7cc8a05e36c8bc1e81a8b77843305fe547caf9d06c743838db13383a973dae8e",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "9e73c189-0149-46e8-b1ed-e8b19b2a8efc",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "La métrica de accuracy:",
      "explanation": "$$\\text{Accuracy} = \\frac{TP+TN}{TP+TN+FP+FN}$$",
      "difficulty": 1,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Se conoce como la ratio de éxito."
        },
        {
          "id": "b",
          "text": "Representa el número de predicciones correctas entre el total de predicciones."
        },
        {
          "id": "c",
          "text": "Representa el número de falsos detectados."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:3c34b76f85573fa87e4b1b5c09b3b3e90b517c5088187b8dfc8b2f7c6c1a2b57",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "a03b5e07-82c6-4f21-83c0-509fd3bbc1d2",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes visualizaciones es más adecuada para evaluar los errores en un modelo de regresión?",
      "explanation": "✅ B. Gráfico de dispersión de residuos vs. valores predichos.\n\nPor qué las otras no:\n\nA: un histograma/frecuencias ayuda a ver la distribución, pero no revela patrones (heterocedasticidad, no linealidad).\n\nC: no es un diagnóstico estándar de regresión y además depende del tipo de entrenamiento.\n\nD: un gráfico de pastel no sirve para diagnosticar errores.",
      "difficulty": 2,
      "options": [
        {
          "id": "a5653a9f-4ff1-4afb-b1e0-3a175997db71",
          "text": "Gráfico de barras de frecuencia de errores absolutos."
        },
        {
          "id": "09a452d1-5e9a-40bd-9a3a-e6bacadc46ad",
          "text": "Gráfico de dispersión de residuos vs. valores predichos."
        },
        {
          "id": "640626ec-bb7c-4894-9ced-2e28acf9abaa",
          "text": "Gráfico de línea de errores relativos vs. iteraciones de entrenamiento."
        },
        {
          "id": "b566a99f-58ab-4d48-847e-99951f9148ed",
          "text": "Gráfico de pastel de errores cuadráticos medios."
        }
      ],
      "correctOptionIds": [
        "09a452d1-5e9a-40bd-9a3a-e6bacadc46ad"
      ],
      "createdBy": "",
      "sourcePackId": "778c30fd-9df1-4385-9961-39a237b103e9",
      "contentHash": "sha256:a046452813b795dc05e351bb2460568b38b48cd2d00ec3fe914e2c8ba1b552e4",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "a23d7c5b-0e4a-4442-85fd-c3db257b8d5b",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "Señala la afirmación correcta sobre los hiperparámetros:",
      "explanation": "Los hiperparámetros son configuraciones que afectan el comportamiento y el rendimiento de los modelos de aprendizaje automático, y su optimización tiene como objetivo mejorar el rendimiento predictivo del modelo en conjuntos de datos nuevos y no vistos.",
      "difficulty": 2,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "hiperparametros",
        "optimizacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Sirven para optimizar los modelos."
        },
        {
          "id": "b",
          "text": "Su optimización puede generar sobreajuste a los datos de entrenamiento."
        },
        {
          "id": "c",
          "text": "Su optimización nunca genera sobreajuste, pues no modifican los datos de entrenamiento."
        },
        {
          "id": "d",
          "text": "Son iguales para todos los modelos."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:00d4b0b9287f493c2c9f2dc54fbe3e9bf8d1b1b4f0f2c8dfb13e6f54a5c6bd88",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "a2e52897-b8db-4966-adec-0f97d0cffceb",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones sobre los hiperplanos es **cierta**?",
      "explanation": "Un hiperplano es el límite de decisión en un espacio de características (de cualquier dimensión). En SVM se elige el que maximiza el margen (y en *soft margin* equilibrando margen y errores).",
      "difficulty": 1,
      "tags": [
        "svm",
        "hiperplano",
        "margen"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Un hiperplano solo se define para dos dimensiones."
        },
        {
          "id": "b",
          "text": "Límite de decisión entre clases que separa de manera óptima las instancias de datos, en espacio de características multidimensional."
        },
        {
          "id": "c",
          "text": "El hiperplano en SVM siempre pasa por el origen en el espacio de características."
        },
        {
          "id": "d",
          "text": "Un hiperplano busca el sobreajuste de las instancias de datos."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:9f795f6b56a29559c764e53a7bb46018c3877f557bff89fc3df4db8b4d3c6b4b",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "a4581307-14dc-4f85-92ef-8aaf9ededd7d",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "¿Cuál NO es una característica del **diagrama de cajas**?",
      "difficulty": 2,
      "options": [
        {
          "id": "a",
          "text": "Q2 representa la mediana"
        },
        {
          "id": "b",
          "text": "**Los bigotes representan el rango intercuartílico**"
        },
        {
          "id": "c",
          "text": "Los bigotes pueden ir del mínimo al máximo"
        },
        {
          "id": "d",
          "text": "Incluye Q1 y Q3"
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:919bdd52ce7f6ac607854a8c9acb5ef3b72363b424b4d85cf68584fc17187d8e",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "a629701e-637d-4751-8e4b-ac0d65733f29",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "Señala la afirmación válida. Para la mayoría de los conjuntos de datos:",
      "explanation": "En la mayoría de los conjuntos de datos, no todos los hiperparámetros son igualmente relevantes. Algunos pueden tener un impacto significativo en el rendimiento del modelo, mientras que otros pueden tener un impacto mínimo o incluso nulo. La determinación de la relevancia de los hiperparámetros depende del conjunto de datos específico y del problema que se esté abordando.",
      "difficulty": 2,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "hiperparametros",
        "relevancia"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Todos los hiperparámetros son relevantes."
        },
        {
          "id": "b",
          "text": "Solo algunos de los hiperparámetros son relevantes."
        },
        {
          "id": "c",
          "text": "La relevancia o no de los hiperparámetros depende del volumen de los datos."
        },
        {
          "id": "d",
          "text": "Existe el mismo conjunto de hiperparámetros relevante."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:2a3b4c5d6e7f8091a2b3c4d5e6f708192a3b4c5d6e7f8091a2b3c4d5e6f70819",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "a7235045-65b9-4187-b63a-17b4b31bb061",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "¿Cuáles son los pasos que sigue el método **Boosting**?",
      "explanation": "Boosting entrena **secuencialmente** modelos débiles, reponderando las muestras (o optimizando una pérdida) para que cada iteración se centre en los errores de la anterior; la combinación final suele ser **ponderada**.",
      "difficulty": 3,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Genera múltiples conjuntos de entrenamiento mediante muestreo con reemplazo, entrena en paralelo tantos clasificadores base como conjuntos de datos generados existan, combina las predicciones de cada clasificador base para obtener la predicción final."
        },
        {
          "id": "b",
          "text": "Genera múltiples conjuntos de entrenamiento mediante muestreo con reemplazo, entrena secuencialmente el clasificador base con cada conjunto de datos de entrenamiento generado, combina las predicciones de cada clasificador base a través del voto mayoritario."
        },
        {
          "id": "c",
          "text": "Asigna pesos a cada muestra del conjunto de entrenamiento, inicialmente todos tienen el mismo peso. Entrena el modelo débil utilizando el conjunto de datos de entrenamiento ponderado con los pesos actuales. Calcula el error del modelo débil. Asigna pesos al modelo débil. Actualiza los pesos de las muestras y repite los pasos hasta alcanzar un criterio de parada. Combina los modelos débiles para formar un modelo fuerte que se utiliza para futuras predicciones."
        },
        {
          "id": "d",
          "text": "Genera múltiples conjuntos de entrenamiento mediante muestreo con reemplazo. Entrena el modelo débil utilizando el conjunto de datos de entrenamiento ponderado con los pesos actuales. Asigna pesos al modelo débil. Actualiza los pesos de las muestras y repite desde el entrenamiento hasta alcanzar un criterio de parada. Combina los modelos débiles para formar un modelo fuerte."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:2c0a788e942384215be4acdd317cc744ac1795bad9689e295f243d2ef5bf9b91",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "a7bd9cfa-2058-49a5-8378-43455165bb22",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "971fb6e6-0b0d-4637-8d69-7db209dd146e",
      "type": "DESARROLLO",
      "prompt": "Explica cómo medir la calidad de un trabajo científico desde el punto de vista de la redacción y la validez de sus fuentes.",
      "difficulty": 2,
      "tags": [
        "redaccion-cientifica"
      ],
      "modelAnswer": "## Calidad de un Trabajo Científico\n\n### Criterios de calidad en redacción\n- **Precisión**: Afirmaciones concretas, cuantificadas, sin ambigüedad.\n- **Concisión**: Sin redundancias ni palabras innecesarias.\n- **Objetividad**: Sin valoraciones subjetivas; lenguaje impersonal.\n- **Coherencia interna**: Conclusiones derivadas lógicamente de los datos.\n- **Estructura**: Sigue el formato IMRaD (Introducción, Métodos, Resultados, Discusión).\n\n### Criterios de calidad en fuentes\n- **Peer review**: Las fuentes han superado revisión por pares.\n- **Actualidad**: Recientes (últimos 5 años) salvo trabajos fundacionales.\n- **Relevancia**: Directamente pertinentes al problema investigado.\n- **Variedad**: No basado en un único autor o fuente.\n\n### Indicadores externos de calidad\n- **Factor de impacto (JIF)** de la revista.\n- **Cuartil (Q1–Q4)**: Posición relativa en el campo (Q1 = top 25%).\n- **Índice h del autor**: h publicaciones citadas al menos h veces.\n- **Reproducibilidad**: ¿Otros pueden replicar el experimento con la descripción facilitada?",
      "keywords": [
        "calidad científica",
        "factor de impacto",
        "índice h",
        "peer review",
        "IMRaD",
        "cuartil",
        "reproducibilidad"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:89de1b7c9cffe253eded41625b923a27896bf9096f35281037a8661faa97d5f6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "a7e2d4e2-7a77-4c9d-9ece-3b819ad74444",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "¿Por qué aplicar normalización a los datos?",
      "explanation": "Se normaliza para evitar que las variables con valores numéricos grandes dominen el cálculo (distancias, etc.) frente a variables con magnitudes pequeñas.",
      "difficulty": 2,
      "tags": [
        "normalizacion",
        "escalado"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Porque se utiliza la distancia euclídea y necesita la normalización para poder calcularse."
        },
        {
          "id": "b",
          "text": "Los atributos con magnitudes altas pesarán mucho más que los atributos con magnitudes bajas."
        },
        {
          "id": "c",
          "text": "A y B son ciertas."
        },
        {
          "id": "d",
          "text": "A y B son falsas."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:df0b2f6f0c7d1ad1d9c4d5b5e89b7f2a4c68e5d2d05d2b13de4d8d4b1c0e3e5b",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "a9a5cee2-284f-42f0-af7f-18415155aa14",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "067cd1e1-d35d-47ca-9713-f712013ed237",
      "type": "DESARROLLO",
      "prompt": "¿Cuáles son algunos de los desafíos éticos más comunes en el desarrollo y uso de inteligencia artificial?",
      "difficulty": 2,
      "tags": [
        "etica",
        "regulacion"
      ],
      "modelAnswer": "## Desafíos Éticos en IA\n\n### 1. Sesgo y discriminación algorítmica\nLos modelos aprenden de datos históricos que contienen sesgos sociales. Pueden perpetuar discriminaciones en contratación, créditos, diagnóstico médico o justicia penal si no se detectan y corrigen.\n\n### 2. Privacidad y vigilancia masiva\nEl reconocimiento facial, análisis de comportamiento y Big Data pueden vulnerar la privacidad sin consentimiento, especialmente cuando los usa el Estado o grandes corporaciones.\n\n### 3. Opacidad y falta de explicabilidad (caja negra)\nLas decisiones de redes neuronales profundas son difíciles de interpretar, lo que genera problemas cuando afectan derechos fundamentales y no pueden justificarse ante los afectados.\n\n### 4. Responsabilidad y atribución de daños\nCuando un sistema de IA causa daño (accidente de coche autónomo, diagnóstico erróneo), no está claro quién responde: ¿fabricante, operador, usuario?\n\n### 5. Impacto en el empleo\nLa automatización puede desplazar trabajos en manufactura, transporte y servicios financieros, generando desigualdad económica si la transición no se gestiona adecuadamente.\n\n### 6. Uso malicioso\nDeepfakes, generación masiva de desinformación, ataques adversariales y armamento autónomo son riesgos graves del uso malicioso de la IA.\n\n### 7. Concentración de poder\nEl desarrollo avanzado de IA está concentrado en pocas empresas tecnológicas y países, generando asimetrías de poder y dependencia tecnológica.\n\n### Marco regulatorio\nLa UE afronta estos desafíos con el **AI Act** (Ley de IA): clasifica los sistemas por nivel de riesgo e impone requisitos proporcionales de transparencia y supervisión humana.",
      "keywords": [
        "sesgo",
        "privacidad",
        "explicabilidad",
        "responsabilidad",
        "deepfakes",
        "empleo",
        "AI Act",
        "ética IA"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:877e80886af60690c5d0b4a668c8e6acc99b669f1abe9a5a2a9d74733d5dee30",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "aa7edfd9-1af6-4c81-81c0-46d19ec54cf4",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "502e9489-f902-45a4-8614-1f853b90f62f",
      "type": "DESARROLLO",
      "prompt": "En el contexto de la ciencia de datos, explica qué diferencias esenciales existen cuando hablamos de modelos de Inteligencia Artificial frente a un proyecto tradicional de software.",
      "difficulty": 2,
      "tags": [
        "gestion-proyectos",
        "ciencia-datos"
      ],
      "modelAnswer": "## Proyectos de IA vs Software Tradicional\n\n### 1. Rol de los datos\n- **Software**: Los datos son una entrada más; el comportamiento se define con reglas explícitas programadas.\n- **IA**: Los datos son el **activo principal**. El sistema aprende reglas implícitas a partir de ellos.\n\n### 2. Naturaleza del comportamiento\n- **Software**: Hace exactamente lo que el programador codifica. Resultado determinista.\n- **IA**: El comportamiento **emerge del entrenamiento**. Las predicciones son probabilísticas.\n\n### 3. Ciclo de vida\n- **Software**: Análisis → Diseño → Desarrollo → Testing → Despliegue → Mantenimiento.\n- **IA**: Incluye fases adicionales: adquisición de datos, EDA, feature engineering, entrenamiento, evaluación, monitorización de data drift y reentrenamiento continuo.\n\n### 4. Gestión de la incertidumbre\n- **Software**: Comportamiento predecible y verificable mediante tests.\n- **IA**: Siempre existe margen de error cuantificado con métricas (accuracy, F1, AUC).\n\n### 5. Degradación en producción\n- **Software**: No se degrada si el código no cambia.\n- **IA**: Puede degradarse por *data drift* o *concept drift*, requiriendo reentrenamiento.\n\n### 6. Perfiles del equipo\n- **Software**: Desarrolladores, QA, arquitectos de software.\n- **IA**: Añade data scientists, ML engineers, MLOps, expertos de dominio para etiquetado.",
      "keywords": [
        "IA vs software",
        "ciclo de vida",
        "data drift",
        "incertidumbre",
        "MLOps",
        "iterativo"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:0ce91fc191bdb2857d6f007025f2c213c3f8ecd27cb6ddae0b2f014a7c9138ee",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "aaff9803-4146-4b1b-aace-309db326cff3",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "El algoritmo original de **Boosting**:",
      "explanation": "Según el temario, el algoritmo original se atribuye a **Schapire y Singer (1996)**.",
      "difficulty": 2,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Fue propuesto por Freund y Schapire en 1996."
        },
        {
          "id": "b",
          "text": "Fue propuesto por Freund y Shapire en 1977."
        },
        {
          "id": "c",
          "text": "Fue propuesto por Schapire y Singer en 1996."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:0f9c4ebd85a6f1795f0dbf8d6d2f1c306cc2b08f7b51db1dfddbe5a4fdf5b0be",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "abd02ae6-3e5a-4584-b037-23f9cce8470e",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "En el algoritmo Random Forest, ¿qué es el **Out-of-Bag (OOB) error**?",
      "explanation": "El **OOB error** se estima con las observaciones que quedan **fuera** de la muestra *bootstrap* usada para entrenar cada árbol (instancias no utilizadas para ese árbol).",
      "difficulty": 2,
      "tags": [
        "random-forest",
        "oob",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "El error en el conjunto de prueba."
        },
        {
          "id": "b",
          "text": "El error en el conjunto de entrenamiento."
        },
        {
          "id": "c",
          "text": "El error en las instancias no utilizadas durante el entrenamiento."
        },
        {
          "id": "d",
          "text": "El error en el conjunto de validación."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:5ee7d629ad1600520120af82d314cd2308923284332c1981af03ef1fe95db8b6",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "b1a25422-e4ae-48fc-bc8a-65b27975afbb",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "9d6276cf-e9aa-48ad-a074-fe7ce913673d",
      "type": "DESARROLLO",
      "prompt": "Describe en qué consisten los algoritmos evolutivos (o genéticos) y propón un problema que pueda ser tratado con ellos.",
      "difficulty": 2,
      "tags": [
        "computacion-bioinspirada",
        "optimizacion"
      ],
      "modelAnswer": "## Algoritmos Evolutivos (Genéticos)\n\n### Qué son\nMétodos de optimización inspirados en la evolución biológica darwiniana. Operan sobre una **población de soluciones candidatas** que evolucionan iterativamente mediante operadores inspirados en la genética.\n\n### Componentes principales\n1. **Codificación**: Cada solución se representa como un cromosoma (cadena de bits, valores reales o permutaciones).\n2. **Función de fitness**: Evalúa la calidad de cada solución.\n3. **Selección**: Los individuos con mayor fitness tienen mayor probabilidad de ser padres (ruleta, torneo).\n4. **Cruce (crossover)**: Combina dos padres generando hijos que heredan características de ambos.\n5. **Mutación**: Introduce cambios aleatorios para mantener diversidad y evitar convergencia prematura.\n6. **Reemplazo**: Los hijos sustituyen a los individuos menos aptos.\n\n### Ciclo\n`Población inicial → Evaluación → Selección → Cruce + Mutación → Nueva generación → [repetir hasta convergencia]`\n\n### Problema propuesto: Optimización de rutas logísticas (TSP)\nUna empresa de distribución tiene 20 clientes. Objetivo: minimizar la distancia total recorrida.\n\n- **Codificación**: Permutación de los 20 clientes.\n- **Fitness**: Distancia total de la ruta (minimizar).\n- **Cruce**: Order Crossover (OX).\n- **Mutación**: Intercambio aleatorio de dos clientes en la permutación.\n\nCon 20 clientes existen 20! ≈ 2,4×10¹⁸ rutas posibles. El algoritmo converge a soluciones de alta calidad sin búsqueda exhaustiva.",
      "keywords": [
        "algoritmo genético",
        "evolutivo",
        "fitness",
        "cruce",
        "mutación",
        "selección",
        "TSP",
        "optimización"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:7850a9c7262d3587a45b8c6e9b7dada7058070ae78cef73e388d300ae6663e13",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "b25f6deb-3562-462f-883e-ff55d68dfde1",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Si dos eventos son exhaustivos:",
      "explanation": "Dos eventos exhaustivos **cubren todos los casos**: necesariamente ocurre **al menos uno** ($A\\cup B=\\Omega$).",
      "difficulty": 1,
      "tags": [
        "probabilidad",
        "eventos",
        "exhaustivos"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Deben ocurrir los dos."
        },
        {
          "id": "b",
          "text": "Al menos uno de los dos debe ocurrir."
        },
        {
          "id": "c",
          "text": "Si uno ocurre el otro no puede ocurrir."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores describe la exhaustividad."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:6b7c8d9e0f1a2b3c4d5e6f708192a3b4c5d6e7f8091a2b3c4d5e6f708192a3b4",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "b3b52623-e5ad-46c9-997c-606da37f70c9",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "Son parte de las técnicas para imputar datos ausentes:",
      "explanation": "En el tema se consideran como técnicas de tratamiento de datos ausentes tanto el enfoque probabilístico como la eliminación de registros/atributos con ausentes y la imputación simple (media/mediana/moda).",
      "difficulty": 1,
      "tags": [
        "datos-ausentes",
        "imputacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Enfoque probabilísticos."
        },
        {
          "id": "b",
          "text": "A, C y D son verdaderas."
        },
        {
          "id": "c",
          "text": "Imputación por eliminación."
        },
        {
          "id": "d",
          "text": "Imputación por media, mediana y moda."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:5dc445d2c4f1c39c5f7f1ff4a97b1b9a24fd463b96bbf0a6b48c0f7b2c18b6a1",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "b44a586f-26b0-4c0d-ac79-2531a7f699eb",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a1245be8-e251-419a-bcdc-c822fd0e4750",
      "type": "DESARROLLO",
      "prompt": "Explica cómo el razonamiento inductivo se aplica en la investigación de inteligencia artificial para formular generalizaciones a partir de observaciones específicas.",
      "difficulty": 2,
      "tags": [
        "metodologia",
        "ciencia"
      ],
      "modelAnswer": "## Razonamiento Inductivo en IA\n\n### Qué es\nEl **razonamiento inductivo** consiste en derivar conclusiones generales a partir de observaciones particulares. Va de lo concreto a lo general. ⚠️ Las conclusiones son probabilísticas, no absolutas.\n\n### Relación directa con el ML\nEl **machine learning es razonamiento inductivo computacional**: el algoritmo observa muchos ejemplos (datos de entrenamiento) y genera un modelo (generalización) aplicable a nuevos casos.\n\n### Ejemplos en IA\n\n**Ejemplo 1 – Clasificación de imágenes médicas**:\nUn radiólogo etiqueta 10.000 RMN: los tumores benignos tienen bordes regulares, los malignos irregulares. Una CNN aprende esta generalización inductivamente y la aplica a imágenes nuevas.\n\n**Ejemplo 2 – Detección de spam**:\nEn miles de correos etiquetados como spam aparecen con alta frecuencia \"oferta\", \"gratis\", \"urgente\". El modelo induce que estos términos son indicativos de spam.\n\n**Ejemplo 3 – Formulación de hipótesis**:\nSe observa que los transformers superan consistentemente a las RNN en PLN. Se induce la hipótesis: *\"Los transformers generalizan mejor que las RNN en tareas de PLN\"*, que luego se verifica experimentalmente.",
      "keywords": [
        "razonamiento inductivo",
        "generalización",
        "machine learning",
        "hipótesis",
        "método científico"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:eb12353dffc03c03a4166e869666c7ed1934e096b9467527562930724ae855a3",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "b5adf1cf-db16-4b4c-9cbe-1484d321afef",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "072afd6b-bd5a-417f-bd3c-30c5b25b56ec",
      "type": "TEST",
      "prompt": "Si un servicio externo (*embeddings* o LLM) está lento o caído, ¿qué patrón operativo es más adecuado?",
      "explanation": "Con *timeouts/retries* controlas bloqueos; con degradación y *fallback* mantienes servicio mínimo; con presupuestos evitas sobrecostes durante incidentes.",
      "difficulty": 3,
      "tags": [
        "operaciones",
        "timeouts",
        "reintentos",
        "degradacion",
        "fallback",
        "coste"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Aumentar el *top-k* y esperar."
        },
        {
          "id": "b",
          "text": "Definir *timeouts* y reintentos; activar modos degradados y *fallback* de modelo; limitar presupuesto de tokens."
        },
        {
          "id": "c",
          "text": "Subir temperatura para «acelerar»."
        },
        {
          "id": "d",
          "text": "Desactivar los registros para ahorrar tiempo."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:6c5b4a392817161514131211100f0e0d0c0b0a09080706050403020100ffeeddcc",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "b8993902-8e25-4657-ba55-8d79aed9044f",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "b225751e-e66f-4b40-9d10-c0b84fe478a3",
      "type": "TEST",
      "prompt": "Quieres mejorar calidad antes de considerar **fine-tuning**. ¿Qué secuencia es más sensata?",
      "explanation": "Primero reduces ambigüedad (instrucciones), luego mejoras señal (recuperación) y finalmente mides/aseguras (golden set + guardrails). Es más barato y estable que escalar a ciegas.",
      "difficulty": 3,
      "tags": [
        "optimizacion",
        "prompt",
        "retrieval",
        "golden-set",
        "guardrails",
        "fine-tuning"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Comprar más GPU y aumentar el tamaño del modelo."
        },
        {
          "id": "b",
          "text": "Subir *k* al máximo y confiar en que mejore."
        },
        {
          "id": "c",
          "text": "Afinar instrucciones/formatos → mejorar recuperación (*re-ranking*, filtros) → validar con *golden set* y *guardrails*."
        },
        {
          "id": "d",
          "text": "Cambiar de modelo en cada fallo."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:9c8b571f1cfa9f1f7f70dbef3c1f405ec5f4bb3d3f5d0f9c1a3e37d7b252a73d",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "b9425891-2a97-427f-b8ec-b4449d9c39cd",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "6. ¿Cuál de las siguientes métricas MAE, MSE o RMSE de los modelos de regresión es más robusta a los valores anómalos?",
      "explanation": "**MAE** usa error **absoluto** y crece linealmente con el tamaño del error, por lo que es **menos sensible** a valores extremos que **MSE/RMSE**, que elevan el error al cuadrado y amplifican outliers.",
      "difficulty": 2,
      "tags": [
        "regresión",
        "MAE",
        "MSE",
        "RMSE",
        "outliers"
      ],
      "options": [
        {
          "id": "a",
          "text": "La métrica más robusta es el MAE ya que El MAE penaliza de manera significativa los errores grandes en las predicciones, asignando un peso proporcional al cuadrado de la diferencia entre la predicción y el valor real."
        },
        {
          "id": "b",
          "text": "Las métricas más robustas son MSE o RMSE dado que no se ven afectadas por los valores extremos debido al término del cuadrado."
        },
        {
          "id": "c",
          "text": "La métrica más robusta es el MAE dado que se calcula tomando el promedio de las diferencias absolutas de las predicciones y los valores reales."
        },
        {
          "id": "d",
          "text": "El RMSE siempre produce un valor más pequeño que MAE, lo que demuestra que es una métrica más precisa y robusta en todos los casos de evaluación de modelos de regresión."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "createdBy": "Luis",
      "sourcePackId": "c28801ab-40f1-46bb-938b-9d886992b1a0",
      "contentHash": "sha256:93d64bfc4563ccd2081b80b207ad42a73c27e10a7c5d63f08dc2c5b30269e30f",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "b9c18c7b-a21c-4c2d-a449-01f060414f55",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Un modelo con gran valor de precisión:",
      "explanation": "Precisión (PPV): $$\\text{Precision} = \\frac{TP}{TP+FP}$$. Alta precisión ⇒ pocos **falsos positivos**.",
      "difficulty": 2,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Indica que la mayoría de las veces que se predice la clase negativa está en lo cierto."
        },
        {
          "id": "b",
          "text": "Indica que la mayoría de las veces que se predice la clase positiva está en lo cierto."
        },
        {
          "id": "c",
          "text": "Indica que el modelo es completamente impreciso y aleatorio."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:90f9b6c55d3d2fb39b24c7d3a8b8d4a3a5e6d1b0a0b4d9cdbda54c0ed0f7e3c2",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "bd373e0e-9d68-40da-a421-0a4b09429f76",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "La siguiente línea de código `dataset.dropna(inplace=True)` representa:",
      "explanation": "`dropna` elimina los registros (por defecto, filas) que contienen valores faltantes. Con `inplace=True` modifica el `dataset` directamente.",
      "difficulty": 1,
      "tags": [
        "datos-ausentes",
        "pandas"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Imputación de valores mediante el enfoque probabilístico."
        },
        {
          "id": "b",
          "text": "Imputación de valores mediante el algoritmo de esperanza-maximización."
        },
        {
          "id": "c",
          "text": "Imputación por eliminación."
        },
        {
          "id": "d",
          "text": "Imputación por media."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:25e02ccf6609a2c1c85e9c3e31f6a8d2d85c49ae6d8b0891e12f8c2af4f9f4b4",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "c1ce0d01-4e81-4283-b61b-97518e9aa205",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "33ab0c5f-8035-43a2-8314-55bdc07b4b6d",
      "type": "TEST",
      "prompt": "¿Para qué sirve ejecutar un **golden set** tras actualizar el índice o el flujo?",
      "explanation": "El *golden set* actúa como test de regresión: detecta desvíos en recuperación y caídas de calidad tras cambios en índice/flujo.",
      "difficulty": 2,
      "tags": [
        "golden-set",
        "regresion",
        "calidad",
        "rag",
        "validacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Para medir solo la latencia p95."
        },
        {
          "id": "b",
          "text": "Para entrenar de nuevo el LLM."
        },
        {
          "id": "c",
          "text": "Para comprobar sanidad: que las consultas esperadas recuperen pasajes correctos y que se mantenga la calidad tras cambios."
        },
        {
          "id": "d",
          "text": "Para aumentar el tamaño de la ventana de contexto."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:3c2d1e0f9a8b7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b9c8d7e6f5a4b3c2d",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "c2ec5437-a8e7-4033-bfd9-0d7f0e2a944c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "2. Se tiene un conjunto de datos médicos de registro de signos vitales de pacientes de un servicio de UCI adulto: presión arterial, frecuencia cardiaca, temperatura y frecuencia respiratoria. En este conjunto de datos existe un 5% de datos faltantes en la presión arterial y en la frecuencia respiratoria. ¿Cuál sería la mejor estrategia para trabajar con los datos faltantes?",
      "explanation": "Con un **5%** de datos faltantes no suele compensar eliminar filas (pierdes información) y, en *signos vitales* por paciente, una imputación **intra-paciente** suele ser más realista que media/moda global.\n\nUsar una **medición previa del mismo paciente** es equivalente a una imputación temporal tipo *last observation carried forward* y respeta la variabilidad entre pacientes.",
      "difficulty": 2,
      "tags": [
        "datos faltantes",
        "imputación",
        "MAR/MCAR",
        "series temporales clínicas"
      ],
      "options": [
        {
          "id": "a",
          "text": "Eliminarlos."
        },
        {
          "id": "b",
          "text": "Reemplazarlos por el promedio de todos los los valores de presión arterial y frecuencia respiratoria.."
        },
        {
          "id": "c",
          "text": "Reemplazarlos por la moda de todos los valores de presión arterial y frecuencia respiratoria."
        },
        {
          "id": "d",
          "text": "Reemplazar el valor faltante de presión arterial y frecuencia respiratoria por una medición anterior del mismo paciente."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "createdBy": "Luis",
      "sourcePackId": "c28801ab-40f1-46bb-938b-9d886992b1a0",
      "contentHash": "sha256:5bb330b2a5ab631a54c2fe674b378a0ac1b82c5d17c82efdfe999c6a5c71a357",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "c30efa52-17e5-43d3-88b0-1d0fc41b0b5a",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "Señala la afirmación correcta. El número de modelos necesarios para converger a un óptimo global:",
      "explanation": "El número de modelos necesarios para converger a un óptimo global puede variar significativamente dependiendo de varios factores, como el algoritmo de optimización utilizado, la complejidad del problema, el conjunto de datos y la configuración de hiperparámetros. Por lo tanto, es importante considerar este aspecto al establecer el criterio de parada durante el proceso de optimización.",
      "difficulty": 3,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "criterio-de-parada",
        "convergencia"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Por lo general es siempre el mismo."
        },
        {
          "id": "b",
          "text": "Puede variar bastante y el criterio de parada lo debe considerar."
        },
        {
          "id": "c",
          "text": "No es algo que debe ser tenido en cuenta."
        },
        {
          "id": "d",
          "text": "Debe estar predefinido por el ingeniero de machine learning."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:7f6e5d4c3b2a1908f7e6d5c4b3a29108f7e6d5c4b3a29108f7e6d5c4b3a29108",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "c5b1e42c-6d41-4b64-9736-27afeeb68edf",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "Está creando una solución de aprendizaje automático para un centro de llamadas. El objetivo\ndel sistema es dirigir a los clientes al departamento apropiado, y hay ocho departamentos\nposibles. ¿Qué tipo de problema de aprendizaje automático describe esta solución?",
      "explanation": "Sí. Hay ocho categorías posibles (departamentos), así que el sistema decide entre más de dos clases → clasificación multiclase.\n\n✅ C. Clasificación multiclase.\n\nPor qué las otras no:\n\nA (falsa): clustering es no supervisado y no asigna a clases predefinidas como “departamentos”.\n\nB (falsa): binaria sería solo 2 opciones, aquí hay 8.\n\nD (falsa): anomalías es detectar casos raros, no enrutar a una de varias categorías.",
      "difficulty": 1,
      "options": [
        {
          "id": "72e92e87-b7f1-408f-9e43-38b1b4df161e",
          "text": "Agrupación en clusteres."
        },
        {
          "id": "88e38ad9-35ed-4de5-903c-8e216a5dc3e8",
          "text": "Clasificación binaria."
        },
        {
          "id": "abcea569-1a0f-4090-a99f-2a7ca64671d6",
          "text": "Clasificación multiclase."
        },
        {
          "id": "994e21e9-8ac0-485a-bab3-7f803213b2c3",
          "text": "Detección de anomalías."
        }
      ],
      "correctOptionIds": [
        "abcea569-1a0f-4090-a99f-2a7ca64671d6"
      ],
      "createdBy": "",
      "contentHash": "sha256:bce1041909f87b1692b0c1f968461ed976eb178e216c36ebb8518d0a342fcfdd",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "c5ba0a1f-bacd-49c3-8a49-ebf918faa603",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "3db70205-fc8e-43aa-8f36-67eefa0d682c",
      "type": "TEST",
      "prompt": "La siguiente línea de código `imputer = SimpleImputer(missing_values=nan, strategy='mean')` representa:",
      "explanation": "`SimpleImputer(..., strategy='mean')` rellena los valores `NaN` usando la **media** de cada característica.",
      "difficulty": 1,
      "tags": [
        "imputacion",
        "sklearn"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Imputación de valores mediante el enfoque probabilísticos."
        },
        {
          "id": "b",
          "text": "Imputación de valores mediante el algoritmo de esperanza-maximización."
        },
        {
          "id": "c",
          "text": "Imputación por eliminación."
        },
        {
          "id": "d",
          "text": "Imputación por media."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:92f3b51a81b7a8b1dbf3b7c2cbd38b8a2a0e2f2f7a83bbacdd83f3a5ef4a5c30",
      "createdBy": "Luis",
      "sourcePackId": "0e6eac3f-f1c3-4e03-a88f-2b73adab0167",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:19:20.692Z",
      "updatedAt": "2026-02-20T23:19:20.692Z"
    },
    {
      "id": "c5e767b8-5ca4-4eee-ac56-e73325eb40e1",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "PRACTICO",
      "prompt": "### Evaluación de un clasificador de manzanas enfermas (métricas)\n\nSe ha utilizado un clasificador (p. ej. **Random Forest**) para clasificar imágenes de manzanas y detectar enfermedad:\n\n- Clase **0**: sana (negativa)  \n- Clase **1**: enferma (positiva)\n\nResultados:\n\n| Imagen | Clase Real | Clase predicha |\n|---|---|---|\n| Img1 | 0 | 0 |\n| Img2 | 0 | 0 |\n| Img3 | 1 | 1 |\n| Img4 | 1 | 1 |\n| Img5 | 0 | 1 |\n| Img6 | 1 | 1 |\n| Img7 | 1 | 1 |\n| Img8 | 0 | 0 |\n| Img9 | 0 | 1 |\n| Img10 | 0 | 0 |\n\n\nSe pide:\n\n1. Calcular **precision**, **recall**, **accuracy** y **F1** para estos resultados de clasificación **para las dos clases**.  \n2. Explica el comportamiento del clasificador y si cumpliría la tarea de detectar manzanas enfermas correctamente.  \n3. Analiza el valor de **sensibilidad**: ¿qué indica este valor? Explica.\n\n> Origen: **Examen anterior** (UNIR **TAA 2024**, **Modelo F**, código **10210068**).\n",
      "explanation": "Aquí la métrica crítica es la **sensibilidad/recall** de la clase 1: vale 1.0 → no se escapa ninguna enferma. A cambio tienes FP (falsas alarmas), que se traducen en coste de revisión.",
      "difficulty": 4,
      "tags": [
        "examen anterior",
        "UNIR",
        "2024",
        "modelo-f",
        "métricas",
        "sensibilidad",
        "manzanas",
        "enfermedad"
      ],
      "modelAnswer": "Tomamos **1 (enferma)** como clase positiva.\n\n## Conteos (positiva = 1)\n- **TP (1→1)**: Img3, Img4, Img6, Img7 = **4**\n- **FN (1→0)**: **0**\n- **TN (0→0)**: Img1, Img2, Img8, Img10 = **4**\n- **FP (0→1)**: Img5, Img9 = **2**\nTotal = 10.\n\n## Métricas (positiva = 1, “enferma”)\n- **Precision(1)** = TP/(TP+FP) = 4/(4+2) = **0.67**\n- **Recall(1)** = TP/(TP+FN) = 4/(4+0) = **1.00**\n- **Accuracy** = (TP+TN)/Total = (4+4)/10 = **0.80**\n- **F1(1)** = 2·P·R/(P+R) = 2·0.67·1/(0.67+1) = **0.80**\n\n## Métricas para la otra clase (0, “sana”)\nPara **0** como positiva (one-vs-rest):\n- TP(0)=4, FP(0)=0, FN(0)=2, TN(0)=4\n- **Precision(0)** = 4/(4+0) = **1.00**\n- **Recall(0)** = 4/(4+2) = **0.67**\n- **F1(0)** = **0.80**\n- **Accuracy** = **0.80**\n\n## Interpretación\n- Para detectar manzanas **enfermas**, el punto fuerte es el **recall = 1.0**: **no se escapa ninguna enferma** (FN=0).  \n- El problema es que mete **falsos positivos** (2 sanas marcadas como enfermas), lo que reduce precision (0.67).\n\nSi el objetivo es “mejor que sobre y no que falte” (seguridad/prevención), este comportamiento suele ser **aceptable**: revisas manualmente las marcadas como enfermas y no dejas pasar enfermas.\n\n## Sensibilidad\nEn clasificación binaria, **sensibilidad = recall de la clase positiva** = TP/(TP+FN).  \nAquí es **1.0**, lo que significa: *de todas las manzanas realmente enfermas, el modelo identifica el 100%*.",
      "createdBy": "Luis",
      "sourcePackId": "eda08197-7337-49c1-9767-1933b50cca25",
      "contentHash": "sha256:77e47bc9355f061a8c3bac6a013e1c8e54d09c97f0c3d6b53402699e5b90a7ee",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "c65647be-b015-4b10-ac5a-dbd6419f058e",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones describe correctamente el **compromiso sesgo-varianza** en un modelo de *machine learning*?\n\nSeleccione una:",
      "explanation": "Sesgo alto → modelo demasiado simple (subajuste). Varianza alta → modelo demasiado sensible a los datos de entrenamiento (sobreajuste).",
      "difficulty": 2,
      "tags": [
        "sesgo-varianza",
        "overfitting",
        "underfitting"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "El compromiso sesgo-varianza se refiere a la relación entre el sesgo y la varianza de un modelo, donde un sesgo alto puede llevar a un subajuste y una varianza alta puede llevar a un sobreajuste."
        },
        {
          "id": "b",
          "text": "El compromiso sesgo-varianza solo se aplica a modelos de regresión y no a otros tipos de modelos de machine learning."
        },
        {
          "id": "c",
          "text": "Un modelo con bajo sesgo y alta varianza generalmente se ajusta bien a los datos de entrenamiento y generaliza bien a nuevos datos."
        },
        {
          "id": "d",
          "text": "El compromiso sesgo-varianza no es relevante en el contexto de machine learning y no afecta el rendimiento del modelo."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:cbd7b5002ba903afe755ce0f1bc85c8e5eafb76b164af592ba0974839457995e",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "ca35c5a9-948e-4620-a2ab-d6c5d128a72f",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Si usted está entrenando un modelo con un conjunto de datos médicos para diagnóstico de una enfermedad rara. ¿Qué métricas de validación del modelo debería compartir para que los especialistas puedan concluir que es un buen modelo?",
      "explanation": "✅ **C. Calcular y explicar exactitud, sensibilidad y especificidad.**\n\nEn diagnóstico médico (y más si es una enfermedad rara), **accuracy sola** puede engañar; lo importante es reportar también:\n- **Sensibilidad (recall/TPR)**: cuántos enfermos detectas.\n- **Especificidad (TNR)**: cuántos sanos no etiquetas como enfermos.\n\n**Por qué no las otras:**\n- **A**: TP/TN sueltos no permiten comparar bien sin contexto (FP/FN).\n- **B**: la matriz de confusión ayuda, pero sin métricas resumidas obliga al médico a calcularlo “a mano”.\n- **D**: solo especificidad ignora la parte crítica (no dejar enfermos sin detectar).",
      "difficulty": 3,
      "options": [
        {
          "id": "5e237480-d1c8-4666-80d5-297168b927e7",
          "text": "Presentar los valores de verdaderos positivos y verdaderos negativos."
        },
        {
          "id": "c96e0aae-d318-43db-9e73-1fb00251f237",
          "text": "Mostrar la matriz de confusión."
        },
        {
          "id": "5c93b694-4276-49d0-bd34-883935099937",
          "text": "Calcular y explicar los resultados de exactitud, sensibilidad y especificidad."
        },
        {
          "id": "7a9ffce0-b691-4713-a9cb-2b80dc831d8c",
          "text": "Mostrar el resultado de especificidad ya que mide la tasa de casos negativos clasificados correctamente."
        }
      ],
      "correctOptionIds": [
        "5c93b694-4276-49d0-bd34-883935099937"
      ],
      "createdBy": "",
      "sourcePackId": "contribution-2026-02-18-julio-modelosB-C-new-6f543832",
      "contentHash": "sha256:dca1ce9fe4b01f45cad09a743794687538015db54976b7622e6c8ee8739e4ce9",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "cb4ac2af-e349-4486-93a4-c287aaee6f1c",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "Son características generales del método **Bagging**:",
      "explanation": "Bagging reduce sobre todo **varianza**: modelos homogéneos, entrenamiento **en paralelo**, agregación por **voto/promedio**.",
      "difficulty": 2,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Reduce bias o sesgo, su aprendizaje base es homogéneo, su entrenamiento base es secuencial, y su método de agregación es peso promedio."
        },
        {
          "id": "b",
          "text": "Mejora exactitud, su aprendizaje base es heterogéneo, su entrenamiento base es secuencial, y su método de agregación es peso promedio."
        },
        {
          "id": "c",
          "text": "Reduce varianza, es homogéneo, el entrenamiento es en paralelo, y la predicción está dada por el voto mayoritario o promedio."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:2e2e5ac2852e90ab1a8a6d0c19c8b2a6a4bb50a2a6c8d9e8c3d9a6d8f1e2a3b4",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "cc4eb31c-2f77-489f-950f-d8e1cdef4447",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "En el aprendizaje automático:",
      "explanation": "El train se usa para ajustar el modelo y el test para evaluar generalización; un error bajo en train no garantiza error bajo en test (overfitting).",
      "difficulty": 1,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "El conjunto de entrenamiento se utiliza para construir un modelo."
        },
        {
          "id": "b",
          "text": "El conjunto de test se utiliza para evaluar un modelo."
        },
        {
          "id": "c",
          "text": "Si un modelo tiene un error mínimo en el conjunto de entrenamiento también lo tendrá en el conjunto de test."
        },
        {
          "id": "d",
          "text": "Todas las anteriores son correctas."
        }
      ],
      "correctOptionIds": [
        "a",
        "b"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:ca81c816ac6aef6bff7f2481b1f5a7bcb4a4388a2b08cc1c1a1d2b99a888aa64",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "cc93fc89-111b-4ba3-bd8a-7e47ca4382bb",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes opciones describe correctamente la **ganancia de información** en árboles de decisión?",
      "explanation": "Definición: $$IG = H(\\text{padre}) - \\sum_{i} \\frac{n_i}{n} H(\\text{hijo}_i)$$",
      "difficulty": 3,
      "tags": [
        "ganancia-de-informacion",
        "entropia",
        "splits"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "La ganancia de información mide la pureza de un nodo en un árbol de decisión, donde un valor más alto indica una mayor homogeneidad en las clases."
        },
        {
          "id": "b",
          "text": "La ganancia de información se utiliza para seleccionar la característica que divide un conjunto de datos de la manera más equitativa posible, sin favorecer una clase sobre otra."
        },
        {
          "id": "c",
          "text": "La ganancia de información se calcula como la diferencia entre la entropía del nodo padre y la suma ponderada de las entropías de los nodos hijos después de una división."
        },
        {
          "id": "d",
          "text": "La ganancia de información asigna un valor de 0 cuando todas las muestras en un nodo pertenecen a la misma clase, lo que indica una falta de variabilidad en las clases objetivo."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:2fb6c815212e9e654d05bdc4a46b06c39b2d2854bcb968ab9efec2a894116b48",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "cd8e436c-9340-49fb-a7bd-8b3ea496f1ca",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "En los problemas de clasificación:",
      "explanation": "En clasificación la variable respuesta es categórica: puede ser binaria (2 clases) o multiclase (>2).",
      "difficulty": 1,
      "tags": [
        "tema1",
        "practica",
        "test"
      ],
      "options": [
        {
          "id": "a",
          "text": "La variable respuesta contiene siempre más de dos categorías."
        },
        {
          "id": "b",
          "text": "La variable respuesta contiene siempre dos o más categorías."
        },
        {
          "id": "c",
          "text": "La variable respuesta es de tipo numérico."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores es correcta."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "createdBy": "Luis",
      "sourcePackId": "43f6e3ff-acf6-49ad-b9ba-82c7817ef4d9",
      "contentHash": "sha256:ad79fbf6f548a6f9fd4dfb5d346d5c0f8ac32a0d021fd2df4fe3f41d3a0d3b89",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "cdbdd672-357e-4db7-9e57-3a7335727a8b",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "9d6276cf-e9aa-48ad-a074-fe7ce913673d",
      "type": "DESARROLLO",
      "prompt": "En el contexto del aprendizaje automático, explica en qué consiste la validación cruzada (cross validation) y pon un ejemplo de cómo aplicarlo.",
      "difficulty": 2,
      "tags": [
        "aprendizaje-automatico",
        "evaluacion"
      ],
      "modelAnswer": "## Validación Cruzada (Cross Validation)\n\n### Qué es\nTécnica de evaluación de modelos que estima el rendimiento generalizable usando todos los datos disponibles, reduciendo sesgo y varianza frente a una única partición train/test.\n\n### Funcionamiento: k-fold cross validation\n1. El dataset se divide en **k partes iguales (folds)**.\n2. Se realizan **k iteraciones**: en cada una, k-1 folds para entrenamiento y 1 para validación.\n3. La métrica se calcula en cada iteración.\n4. El resultado es la **media ± desviación estándar** de las k métricas.\n\n**Ventaja clave**: Todos los datos se usan tanto para entrenamiento como para validación.\n\n### Variantes\n- **Stratified k-fold**: Mantiene la proporción de clases en cada fold (datasets desbalanceados).\n- **Leave-One-Out (LOO)**: k = n. Costoso; útil con datasets muy pequeños.\n- **Time Series Split**: Respeta el orden temporal para no usar datos futuros.\n\n### Ejemplo (k = 5, clasificación de churn)\nDataset: 1.000 clientes.\n1. Dividir en 5 folds de 200 clientes.\n2. Iteración 1: Train = folds 2,3,4,5 → Test = fold 1 → F1: 0,82\n3. Iteración 2: Train = folds 1,3,4,5 → Test = fold 2 → F1: 0,79\n4. ... hasta la iteración 5.\n5. **Resultado**: F1 promedio = 0,81 ± 0,03\n\nEsta estimación es mucho más fiable que evaluar el modelo una única vez.",
      "keywords": [
        "validación cruzada",
        "k-fold",
        "stratified",
        "leave-one-out",
        "generalización",
        "sobreajuste"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:a3588da5704d1fd88efbca49c7624ae511091d8eec84eed844065485eb7af30f",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "ce56ce77-1190-4c12-a24b-27f649f277d2",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "388275e1-be5b-44fd-8fbd-52591fd74159",
      "type": "TEST",
      "prompt": "Si **recall@k** es alto pero el **MRR (Mean Reciprocal Rank)** es bajo, ¿qué sugiere?",
      "explanation": "El relevante aparece dentro del top-*k* (recall alto), pero suele estar muy abajo (MRR bajo). Eso apunta a un problema de ordenación → *re-ranking*.",
      "difficulty": 3,
      "tags": [
        "retrieval",
        "recall@k",
        "mrr",
        "ranking",
        "reranking"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Hay pocos documentos relevantes en el corpus."
        },
        {
          "id": "b",
          "text": "Recuperas lo relevante, pero mal ordenado; necesitas *re-ranking*."
        },
        {
          "id": "c",
          "text": "El *k* es demasiado bajo."
        },
        {
          "id": "d",
          "text": "La ventana de contexto es insuficiente."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:1e0ce7a1d6b4e52b2f3b9f4a1aee6b2401a51b7bfc8b7c0f53e0c7a94d5f8a4e",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "d09a8767-e4b6-4711-a22d-975923299326",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "¿En qué contexto sería preferible utilizar **Extra Trees** en lugar de Random Forest?",
      "explanation": "Si se prioriza **rapidez de entrenamiento**, Extra Trees puede ser preferible por su construcción más aleatoria.",
      "difficulty": 2,
      "tags": [
        "extra-trees",
        "comparacion",
        "entrenamiento"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Cuando se busca una mayor interpretabilidad del modelo."
        },
        {
          "id": "b",
          "text": "Cuando se tiene un conjunto de datos pequeño."
        },
        {
          "id": "c",
          "text": "Cuando se desea mayor velocidad de entrenamiento."
        },
        {
          "id": "d",
          "text": "Cuando se necesita un modelo altamente preciso."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:5665765fe4223b0aa409df7b28eb6c3d07c95a53bbd59995de5d7351f4529915",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "d1244911-3389-4235-8df9-0f588b291b73",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "¿Qué suposición se hace sobre la independencia de las variables en Naïve Bayes?",
      "explanation": "Naïve Bayes asume **independencia (condicional) entre variables** dado la clase, para simplificar el cálculo de la verosimilitud.",
      "difficulty": 1,
      "tags": [
        "independencia",
        "naive-bayes"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Las variables son dependientes entre sí."
        },
        {
          "id": "b",
          "text": "Las variables son independientes entre sí."
        },
        {
          "id": "c",
          "text": "No se hace ninguna suposición con respecto a las variables."
        },
        {
          "id": "d",
          "text": "La dependencia o independencia de las variables no es de interés para el algoritmo."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:5a32f1a6b60e4f1a7db1f0f7f9e5c0a5c0b1f2a3b4c5d6e7f8a9b0c1d2e3f4a5",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "d2c262f2-e26e-4a3f-bf3d-b89e44c06b95",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "Un científico de datos está utilizando árboles de decisión para clasificar clientes en dos categorías: \"Comprador\" y \"No Comprador\". Durante el proceso de construcción del árbol, elige la variable \"Ingresos Anuales\" como la primera característica para dividir los datos. Sin embargo, nota que el árbol resultante tiene muchas divisiones, algunas de las cuales parecen específicas para casos excepcionales en el conjunto de entrenamiento.¿Cuál de las siguientes acciones sería una estrategia efectiva para abordar el sobreajuste en este árbol de decisión?",
      "explanation": "✅ C. Aplicar la poda del árbol (pruning).\n\nLa poda reduce complejidad y elimina ramas específicas del entrenamiento, mitigando el sobreajuste.\n\nPor qué no:\n- A: más profundidad suele empeorar el sobreajuste.\n- B: menos datos normalmente empeora generalización.\n- D: tasa de aprendizaje no aplica a árboles de decisión clásicos.",
      "difficulty": 2,
      "options": [
        {
          "id": "40f16cd7-5c4b-45bd-bfb5-4ec998e5684d",
          "text": "Incrementar la profundidad máxima del árbol."
        },
        {
          "id": "6ee902d9-77ae-4d4a-8c70-01cc9702233f",
          "text": "Utilizar un conjunto de datos de entrenamiento más pequeño."
        },
        {
          "id": "582af831-7cb4-42a6-b380-2019fd79d67a",
          "text": "Aplicar la poda del árbol (pruning)."
        },
        {
          "id": "e8427a60-ed0d-4415-ae2c-05273cd1e97d",
          "text": "Aumentar la tasa de aprendizaje."
        }
      ],
      "correctOptionIds": [
        "582af831-7cb4-42a6-b380-2019fd79d67a"
      ],
      "createdBy": "",
      "sourcePackId": "9a48d918-0ffe-4d28-9f78-0c2350dcfe9c",
      "contentHash": "sha256:d00ba6582f44eb3194721fa1a53b46e07f87031e3653be0617f5c6f37d2f344c",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "d2e46a19-d86c-4861-b31f-4497655f8acf",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5fd196fa-df50-4e1a-8e3e-e3a27f407591",
      "type": "TEST",
      "prompt": "¿Cuáles son los pasos que sigue el método **Bagging**?",
      "explanation": "Bagging = **bootstrap aggregating**: se crean *bootstrap samples* (con reemplazo), se entrenan modelos **en paralelo** e independientes, y se agregan (voto/promedio) sus predicciones.",
      "difficulty": 2,
      "tags": [
        "tema-9",
        "ensemble",
        "bagging",
        "boosting",
        "bootstrap"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Genera múltiples conjuntos de entrenamiento mediante muestreo con reemplazo, entrena en paralelo tantos clasificadores base como conjuntos de datos generados existan, combina las predicciones de cada clasificador base para obtener la predicción final."
        },
        {
          "id": "b",
          "text": "Genera múltiples conjuntos de entrenamiento mediante muestreo con reemplazo, entrena secuencialmente el clasificador base con cada conjunto de datos de entrenamiento generado (hasta no terminar un entrenamiento no puede continuar con el siguiente), combina las predicciones de cada clasificador base a través del voto mayoritario."
        },
        {
          "id": "c",
          "text": "Asigna pesos a cada muestra del conjunto de entrenamiento, inicialmente todos tienen el mismo peso. Entrena el modelo débil utilizando el conjunto de datos de entrenamiento ponderado con los pesos actuales. Calcula el error del modelo débil. Asigna pesos al modelo débil. Actualiza los pesos de las muestras y repite hasta alcanzar un criterio de parada. Combina los modelos débiles para formar un modelo fuerte."
        },
        {
          "id": "d",
          "text": "Genera múltiples conjuntos de entrenamiento mediante muestreo con reemplazo. Entrena el modelo débil utilizando el conjunto de datos de entrenamiento ponderado con los pesos actuales. Asigna pesos al modelo débil. Actualiza los pesos de las muestras y repite hasta alcanzar un criterio de parada. Combina los modelos débiles para formar un modelo fuerte."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:a243ea09a1a12f0fa229d262f7fb013081f9f29b9b34b0480a62a6b6c31f2d0a",
      "createdBy": "Luis",
      "sourcePackId": "f55988d5-2c1d-4f7a-865b-2ef36a712ff0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:16:43.076Z",
      "updatedAt": "2026-02-21T15:16:43.076Z"
    },
    {
      "id": "d5d23a84-db33-40de-929e-f1ff39253ae4",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "Señale la afirmación falsas sobre el aprendizaje automático:",
      "explanation": "No existe un algoritmo universal que sea el mejor para todo. El rendimiento depende del tipo de datos y del problema (clasificación, regresión, ruido, dimensionalidad, desbalanceo, etc.). Por eso hay que elegir modelo y validar.",
      "difficulty": 3,
      "options": [
        {
          "id": "60f6547c-a774-435e-bf34-27fce487ed54",
          "text": "Existe un solo algoritmo de aprendizaje automático que se puede adaptar a cualquier circunstancia."
        },
        {
          "id": "8ffe8ee1-c185-4255-b6bc-0d12ded4cb09",
          "text": "El aprendizaje automático es una de las áreas de la inteligencia artificial."
        },
        {
          "id": "53adef19-6c28-4656-b4f8-24d72deebef4",
          "text": "El aprendizaje profundo es un área del aprendizaje automático."
        },
        {
          "id": "9ca9f5fd-1461-4e63-8c81-c6274d4eb861",
          "text": "Aprendizaje automático y machine learning hacen referencia a lo mismo."
        }
      ],
      "correctOptionIds": [
        "60f6547c-a774-435e-bf34-27fce487ed54"
      ],
      "createdBy": "",
      "contentHash": "sha256:b0eb0947c9006c62a893ad5865d4585c66af23351ad506cc507c72224b9a767d",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "d5e3cacc-ab31-42b5-b1b0-c3067ce092dc",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "DESARROLLO",
      "prompt": "### Calidad del agua en Gorgoroth (razonamiento teórico)\n\nEl acceso al **agua potable** es esencial para la salud y un componente clave de la protección sanitaria.  \nEn la zona de **Gorgoroth** quieren invertir recursos para **mejorar la calidad del agua**, pero no saben cuál es la calidad actual ni si **varía a lo largo del año**.\n\n**Pregunta:**  \n¿Sería posible ayudar a los responsables de Gorgoroth a **predecir la calidad del agua** para controlar su contaminación?  \n¿Es un problema de **aprendizaje automático**? ¿Qué **tipo de problema** es y cómo se podría resolver con las **técnicas vistas en la asignatura**?\n\n> Origen: **Examen anterior** (UNIR, ordinaria **07–12/03/2025**, **Modelo E**).",
      "explanation": "La clave es definir una **variable objetivo medible** (índice o clase) y disponer de histórico para entrenar un modelo **supervisado**. El componente temporal obliga a evaluar con splits temporales.",
      "difficulty": 3,
      "tags": [
        "examen anterior",
        "definición del problema",
        "pipeline ML",
        "datos",
        "evaluación"
      ],
      "modelAnswer": "## Sí, se puede (si hay datos medibles)\n\nPara **predecir** la calidad del agua necesitas dos cosas:\n\n1. Una **variable objetivo** (`y`) que represente “calidad” de forma cuantificable. Ejemplos:\n   - Un **índice** continuo (p. ej. `WQI`, niveles de nitratos, E. coli, turbidez, pH, etc.).\n   - Una **etiqueta** por categorías (p. ej. `apta / no apta`, o `buena / media / mala`).\n\n2. Un histórico de **observaciones** (características `X`) que expliquen esa calidad.\n\nSin eso no hay magia: solo opiniones.\n\n## ¿Es aprendizaje automático? Sí (supervisado)\n\nSi tienes ejemplos de la forma:\n\n- `X =` mediciones y contexto (fecha, lugar, condiciones…)\n- `y =` calidad medida\n\nEntonces es un problema de **aprendizaje supervisado**.\n\n### Tipo de problema\nDepende de cómo definas `y`:\n\n- **Regresión** si `y` es **numérica continua** (p. ej. nivel de contaminante, índice de calidad).\n- **Clasificación** si `y` es una **clase** (p. ej. `apta/no apta`).\n\nAdemás, como preguntas por variación “a lo largo del año”, hay componente **temporal/estacional**:\n- O bien lo tratas como **series temporales**.\n- O lo tratas como regresión/clasificación estándar, pero añadiendo variables de **tiempo** (mes, estación, día del año) y/o retardos.\n\n## ¿Cómo lo resolvería con lo visto en la asignatura?\n\n### 1) Datos necesarios (lo que realmente importa)\n- **Mediciones del agua**: pH, turbidez, conductividad, nitratos, fosfatos, coliformes, metales pesados…\n- **Contexto**:\n  - Fecha/hora (para estacionalidad).\n  - Punto de muestreo (localización).\n  - Meteo e hidrología (lluvia, temperatura, caudal).\n  - Actividad humana (vertidos, agricultura, industria, población).\n\n### 2) Preparación (sin esto todo es basura)\n- **EDA** (Tema 2): distribuciones, outliers, correlaciones, estacionalidad.\n- **Datos ausentes** (Tema 3): imputación (media/mediana, KNN, modelos), o eliminación si es razonable.\n- **Normalización/estandarización** (Tema 3): necesaria si usas modelos sensibles a escala (p. ej. **SVM**).\n\n### 3) Modelos candidatos (según el tipo de `y`)\n**Si es regresión (Tema 4):**\n- Línea base: **regresión lineal** (rápida, interpretable).\n- Si hay no linealidad: **árboles** / **Random Forest** (Temas 6 y 10).\n- Para mejorar: **bagging/boosting** (Tema 9), y **optimización de hiperparámetros** (Tema 11).\n\n**Si es clasificación (Tema 5):**\n- Baselines: umbral sobre un índice, o modelos simples.\n- **SVM** (Tema 7) con escalado.\n- **Árboles / Random Forest** (Temas 6 y 10).\n- **Naïve Bayes** (Tema 8) si el enfoque es probabilístico y con variables bien tratadas.\n\n### 4) Evaluación correcta (clave para no autoengañarte)\n- **Regresión**: `MAE`, `MSE`, `RMSE`, `R²` (Tema 4).\n- **Clasificación**: matriz de confusión + `precision`, `recall`, `F1`, `accuracy` (Tema 5).\n\n**Muy importante:** si hay tiempo (estaciones), el split debe respetar el orden temporal:\n- Entrenar con meses/años anteriores y validar con posteriores (evitar “mirar el futuro”).\n\n## Uso práctico para “controlar la contaminación”\nUna vez entrenado:\n- Predices calidad futura y montas un **sistema de alertas** (p. ej. si `WQI` baja o si `P(no apta)` sube).\n- Priorizas inspecciones y **acciones preventivas** (saneamiento, cierre temporal, investigación de vertidos).\n- Monitorizas **deriva** (cambios de patrones) y reentrenas periódicamente.\n\n## Conclusión\nSí: es un problema de **aprendizaje supervisado** (regresión o clasificación según la definición de calidad), con fuerte componente **temporal/estacional**. Se resuelve con un pipeline clásico: **EDA → limpieza/imputación → modelo → evaluación → despliegue/alertas**.",
      "keywords": [
        "aprendizaje supervisado",
        "regresión",
        "clasificación",
        "series temporales",
        "calidad del agua",
        "estacionalidad",
        "EDA",
        "imputación"
      ],
      "createdBy": "Luis",
      "sourcePackId": "83ef5676-1384-45f7-804a-20c7d1f4690b",
      "contentHash": "sha256:b7fdefecfffc2cbc64dc1a95e5d2a4f2c386c7cbcbaedd3cdfaba50b62631e06",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "d6087d15-269e-4109-a2ea-80a81ed89113",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "DESARROLLO",
      "prompt": "### El Tiempo en Australia (análisis completo)\n\nEn el **Anexo** final encontrarás la descripción del problema (**El Tiempo en Australia**) y el conjunto de datos asociado. Debes realizar un **análisis completo**, usando los conocimientos de la asignatura.\n\n**Condiciones:**\n- Responde **sin escribir código**.\n- Cualquier aclaración o suposición que hagas sobre el conjunto de datos debe quedar **escrita**.\n- La respuesta debe ser una **explicación y/o justificación** a las cuestiones planteadas (no basta con listar pasos).\n\n> Origen: **Examen anterior** (UNIR **TAA 2024**, **Modelo E**, código **10210067**).\n",
      "explanation": "Un “análisis completo” aquí es: **definir objetivo**, **EDA**, **preprocesado**, **modelos candidatos**, **métrica alineada con negocio** y **validación sin fuga**. Árboles/RF suelen ser la apuesta segura en este tipo de dataset.",
      "difficulty": 4,
      "tags": [
        "examen anterior",
        "UNIR",
        "2024",
        "modelo-e",
        "EDA",
        "preprocesado",
        "evaluación",
        "tiempo"
      ],
      "modelAnswer": "*(Sin el anexo delante, asumo el caso típico “Weather in Australia”: objetivo de **clasificación** como `RainTomorrow` = Sí/No, con variables meteorológicas y fechas.)*\n\n## 1) Entender el problema y definir objetivo\n- **Objetivo**: predecir si lloverá mañana (binario) o predecir cantidad (regresión).  \n- Definir horizonte (mañana), unidad temporal (diario) y qué es “llover” (umbral de mm).\n\n## 2) Exploración (Tema 2)\n- Distribución de la **variable objetivo** (¿está desbalanceada? suele estarlo).\n- Distribuciones de variables numéricas (Temp, Humidity, WindSpeed, Pressure…).\n- Relaciones clave: humedad vs lluvia, presión vs lluvia, nubosidad vs lluvia.\n- Efectos por **Location** y por **estación** (mes/estación del año).\n\n## 3) Limpieza y preparación (Tema 3)\n- **Faltantes**:  \n  - Identificar porcentaje por variable.  \n  - Imputación: mediana para numéricas, moda para categóricas, o imputación por grupo (p. ej. por Location/mes).  \n  - Si una variable tiene demasiados NA, valorar eliminarla.\n- **Variables categóricas** (Location, WindDir…): one-hot o codificación adecuada.\n- **Fecha**: extraer mes/estación; opcionalmente features como “día del año”.\n- **Escalado**: necesario si usas SVM; no imprescindible para árboles/RF.\n\n## 4) Baselines y modelos candidatos (Temas 6–10)\n- **Baseline**: predecir la clase mayoritaria + métricas (para saber si el modelo “aprende”).\n- Modelos razonables:\n  - **Árboles de decisión**: interpretables, capturan no linealidad.\n  - **Random Forest**: mejora generalización, robusto a ruido y relaciones complejas.\n  - **SVM**: si está bien escalado y el dataset no es gigantesco; kernels si no es lineal.\n  - **Naïve Bayes**: rápido, baseline probabilístico (aunque independencia es fuerte).\n- Si hay desbalance: ponderación de clases o técnicas de balanceo.\n\n## 5) Evaluación (Tema 5)\n- Split recomendado: **train/valid/test** o validación cruzada estratificada (si no hay fuga temporal).  \n  Si hay componente temporal fuerte, usar split por tiempo.\n- Métricas:\n  - **Recall** de “lluvia” si lo crítico es no perder días de lluvia (FN caros).  \n  - **Precision** si los falsos avisos son muy costosos.  \n  - **F1** si quieres equilibrio.  \n  - **ROC-AUC / PR-AUC** si hay desbalance.\n- Matriz de confusión para entender FP/FN y ajustar el umbral si el modelo da probabilidades.\n\n## 6) Interpretación y entrega\n- Importancia de variables (en RF) o reglas del árbol para explicar “por qué” predice lluvia.\n- Recomendación final: elegir el modelo que cumpla el criterio de negocio (coste FN vs FP) y que generalice en test.\n- Plan de despliegue: reentrenamiento periódico, control de deriva por estación y por localización.",
      "createdBy": "Luis",
      "sourcePackId": "7b705f3e-b96f-429a-8cf2-7fba79c8a0fa",
      "contentHash": "sha256:105e358616d0b165f86a46f368d99bd2b868ba6dafdbbb29bfaac0ed1fa0387b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "d6d6935a-a890-4090-bc32-8194a4b4d104",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "¿Qué pasa si aumento el número de árboles a un número muy grande en Random Forest en términos de desempeño del modelo?",
      "explanation": "En la práctica se estudia cómo **disminuye el error** (p. ej. OOB) según `n_estimators` y se observa cuándo el rendimiento **se estabiliza**: añadir más árboles aporta mejoras marginales.",
      "difficulty": 3,
      "tags": [
        "random-forest",
        "n-estimators",
        "curva-error"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Aumenta la precisión, pero también la varianza."
        },
        {
          "id": "b",
          "text": "Aumenta la precisión y reduce la varianza."
        },
        {
          "id": "c",
          "text": "Disminuye la precisión y reduce el sesgo."
        },
        {
          "id": "d",
          "text": "Es deseable analizar la disminución del error en términos del número de árboles para ver el desempeño del modelo."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:4b06a3591f8cb7ff1dc1365a494a045f72152f5ace549b99d9d143b18ddbb3e0",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "d6ffbc89-743f-47ec-8f30-7f879e0415bd",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "450fb598-6a22-4be1-8621-ff78740c3973",
      "type": "DESARROLLO",
      "prompt": "Dado un conjunto de datos personales, demográficos y fiscales de varios usuarios, explica cómo procederías para anonimizarlos de forma fiable que no permita la identificación inversa.",
      "difficulty": 2,
      "tags": [
        "datos",
        "privacidad"
      ],
      "modelAnswer": "## Anonimización de Datos Personales\n\nEl proceso debe cumplir el **RGPD** y garantizar que sea inviable reidentificar a los individuos.\n\n### Paso 1: Clasificar los datos\n- **Identificadores directos** (nombre, DNI, email): → eliminar o sustituir.\n- **Cuasi-identificadores** (fecha de nacimiento exacta, código postal, profesión): combinables para reidentificar → transformar.\n- **Datos sensibles** (salario exacto, historial fiscal, patrimonio): → enmascarar o generalizar.\n\n### Paso 2: Aplicar técnicas\n- **Supresión**: Eliminar campos identificadores directos.\n- **Pseudonimización**: Sustituir identificadores por tokens en un vault seguro (reversible solo con acceso autorizado).\n- **Generalización**: Reemplazar valores precisos por rangos (edad exacta → \"30-40 años\"; salario → \"30.000-40.000 €\").\n- **Perturbación / Ruido**: Añadir ruido aleatorio a valores numéricos (salario ± 5%).\n- **k-anonimato**: Garantizar que cada registro sea indistinguible de al menos k-1 registros similares (k ≥ 5).\n\n### Paso 3: Validar\n- Ejecutar ataques de *linkage* con datasets externos para verificar que no hay reidentificación posible.\n- Comprobar que los datos mantienen utilidad estadística.\n\n### Paso 4: Documentar\n- Registrar el proceso según RGPD Art. 25 (privacidad por diseño y por defecto).",
      "keywords": [
        "anonimización",
        "RGPD",
        "pseudonimización",
        "k-anonimato",
        "generalización",
        "supresión",
        "linkage"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:c968cc3bf02850f9701db04eed9ff45bbc442b366c5593dc2dd07d717ce595af",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "d8f50505-d4f3-40f0-beb5-158346243f90",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "Indica la afirmación correcta sobre la **raíz del error cuadrático medio (RMSE)**:\n\nSeleccione una:",
      "explanation": "RMSE = $\\sqrt{\\frac{1}{n}\\sum (y-\\hat{y})^2}$. Hereda la penalización cuadrática del MSE, por eso castiga más los errores grandes que MAE. Además, queda en las mismas unidades que $y$.",
      "difficulty": 1,
      "tags": [
        "rmse",
        "metricas",
        "error"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "RMSE es más sensible a los errores grandes en comparación con MAE en problemas de regresión de aprendizaje automático."
        },
        {
          "id": "b",
          "text": "RMSE proporciona una medida de error en diferentes unidades que la variable objetivo en problemas de regresión."
        },
        {
          "id": "c",
          "text": "RMSE calcula el logaritmo de la raíz cuadrada del promedio de los cuadrados de las diferencias entre predicciones y valores reales."
        },
        {
          "id": "d",
          "text": "RMSE es una medida de error robusta que ignora la magnitud de las diferencias entre las predicciones y los valores reales."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:a3fcad109f7e6e9b279658c97c1954a3fd20c01e444f76bb80c6a05f83a1230e",
      "createdBy": "Luis",
      "sourcePackId": "8a8d0ff6-0d9e-4f6e-a6b4-1a0d2b8f9a4b",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:36:29.551Z",
      "updatedAt": "2026-02-20T23:36:29.551Z"
    },
    {
      "id": "d98f9a5e-1c95-47da-ae57-db2aa88ff5ae",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "784cdbf0-caf2-4f78-9f11-73f5902e2182",
      "type": "TEST",
      "prompt": "Un árbol de decisión se obtiene:",
      "explanation": "En cada nodo se elige el split que **más reduce la impureza** (p.ej., Gini) o que **más aumenta la ganancia de información** (entropía).",
      "difficulty": 2,
      "tags": [
        "arboles-de-decision",
        "split",
        "impureza"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Por medio de un algoritmo que elige primero una variable aleatoria."
        },
        {
          "id": "b",
          "text": "Por medio de un algoritmo que elige primero aquella variable más predictiva."
        },
        {
          "id": "c",
          "text": "Por medio de un algoritmo que elige primero aquella variable menos predictiva."
        },
        {
          "id": "d",
          "text": "Por medio de una elección aleatoria de las variables más predictivas."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:3c01bc3038c36888fbbcc4432519f8e8521ffabe1ed64fade3e29ed1aed2ff3b",
      "createdBy": "Luis",
      "sourcePackId": "6b1aa3c6-5f0c-46b7-9d4a-1a5a3f739f3a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T13:19:32.706Z",
      "updatedAt": "2026-02-21T13:19:32.706Z"
    },
    {
      "id": "dacd8ccd-895a-472f-bf01-98d4821e7973",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "5b7c1734-f5fa-45fd-8985-5f5bed417f36",
      "type": "DESARROLLO",
      "prompt": "Explica los modelos de servicio accesibles en la computación en la nube para proyectos de IA (IaaS, PaaS, SaaS), indicando qué gestiona el usuario y qué el proveedor en cada caso. Pon un ejemplo de cada.",
      "difficulty": 2,
      "tags": [
        "recursos",
        "cloud",
        "infraestructura"
      ],
      "modelAnswer": "## Modelos de Servicio Cloud para Proyectos de IA\n\n### IaaS — Infrastructure as a Service\n- **Proveedor proporciona**: Hardware virtualizado (servidores, almacenamiento, red).\n- **Usuario gestiona**: Sistema operativo, middleware, runtime, aplicaciones y datos.\n- **Control máximo, responsabilidad máxima**.\n- **Ejemplo en IA**: Amazon EC2 con instancias GPU (p3/p4). El científico de datos instala TensorFlow/PyTorch en la instancia y entrena su modelo.\n\n### PaaS — Platform as a Service\n- **Proveedor proporciona**: Infraestructura + SO + runtime + herramientas de desarrollo.\n- **Usuario gestiona**: Aplicaciones y datos únicamente.\n- **Ejemplo en IA**: Google Vertex AI o AWS SageMaker. El equipo solo gestiona el código del modelo y los datos; la plataforma gestiona el entorno de entrenamiento y despliegue.\n\n### SaaS — Software as a Service\n- **Proveedor proporciona**: La aplicación completa lista para usar.\n- **Usuario**: Solo configura el software y aporta los datos.\n- **Ejemplo en IA**: Google AutoML, IBM Watson Studio, Salesforce Einstein. El usuario define el problema y los datos; la plataforma entrena y despliega el modelo automáticamente.\n\n### Resumen\n\n| Modelo | Proveedor gestiona | Usuario gestiona | Ejemplo IA |\n|---|---|---|---|\n| IaaS | Hardware, red | SO, runtime, apps | EC2 + GPU |\n| PaaS | Infra + SO + runtime | Apps, datos | SageMaker |\n| SaaS | Todo | Configuración, datos | Google AutoML |",
      "keywords": [
        "IaaS",
        "PaaS",
        "SaaS",
        "cloud",
        "AWS",
        "SageMaker",
        "GPU",
        "AutoML"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:f1efafcbbfa565185ac4a521cf4b2c42ae218059e48f3bf493006a8703b52a56",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "deef259d-6e2c-4503-817e-06edc9420b30",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Si la probabilidad de pertenencia de una instancia es de 0,55 para la clase 1 y de 0,45 para la clase 2. Se puede afirmar que:",
      "explanation": "✅ A. Está cerca del límite, pero pertenece a la clase 1.\n\nPor qué las otras no:\n\nB: clase 2 tendría que tener probabilidad mayor que clase 1.\n\nC: en clasificación estándar eliges una clase (salvo multilabel, que no es el caso).\n\nD: aunque esté cerca del umbral, sí se clasifica: por regla MAP/argmax gana 0,55.",
      "options": [
        {
          "id": "e03cc759-3828-4675-8173-d4a160822656",
          "text": "El límite de pertenencia a la clase 1 y a la clase 2 están muy cercanos, pero pertenece a la clase 1."
        },
        {
          "id": "ee4ab11a-b7ed-4e51-9246-a859feacde4d",
          "text": "Pertenece a la clase 2"
        },
        {
          "id": "271455a1-701d-46f0-97ae-2083f1d73543",
          "text": "Pertenece a la clase 1 y a la clase 2"
        },
        {
          "id": "e51a7812-25f2-48d5-9b8c-2dd57994c063",
          "text": "No debería clasificarse la instancia"
        }
      ],
      "correctOptionIds": [
        "e03cc759-3828-4675-8173-d4a160822656"
      ],
      "createdBy": "",
      "contentHash": "sha256:6f737b984512972c975e97be4cd687f22c482294fb7a58cd367e35571a1ca165",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "df8938e9-a982-43da-a96a-9ddffee4ca12",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "¿Cuál es el objetivo de un trabajo de ajuste de hiperparámetros?",
      "explanation": "El ajuste de hiperparámetros busca encontrar la configuración óptima de hiperparámetros que maximice el rendimiento del modelo en validación o test, guiándose por una métrica.\n\n✅ A. Optimizar las métricas de validación (es decir, ajustar hiperparámetros para maximizar una métrica como accuracy/AUC/F1 en validación o test).\n\nPor qué las otras no:\n\nB (falsa/ambigua): mezcla “parámetros” con “hiperparámetros”. Los hiperparámetros no se aprenden de los datos, se fijan/ajustan a priori y se eligen por rendimiento en validación/test.\n\nC (falsa): no va de hacer la predicción más rápida; eso sería optimización de inferencia/ingeniería, no tuning.\n\nD (falsa): elegir algoritmo es model selection (otra fase). El tuning asume que el algoritmo/modelo ya está elegido y ajusta sus hiperparámetros.",
      "difficulty": 3,
      "options": [
        {
          "id": "d828a09d-e644-455c-831f-24703438cb0e",
          "text": "Optimizar las métricas de validación para el entrenamiento."
        },
        {
          "id": "461bdea5-b0f2-4d02-ab6a-1a130945d914",
          "text": "Optimizar los parámetros del modelo para producir el mejor modelo."
        },
        {
          "id": "02445340-74a2-467b-a9ab-910ffdd22a99",
          "text": "Optimizar las entradas de datos para producir la predicción más rápida."
        },
        {
          "id": "d7c6c52c-6013-4c5c-9b77-0c8bec86fcae",
          "text": "Optimizar la elección del algoritmo para producir el mejor modelo."
        }
      ],
      "correctOptionIds": [
        "d828a09d-e644-455c-831f-24703438cb0e"
      ],
      "createdBy": "",
      "contentHash": "sha256:25217afe2bcaa22857c50f0e4a334315f6f88cc14d679f13918e494207d99be7",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "dfd74867-5e5d-4286-a76d-45f6c87c0c86",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "388275e1-be5b-44fd-8fbd-52591fd74159",
      "type": "TEST",
      "prompt": "Respecto al **tamaño del contexto**, ¿qué riesgo tiene ampliarlo sin control?",
      "explanation": "Más contexto suele aumentar tokens (coste/latencia) y meter ruido/contradicciones que distraen al modelo. No elimina la necesidad de recuperar ni bloquea *streaming* por definición.",
      "difficulty": 2,
      "tags": [
        "contexto",
        "latencia",
        "coste",
        "ruido",
        "rag"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Siempre mejora la precisión y reduce el coste."
        },
        {
          "id": "b",
          "text": "Eleva coste/latencia y puede introducir distracciones que degradan la respuesta."
        },
        {
          "id": "c",
          "text": "Impide usar *streaming*."
        },
        {
          "id": "d",
          "text": "Elimina la necesidad de recuperar."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:1c79a8c4b6b9e890e1a09dc3b2d9b0a7c688df30d3d22f1caa4a0a2b0a68d723",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "e11cf2c6-c8bf-494b-9501-737bf9e8062d",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Los eventos dependientes:",
      "explanation": "Si dos eventos son dependientes, la ocurrencia de uno **afecta** a la probabilidad del otro (y viceversa).",
      "difficulty": 2,
      "tags": [
        "probabilidad",
        "dependencia"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Permiten estimar la presencia de un evento en función del otro."
        },
        {
          "id": "b",
          "text": "Siempre ocurren a la vez."
        },
        {
          "id": "c",
          "text": "Implica que la existencia de uno puede conllevar la existencia del otro."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores describe los eventos dependientes."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:9e0f1a2b3c4d5e6f708192a3b4c5d6e7f8091a2b3c4d5e6f708192a3b4c5d6e",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "e400140f-768a-4261-8a0b-edfb8d7106c2",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Si usted está entrenando un modelo con un conjunto de datos médicos para diagnóstico de una enfermedad rara. ¿Qué métricas de validación del modelo debería compartir para que los especialistas puedan concluir que es un buen modelo?",
      "explanation": "✅ C. Calcular y explicar los resultados de exactitud, sensibilidad y especificidad.\n\nPor qué las otras no:\n\nA: dar solo TP y TN es incompleto: sin FP/FN no puedes valorar bien el modelo.\n\nB: la matriz de confusión ayuda, pero la pregunta pide “qué métricas compartir”; lo esperado es sensibilidad/especificidad (y si meten exactitud, explicarla con cuidado). \n\nD: solo especificidad es insuficiente: en enfermedad rara la sensibilidad (no perder positivos) suele ser crítica.",
      "difficulty": 3,
      "options": [
        {
          "id": "b1731825-397b-40be-af3c-a8c0a69653b7",
          "text": "Presentar los valores de verdaderos positivos y verdaderos negativos"
        },
        {
          "id": "1a2f78d7-353a-4194-8c83-8b3dc049d19a",
          "text": "Mostrar la matriz de confusión"
        },
        {
          "id": "bb887606-f217-4a4f-a402-a24d5df3cd6d",
          "text": "Calcular y explicar los resultados de exactitud, sensibilidad y especificidad."
        },
        {
          "id": "de3dedf8-eabb-4048-ab9f-6f054924b35b",
          "text": "Mostrar el resultado de especificidad ya que mide la tasa de casos negativos clasificados correctamente."
        }
      ],
      "correctOptionIds": [
        "bb887606-f217-4a4f-a402-a24d5df3cd6d"
      ],
      "createdBy": "",
      "contentHash": "sha256:e5bd97c4a8b3d793deae272e6d6331efc45f696268a30b452b01ce1bdd2ef641",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "e69799e3-6494-4406-9f73-a21db7f7bf1a",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "9d6276cf-e9aa-48ad-a074-fe7ce913673d",
      "type": "DESARROLLO",
      "prompt": "¿Qué son los autoencoders en el aprendizaje automático? Explica su arquitectura y propón un caso de uso.",
      "difficulty": 2,
      "tags": [
        "aprendizaje-automatico",
        "redes-neuronales"
      ],
      "modelAnswer": "## Autoencoders\n\n### Qué son\nRedes neuronales no supervisadas entrenadas para aprender una representación comprimida de los datos de entrada y reconstruirlos. El objetivo: la salida sea lo más parecida posible a la entrada, forzando al modelo a aprender las características más relevantes.\n\n### Arquitectura\n\n**Encoder (Codificador)**\n- Recibe el dato de entrada x de alta dimensión.\n- Aplica capas que reducen progresivamente la dimensionalidad.\n- Produce un vector comprimido: el **espacio latente** o *bottleneck* (z).\n\n**Decoder (Decodificador)**\n- Toma el vector latente z.\n- Reconstruye progresivamente la dimensión original.\n- Produce la reconstrucción x̂ ≈ x.\n\n`Entrada x → [Encoder] → Espacio latente z → [Decoder] → Reconstrucción x̂`\n\n**Función de pérdida**: Error de reconstrucción (MSE para datos continuos, Binary Cross-Entropy para binarios).\n\n### Variantes\n- **VAE (Variational Autoencoder)**: Aprende una distribución probabilística en el espacio latente, permitiendo generar nuevos datos.\n- **Autoencoder convolucional**: Para imágenes (capas Conv2D).\n- **Autoencoder disperso (sparse)**: Fuerza activación de pocas neuronas en el espacio latente.\n\n### Caso de uso: Detección de anomalías industriales\nUn autoencoder se entrena **solo con datos normales** de vibraciones de motores correctos. En producción, calcula el error de reconstrucción para cada nueva medición: si supera un umbral, la muestra es anómala (posible fallo del motor). No se necesitan ejemplos de fallos etiquetados.",
      "keywords": [
        "autoencoder",
        "encoder",
        "decoder",
        "espacio latente",
        "VAE",
        "detección anomalías",
        "reconstrucción"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:323ff92542357d7ffcf5d6a7774d5cf8448badf30e1faf8ac8660f4f7041d52c",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "e69ffbb9-02dc-433a-9ee6-df1e45d2bbf5",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "450fb598-6a22-4be1-8621-ff78740c3973",
      "type": "DESARROLLO",
      "prompt": "Describe en qué consiste el movimiento de datos abiertos (open data), cuáles son los principales tipos de entidades que publican datos de forma abierta y quiénes son sus principales beneficiarios. ¿Qué motivaciones tendría una empresa privada para publicar sus datos? Propón un ejemplo práctico.",
      "difficulty": 2,
      "tags": [
        "datos",
        "gestion-proyectos"
      ],
      "modelAnswer": "## Open Data (Datos Abiertos)\n\n### Qué es\nEl movimiento **open data** promueve que los datos sean accesibles, reutilizables y redistribuibles libremente por cualquier persona, sin restricciones de copyright ni de otro tipo. Los datos se publican en formatos abiertos y estándar (CSV, JSON, RDF).\n\n### Entidades que publican datos abiertos\n- **Entidades gubernamentales**: Administraciones nacionales, regionales y locales (datos.gob.es, data.europa.eu).\n- **Organismos internacionales**: ONU, OMS, Banco Mundial.\n- **Instituciones académicas**: Datasets de experimentos, corpus lingüísticos (UCI ML Repository, Zenodo).\n- **Empresas tecnológicas**: Google, Meta, Microsoft publican datasets para investigación en IA.\n\n### Principales beneficiarios\n- **Ciudadanos**: Información para participación cívica y toma de decisiones informadas.\n- **Investigadores**: Análisis y generación de conocimiento sin coste de adquisición.\n- **Empresas**: Desarrollo de productos y servicios sobre datos publicados.\n- **Administraciones públicas**: Mejora de la eficiencia y transparencia.\n\n### Motivaciones de una empresa privada\n1. **Responsabilidad social corporativa (RSC)**: Mejorar imagen pública.\n2. **Generación de ecosistema**: Terceros desarrollan productos compatibles (efecto red).\n3. **Posicionamiento como líder**: Referente del sector.\n4. **Atraer talento e investigación**: Los investigadores desarrollan mejoras aprovechables.\n\n### Ejemplo práctico\nUna empresa de transporte público publica datos de rutas, horarios y posiciones en tiempo real. Los desarrolladores crean apps de navegación, los investigadores analizan movilidad, y la empresa obtiene feedback para optimizar sus servicios.",
      "keywords": [
        "open data",
        "datos abiertos",
        "RSC",
        "transparencia",
        "ecosistema",
        "FAIR"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:fe75b3fd2ef237fadb0fdb8e3a4cc7f05dfd1dd84ae40314161b1f02eb2f76d7",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "e6c4ebdc-83a7-4d34-b3bd-f3cb34cb11ea",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "ce4369a8-42da-42d5-a4c2-dbbdce2a4eb0",
      "type": "TEST",
      "prompt": "¿Qué combinación de estrategias de **memoria** es la más coherente?",
      "explanation": "Combina corto plazo (coherencia reciente) con largo plazo (persistencia/recuperación semántica) sin reventar el contexto.",
      "difficulty": 2,
      "tags": [
        "memoria",
        "ventana",
        "vectorial",
        "resumen",
        "agentes"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Solo historial completo sin límites ni resúmenes."
        },
        {
          "id": "b",
          "text": "Eliminar cualquier dato antiguo para evitar sesgos."
        },
        {
          "id": "c",
          "text": "Ventana deslizante para lo reciente + memoria vectorial y/o resúmenes para conservar lo relevante."
        },
        {
          "id": "d",
          "text": "Usar únicamente metadatos y nunca texto."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:8b6f6c31c2a3b9b0c9f1b6d3c2a1e0f9b8a7c6d5e4f3a2b1c0d9e8f7a6b5c4d3",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "e73fa2ad-3c9e-490b-9f35-e9148cba7699",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "¿Cuál es uno de los beneficios de **Extra Trees** en comparación con Random Forest?",
      "explanation": "Al escoger divisiones de forma más aleatoria (sin buscar el mejor corte), suele ser **más rápido de entrenar** que Random Forest.",
      "difficulty": 2,
      "tags": [
        "extra-trees",
        "rendimiento",
        "entrenamiento"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Mayor interpretabilidad de los modelos."
        },
        {
          "id": "b",
          "text": "Mayor velocidad de entrenamiento."
        },
        {
          "id": "c",
          "text": "Menor capacidad para manejar datos ruidosos."
        },
        {
          "id": "d",
          "text": "Mayor sensibilidad al sobreajuste."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:3106d19776709adaa5cb566ef1c9754ec962919c9c20110b0aff48e70dd731d4",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "e7f8212f-5db3-480c-abfb-ad355bc495cd",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "ce4369a8-42da-42d5-a4c2-dbbdce2a4eb0",
      "type": "TEST",
      "prompt": "En **Flowise (AgentFlow)**, ¿qué configuración mínima ilustra un agente que **calcula y recuerda**?",
      "explanation": "Para “calcular” necesitas herramienta, y para “recordar” necesitas memoria conversacional: Agent Node + calculadora + memory cubre ambas.",
      "difficulty": 2,
      "tags": [
        "flowise",
        "agentflow",
        "herramientas",
        "memoria"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Solo un nodo de LLM sin más."
        },
        {
          "id": "b",
          "text": "Un *Agent Node* con herramienta «Calculadora» habilitada y memoria conversacional activa."
        },
        {
          "id": "c",
          "text": "Un *vector store* sin agente."
        },
        {
          "id": "d",
          "text": "Dos agentes idénticos conectados entre sí."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:cf5d2c1a0b9e8d7c6b5a493827161514131211100f0e0d0c0b0a0908070605040",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "e89cbbc6-d9b7-4137-8bb0-17d262350997",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "Un científico de datos está trabajando en un problema de clasificación utilizando un modelo de Random Forest. Observa que su modelo tiene un rendimiento excepcionalmente alto en el conjunto de entrenamiento, pero cuando evalúa el modelo en un conjunto de prueba, nota una disminución significativa en la precisión. ¿Cuál de las siguientes estrategias podría ayudar a mejorar la generalización del modelo de Random Forest?",
      "explanation": "✅ A. Aumentar el número de árboles en el bosque.\n\nPor qué las otras no:\n\nB: menos datos suele empeorar la generalización.\n\nC: más profundidad suele aumentar el sobreajuste.\n\nD: puede ayudar en algunos casos (p.ej. limitar max_features), pero la respuesta estándar para reducir varianza en Random Forest es aumentar el número de árboles.",
      "difficulty": 3,
      "options": [
        {
          "id": "e1931f15-a66f-4d12-a8b8-dc84083f8bfe",
          "text": "Aumentar el número de árboles en el bosque."
        },
        {
          "id": "e2770ed7-8135-4aef-b617-9c99eba3f1db",
          "text": "Reducir la cantidad de datos de entrenamiento."
        },
        {
          "id": "3db3e6f5-b231-474d-abf6-297a43f88687",
          "text": "Aumentar la profundidad máxima de cada árbol."
        },
        {
          "id": "049df430-c553-42aa-9a8a-8ac170d90fd6",
          "text": "Utilizar un conjunto de características más pequeño."
        }
      ],
      "correctOptionIds": [
        "e1931f15-a66f-4d12-a8b8-dc84083f8bfe"
      ],
      "createdBy": "",
      "sourcePackId": "778c30fd-9df1-4385-9961-39a237b103e9",
      "contentHash": "sha256:444129a9b639fde79ed9f37fb35d9522c8b97f31a619d0cf8a89ab235af8b9ec",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "ea2a890b-099f-4b58-adbe-5559149b5959",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "¿Cuáles de las siguientes afirmaciones son ciertas sobre el clasificador de Naïve Bayes?",
      "explanation": "Naïve Bayes estima probabilidades con datos (frecuencias/verosimilitudes) y asume **independencia condicional** entre características.",
      "difficulty": 2,
      "tags": [
        "naive-bayes",
        "verosimilitud",
        "independencia-condicional"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Utiliza datos históricos para obtener la probabilidad observada de cada evento en función de su vector de características."
        },
        {
          "id": "b",
          "text": "Asume independencia condicional entre los eventos."
        },
        {
          "id": "c",
          "text": "A y B son ciertas."
        },
        {
          "id": "d",
          "text": "El cálculo riguroso del teorema de Bayes es computacionalmente costoso."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:0f1a2b3c4d5e6f708192a3b4c5d6e7f8091a2b3c4d5e6f708192a3b4c5d6e7f8",
      "createdBy": "Luis",
      "sourcePackId": "82432049-5937-495b-aab0-d3f6f9364ac6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:47:50.469Z",
      "updatedAt": "2026-02-21T14:47:50.469Z"
    },
    {
      "id": "ebe5c654-5e68-40dd-bbab-f783f6b1ead5",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "5f556862-dbdd-47aa-95e5-cb0861ea715d",
      "type": "TEST",
      "prompt": "El término varianza de un modelo habla de:",
      "explanation": "✅ C. Cuánto cambia un modelo dependiendo de los datos de entrenamiento utilizados.\n\nPor qué las otras no:\n\nA: no define varianza.\n\nB: describe un síntoma, pero no la definición (la clave es la sensibilidad al dataset).\n\nD: describe el extremo de baja varianza, no la definición.",
      "difficulty": 2,
      "options": [
        {
          "id": "6da418a3-88de-44d9-ac10-5c8a09eea02c",
          "text": "Un modelo que cambia constantemente en su ejecución."
        },
        {
          "id": "be7697c8-a465-4f0b-b136-79658755976e",
          "text": "Un modelo que se entrena varias veces y da resultados diferentes."
        },
        {
          "id": "84571460-545a-4f9a-bab3-cc2b9d0626d6",
          "text": "Cuánto cambia un modelo dependiendo de los datos de entrenamiento utilizados."
        },
        {
          "id": "19b30d0b-c6cb-400e-b609-3eae49b2452f",
          "text": "Construir modelos que no cambien cuando se modifican los datos de entrenamiento."
        }
      ],
      "correctOptionIds": [
        "84571460-545a-4f9a-bab3-cc2b9d0626d6"
      ],
      "createdBy": "",
      "sourcePackId": "778c30fd-9df1-4385-9961-39a237b103e9",
      "contentHash": "sha256:cd4666cdf3365f9fdea3ccf315e8dd5dfa3beca9d6d9f0568aae4264dfa3b893",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "ec21615b-bb8f-492e-a893-2cbd7e9251a9",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "PRACTICO",
      "prompt": "Después de entrenar un modelo con base en **Random Forest** se obtienen los siguientes datos de validación:\n\n- De las **80** instancias de la **clase positiva**, el modelo clasificó bien **50**.  \n- De las **410** instancias de la **clase negativa**, el modelo clasificó bien **350**.\n\nSe pide:\n\n1) Calcular **Accuracy**, **Precisión**, **Recall** y **F1-score** para **ambas clases**.  \n2) Indicar si el algoritmo responde de manera adecuada para clasificar correctamente la **clase positiva**. Justifica.  \n3) Analizar el valor de la **sensibilidad**: ¿qué significado tiene?\n\n(Usa las definiciones habituales: TP, TN, FP, FN).",
      "explanation": "Debe calcular correctamente TP, TN, FP, FN y derivar métricas. En la interpretación, si la clase positiva es crítica, se debe enfatizar recall/sensibilidad y el coste de FN.",
      "difficulty": 3,
      "tags": [
        "métricas",
        "matriz de confusión",
        "random forest",
        "sensibilidad"
      ],
      "modelAnswer": "Primero construimos la **matriz de confusión** (tomando “positiva” como la clase +):\n\n|               | Pred + | Pred - |\n|---|---:|---:|\n| **Real +**    | TP = 50 | FN = 30 |\n| **Real -**    | FP = 60 | TN = 350 |\n\nTotal = 490.\n\n---\n\n## 1) Métricas\n\n### Global\n- **Accuracy** = (TP + TN) / Total = (50+350)/490 = **0.816** (≈ 81.6%)\n\n### Para la clase positiva (+)\n- **Precisión (+)** = TP / (TP+FP) = 50/(50+60) = **0.455**\n- **Recall (+)** = TP / (TP+FN) = 50/(50+30) = **0.625**\n- **F1 (+)** = 2·P·R/(P+R) = **0.526**\n\n### Para la clase negativa (-) (tratándola como “clase de interés”)\nEquivalente a calcular métricas sobre el “-”:\n\n- **Precisión (-)** = TN / (TN+FN) = 350/(350+30) = **0.921**\n- **Recall (-)** = TN / (TN+FP) = 350/(350+60) = **0.854**\n- **F1 (-)** = **0.886**\n\n---\n\n## 2) ¿Clasifica bien la clase positiva?\nSi la **clase positiva es la importante**, la respuesta es: **no especialmente**.\n\n- El **Recall (+) = 0.625** implica que se “escapan” **FN/(TP+FN) = 30/80 = 37.5%** de positivos reales (falsos negativos).  \n- La **Precisión (+) = 0.455** indica además bastantes falsos positivos.\n\nEn contextos donde fallar un positivo cuesta caro (fraude, avería, enfermedad), este rendimiento suele ser insuficiente: habría que **priorizar recall** (p. ej. ajustando umbral, pesos de clase, más datos/variables, etc.).\n\n## 3) Sensibilidad: significado\nLa **sensibilidad** es lo mismo que el **Recall** de la clase positiva:\n\n- **Sensibilidad = TP / (TP+FN) = 0.625**\n\nSe interpreta como: “de todos los positivos reales, ¿qué proporción detecto?”.  \nAquí detecta ~62.5% y deja sin detectar ~37.5%.\n",
      "keywords": [
        "matriz de confusión",
        "accuracy",
        "precisión",
        "recall",
        "sensibilidad",
        "F1",
        "TP",
        "TN",
        "FP",
        "FN"
      ],
      "createdBy": "Luis",
      "sourcePackId": "9f68ddcb-ee6e-4448-b804-bce7c3c45725",
      "contentHash": "sha256:56a77a9dd5dcacaac83808e0296a5acd91815dfaf65717ac3cbb3384c0c397a0",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "ee55e69b-0905-44cb-b375-b321ffea4fff",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "DESARROLLO",
      "prompt": "### Bank Marketing (análisis completo)\n\nEn el **Anexo** final encontrarás la descripción del problema (**Bank Marketing**). Debes realizar un **análisis completo**, usando los conocimientos de la asignatura.\n\n**Condiciones:**\n- Responde **sin escribir código**.\n- Cualquier aclaración o suposición que hagas debe quedar **escrita**.\n\n> Origen: **Examen anterior** (UNIR, ordinaria **07–12/03/2025**, **Modelo D**).\n",
      "explanation": "Análisis end-to-end de un problema tabular típico: EDA, tratamiento de faltantes/variables categóricas/desbalanceo, elección de algoritmos (baseline + modelos del temario) y evaluación con métricas adecuadas (PR-AUC, F1, etc.) y validación estratificada.",
      "difficulty": 3,
      "tags": [
        "examen-anterior",
        "unir",
        "taa",
        "2025-03",
        "modelo-d",
        "analisis",
        "bank-marketing"
      ],
      "modelAnswer": "## Suposición mínima (lo típico en *Bank Marketing*)\nNormalmente es un problema de **clasificación** donde la variable objetivo `y` indica si el cliente **contrata** (sí/no) un producto (p.ej. depósito a plazo) tras una campaña.\n\nSi el anexo difiere, la estructura del análisis es la misma: **definir objetivo → preparar datos → elegir modelo → evaluar bien**.\n\n## 1) Análisis previo y tratamiento de datos\n\n### 1.1 Entender el objetivo y el “momento” de la predicción\n- ¿Queremos predecir **antes** de llamar al cliente (para seleccionar a quién llamar)?\n- ¿O durante/después de la llamada?\n\nEsto importa porque hay variables como `duration` (duración de la llamada) que pueden ser **fuga de información** (*data leakage*) si solo se conocen después.\n\n### 1.2 Inspección del dataset (EDA)\n- **Balanceo** de clases (`y=Sí` suele ser minoritaria).\n- Tipos de variables:\n  - Numéricas (edad, euribor, campaña, etc.)\n  - Categóricas (job, marital, education, contact, month, poutcome…)\n- Estadísticos descriptivos: media/mediana, dispersión, percentiles.\n- Detección de:\n  - **Valores faltantes** (incluyendo “unknown” como *missing* en categóricas).\n  - **Outliers** (p.ej. `campaign` muy alto).\n  - Dependencias/correlaciones fuertes (colinealidad en numéricas).\n\n### 1.3 Preparación\n- **Split** estratificado (train/valid/test) o *k-fold* estratificado.\n- Tratamiento de faltantes:\n  - Numéricas: imputación (media/mediana) o modelo simple; documentar.\n  - Categóricas: categoría `unknown` explícita o imputación por moda.\n- Codificación:\n  - **One-hot** para categóricas (si usamos modelos lineales/SVM).\n  - Para árboles/RF se puede usar one-hot igualmente; o codificación ordinal si procede (con cuidado).\n- Escalado:\n  - Recomendable para **SVM** / regresión logística (estandarización).\n  - No imprescindible para árboles/RF.\n- Desbalanceo:\n  - **class_weight** / costes.\n  - Re-muestreo (sub/over-sampling, **SMOTE** si se permite).\n  - Importante: hacerlo **solo** en entrenamiento (no contaminar test).\n\n## 2) Algoritmos recomendados y por qué\n\n### Baseline rápido (interpretables)\n- **Regresión logística**:\n  - Buena línea base, rápida, probabilística, umbral ajustable.\n  - Permite explicar *drivers* (coeficientes) si las variables están bien codificadas.\n\n### Modelos potentes del temario\n- **Árboles de decisión**:\n  - Interpretables, capturan no linealidades, sensibles a overfitting → podar / limitar profundidad.\n- **Random Forest**:\n  - Reduce varianza con bagging + selección aleatoria de variables.\n  - Suele funcionar muy bien en tabulares con mezcla de variables.\n- **Boosting** (si entra en tu temario con detalle):\n  - Puede mejorar rendimiento enfocándose en errores previos (trade-off: más tuning).\n\n### Alternativa si la frontera es compleja\n- **SVM** (con kernel):\n  - Útil si tras codificar/escala hay separación no lineal.\n  - Ojo con coste computacional en datasets grandes.\n\n> Si el dataset es “tabular clásico”, mi apuesta práctica sería:\n> **Logística (baseline)** → **Random Forest** (mejor rendimiento) → ajustar umbral según objetivo.\n\n## 3) Métricas y evaluación\n\nComo suele haber **clase minoritaria**, *accuracy* puede engañar.\n\n### Métricas clave\n- **Matriz de confusión** (para ver FP/FN).\n- **Precision / Recall / F1** para la clase `Sí`.\n- **ROC-AUC** (útil, pero cuidado con mucho desbalance).\n- **PR-AUC** (muy informativa cuando `Sí` es rara).\n- Si hay coste asimétrico:\n  - Minimizar **FN** (no perder clientes) o minimizar **FP** (no malgastar llamadas), según negocio.\n\n### Protocolo de evaluación recomendado\n- Validación **estratificada** (hold-out o k-fold).\n- Ajuste de hiperparámetros con validación (idealmente **grid/random search**).\n- Selección de **umbral**:\n  - No quedarse con 0,5 “por costumbre”.\n  - Elegir umbral que optimice la métrica objetivo (p.ej. maximizar F1 o cumplir un recall mínimo).\n- Test final **una vez** (para no “entrenar” contra el test).\n\n## 4) Qué justificaría explícitamente en el examen\n- Por qué **es clasificación** y qué etiqueta predigo.\n- Qué variables son potencialmente **leakage** y qué haría con ellas.\n- Qué haría con **categóricas**, **faltantes** y **desbalanceo**.\n- Qué métrica optimizo y por qué (en negocio casi nunca es accuracy).\n",
      "createdBy": "Luis",
      "sourcePackId": "04a1a1df-5192-4d2f-9e7e-12bf6daf1f16",
      "contentHash": "sha256:a2ca826433c60805170ddb3a9bbacb86b4dcc832f876f6f62a1718872468c823",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "ee80c621-ca87-45d4-b825-36e09f2c5fae",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "DESARROLLO",
      "prompt": "Autotaxis Gómez tiene una flota de **10 vehículos**. El gerente está preocupado por el mantenimiento: su máxima prioridad es **prevenir fallos**. Cuando un taxi falla, hay costes indirectos (cliente descontento, reemplazo, taxi y conductor fuera de servicio, etc.). Con revisiones regulares evita algunos fallos, pero no es óptimo porque a veces repara vehículos **antes de que sea necesario**.\n\n**Preguntas:**\n1. ¿Podría disponer de alguna herramienta que le avisara con tiempo suficiente sobre **cuándo un vehículo va a fallar**?\n2. ¿Es un problema de **aprendizaje automático**?\n3. ¿Qué **tipo de problema** es?\n4. ¿Qué **técnicas** vistas en la asignatura aplicarías para resolverlo?\n\nJustifica la respuesta e **indica las necesidades de datos**.",
      "explanation": "La respuesta debe identificar el problema como supervisado (normalmente clasificación binaria con ventana temporal), proponer técnicas vistas (árboles/RF/boosting/SVM) y detallar qué datos hacen falta y por qué la métrica clave suele ser el recall de fallos.",
      "difficulty": 3,
      "tags": [
        "mantenimiento predictivo",
        "clasificación",
        "coste de errores",
        "árboles de decisión",
        "random forest"
      ],
      "modelAnswer": "Sí: se puede construir una herramienta de **predicción de fallo** (o de “riesgo de fallo”) a partir de datos históricos de uso y mantenimiento.\n\n### 1) ¿Es aprendizaje automático?\n**Sí**, porque el objetivo es aprender una relación *datos → probabilidad de fallo* a partir de ejemplos pasados, en lugar de programar reglas fijas.\n\n### 2) ¿Qué tipo de problema es?\nDepende de cómo definamos el objetivo (**label**):\n\n- **Clasificación supervisada (recomendado en examen):**  \n  Definir una ventana temporal, por ejemplo:  \n  **`fallará_en_los_próximos_30_días` ∈ {sí, no}`**  \n  Esto convierte el problema en **clasificación binaria**.\n- **Regresión:** predecir un valor continuo, p. ej. **“días restantes hasta fallo”** (*RUL*).\n- (Opcional si faltan etiquetas de fallo) **detección de anomalías**: si no hay suficientes fallos etiquetados, puedes empezar detectando comportamientos “raros”, pero para *predecir fallos* lo ideal es supervisado.\n\n### 3) Datos necesarios (lo importante de verdad)\nNecesitas **histórico** con:\n- **Etiqueta/objetivo:** registro de *fallos* (fecha del fallo, tipo, componente, severidad) o, para clasificación, si falló dentro de la ventana definida.\n- **Uso y carga:** km/día, horas de motor, trayectos urbanos vs carretera, temperatura ambiente, estilo de conducción (aceleraciones/frenadas), cargas…\n- **Telemetría/sensores (si existe):** temperaturas, vibraciones, presión, OBD, códigos de error, batería, etc.\n- **Mantenimiento:** revisiones realizadas, piezas sustituidas, tiempo desde última revisión, historial de averías.\n- **Contexto del vehículo:** modelo/año, tipo de motor, kilometraje total, etc.\n\n**Nota crítica:** con solo 10 taxis tendrás pocos ejemplos de fallos → probablemente **pocos datos**. Para que funcione, necesitas o bien **mucho tiempo histórico** (años) o más vehículos / más señales.\n\n### 4) Técnicas aplicables (de la asignatura)\n- **Árboles de decisión (clasificación):** buenos para empezar, interpretables (explicabilidad al gerente).\n- **Random Forest / Bagging:** suele mejorar rendimiento y robustez frente a ruido (y da importancia de variables).\n- **Boosting (si se busca máximo rendimiento):** puede mejorar aún más, vigilando sobreajuste.\n- **SVM:** viable si haces buen preprocesado/normalización y el problema es separable en un espacio transformado, pero menos interpretable.\n- **Evaluación:** el coste principal es el **falso negativo** (no avisar y que falle), así que priorizaría **Recall/Sensibilidad** de la clase “fallo”, además de **matriz de confusión** y un umbral orientado a coste.\n\n### Resultado práctico esperado\nEl sistema devolvería algo tipo: “**Taxi #7: riesgo alto de fallo en 30 días**” y el motivo (variables que disparan el riesgo), para planificar mantenimiento sin “cambiar piezas por deporte”.\n",
      "keywords": [
        "clasificación",
        "mantenimiento predictivo",
        "variable objetivo",
        "supervisado",
        "falsos negativos",
        "sensibilidad/recall",
        "árbol de decisión",
        "random forest"
      ],
      "createdBy": "Luis",
      "sourcePackId": "9f68ddcb-ee6e-4448-b804-bce7c3c45725",
      "contentHash": "sha256:806585dee43808f8ed72beeb476d41eac7a709d72e780aa300f47a2634ffa4a6",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "f10bed8c-8620-4c24-9a27-fb4979a23ff4",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "45ad1f2c-e5ec-4983-99cb-a195d9aa604f",
      "type": "TEST",
      "prompt": "¿Qué hiperparámetro en Random Forest controla la cantidad de características consideradas en cada división de un árbol?",
      "explanation": "`max_features` controla cuántas variables se **consideran** (subconjunto aleatorio) en cada **split** durante el crecimiento de cada árbol.",
      "difficulty": 2,
      "tags": [
        "random-forest",
        "hiperparametros",
        "max-features"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "n_estimators."
        },
        {
          "id": "b",
          "text": "max_features."
        },
        {
          "id": "c",
          "text": "max_depth."
        },
        {
          "id": "d",
          "text": "min_samples_split."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:071bd4cdc8fcf218ebce321208a88ca55f447a4a7952bc25e1a77786971e238f",
      "createdBy": "Luis",
      "sourcePackId": "9f96fbbe-5d3e-4ac1-880e-87bbeeb8e70a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:32:54.836Z",
      "updatedAt": "2026-02-21T15:32:54.836Z"
    },
    {
      "id": "f1b549b9-f7ea-472a-b272-f9308fa888ab",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "DESARROLLO",
      "prompt": "### Gemelo digital y detección de enfermedades en aguacates (imágenes)\n\nEl **gemelo digital** plantea un nuevo paradigma en el empleo de modelos de IA. En el sector agro, puede ser una opción muy válida para la **monitorización** de cultivo y **detección precoz** de enfermedades y plagas.\n\nSe cuenta con:\n\n- Un conjunto de **3600 imágenes** de aguacates con dos tipos de enfermedades: **Antracnosis** y **Roña**.\n- Otro conjunto de imágenes de aguacates **sanos**.\n\n**Preguntas:**\n1. ¿Sería posible reconocer a los aguacates **enfermos**?\n2. ¿Es un problema de **aprendizaje automático**? ¿Qué **tipo de problema** es?\n3. ¿Cómo se podría resolver a partir de las **técnicas vistas en la asignatura**?\n\n> Origen: **Examen anterior** (UNIR, ordinaria **07–12/03/2025**, **Modelo D**).\n",
      "explanation": "Clasificación supervisada sobre imágenes: binaria o multiclase según el objetivo. El enfoque estándar es **preprocesar + extraer características/embeddings** y entrenar un clasificador del temario, evaluando con métricas por clase y priorizando *recall* en `enfermo`.",
      "difficulty": 2,
      "tags": [
        "examen-anterior",
        "unir",
        "taa",
        "2025-03",
        "modelo-d",
        "vision",
        "clasificacion"
      ],
      "modelAnswer": "## 1) ¿Se puede reconocer si están enfermos?\n\nSí. Si las imágenes están **etiquetadas** (sano / Antracnosis / Roña) es viable aprender un modelo que, a partir de la **información visual** (color, textura, patrones de mancha), prediga la clase.\n\nEl límite real lo marcan:\n- **Calidad/variedad** de imágenes (iluminación, fondos, distancia, cámaras).\n- **Balanceo** entre clases (si hay muy pocas de una enfermedad).\n- **Consistencia** del etiquetado (ruido en etiquetas).\n\n## 2) ¿Es aprendizaje automático? ¿Qué tipo?\n\nSí: es **aprendizaje supervisado**.\n\nSegún el objetivo:\n- **Clasificación binaria**: `enfermo` vs `sano` (si solo quieres “alerta”).\n- **Clasificación multiclase**: `sano` / `Antracnosis` / `Roña` (si quieres diagnóstico).\n\n## 3) ¿Cómo lo resolvería con técnicas del temario?\n\n### Pipeline mínimo (sin entrar en “magia”)\n1. **Partición** en *train/valid/test* (idealmente **estratificada** por clase).\n2. **Preprocesado**:\n   - Redimensionado uniforme.\n   - **Normalización** de píxeles.\n   - (Opcional) **aumentación**: rotaciones, flips, cambios leves de brillo/contraste para robustez.\n3. **Extracción de características** (dos vías):\n   - **Clásica** (para usar clasificadores del temario): histogramas de color, **HOG**, **LBP** (textura), etc.\n   - **Aprendizaje profundo** (práctico en imágenes): *transfer learning* con una **CNN** preentrenada para extraer embeddings (y luego clasificar).\n4. **Modelo** (del temario) sobre esas características/embeddings:\n   - **SVM** (con kernel si hace falta no linealidad) suele ir bien con descriptores.\n   - **Random Forest** / **Árboles** como baseline interpretable.\n   - (Si el dataset es muy limpio y los descriptores buenos, incluso **Naïve Bayes** puede servir como baseline rápido).\n5. **Evaluación**:\n   - Matriz de confusión.\n   - **Precision/Recall/F1 por clase**.\n   - En agro suele interesar priorizar **Recall** de `enfermo` (minimizar falsos negativos: no “dejar pasar” un enfermo).\n6. **Integración en gemelo digital**:\n   - El modelo alimenta el gemelo con un estado `salud` + **probabilidad**.\n   - Monitorización de **drift** y reentrenos periódicos (cambios de estación/cámara/variedad).\n\n### Nota práctica\nSi el coste de un falso negativo (no detectar enfermedad) es alto, se puede:\n- Ajustar **umbral** de decisión.\n- Usar **ponderación de clases** o re-muestreo (si hay desbalance).\n",
      "createdBy": "Luis",
      "sourcePackId": "04a1a1df-5192-4d2f-9e7e-12bf6daf1f16",
      "contentHash": "sha256:0e41005dbec137566ed24a74ce0a551f3c9eed3db659d2aed0a53922ef187f77",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "f261b027-35b8-4254-8b0a-9a9637a9cba4",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "Son tipos de variables:",
      "difficulty": 1,
      "options": [
        {
          "id": "a",
          "text": "Nominales"
        },
        {
          "id": "b",
          "text": "Ordinales"
        },
        {
          "id": "c",
          "text": "Discretas"
        },
        {
          "id": "d",
          "text": "**Todas las anteriores**"
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:4239422f1dfe38e276454604aa8e17a1d18ee7ca7a9ef600631324a370a8d35d",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "f381717e-244c-4727-878f-b5fefa585f07",
      "subjectId": "7ed5e91c-79e6-4e30-b6b9-ca1e3a29c9a3",
      "topicId": "388275e1-be5b-44fd-8fbd-52591fd74159",
      "type": "TEST",
      "prompt": "En un **RAG**, tras actualizar documentos, el sistema sigue respondiendo con datos antiguos. ¿Qué es lo más probable?",
      "explanation": "Si no re-embebes y reindexas, el retriever sigue trayendo vectores/fragmentos de versiones antiguas. Ajustar *k*, temperatura o *few-shot* no corrige un índice desfasado.",
      "difficulty": 2,
      "tags": [
        "rag",
        "indexado",
        "embeddings",
        "vector-store"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "No se regeneraron los *embeddings* ni se reindexó el *vector store*."
        },
        {
          "id": "b",
          "text": "El *k* de recuperación es demasiado alto."
        },
        {
          "id": "c",
          "text": "La temperatura está por encima de 1.0."
        },
        {
          "id": "d",
          "text": "Falta un ejemplo *few-shot* en el *prompt*."
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:c8b6106b309bf4e4b5fb43b5d2dc97cc97bbebc6762c48d97e1bcf7bb8c2791f",
      "createdBy": "Luis",
      "sourcePackId": "50a24b83-4094-4ea1-8419-0e17cae92d91",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T17:34:13.897Z",
      "updatedAt": "2026-02-20T17:34:13.897Z"
    },
    {
      "id": "f53e6407-1f68-4147-bcd6-2eb213b12b8d",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "1f1be644-ce4e-4134-8501-6bae5948e91c",
      "type": "TEST",
      "prompt": "Indica la afirmación **falsa** sobre el coeficiente de correlación de Pearson:",
      "explanation": "La **covarianza no está normalizada**, mientras que la correlación sí, por lo que no se interpretan igual.",
      "difficulty": 2,
      "options": [
        {
          "id": "a",
          "text": "**El coeficiente se interpreta exactamente igual que la covarianza**"
        },
        {
          "id": "b",
          "text": "Si la covarianza es positiva, la correlación es directa"
        },
        {
          "id": "c",
          "text": "Si la covarianza es negativa, la correlación es inversa"
        },
        {
          "id": "d",
          "text": "Todas son verdaderas"
        }
      ],
      "correctOptionIds": [
        "a"
      ],
      "contentHash": "sha256:2a1b94d0ade87c0353a4dc47d06bb88366cb9d5774ec98314842922dd7c638b1",
      "createdBy": "Jorge",
      "sourcePackId": "9f3b2c6a-8d2e-4b1a-9c77-1a2f6d9e1234",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:49:08.173Z",
      "updatedAt": "2026-02-20T14:49:08.173Z"
    },
    {
      "id": "f6625795-033d-43fd-8371-090e7365aa06",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "e50ab4a3-574f-4002-ac5f-e5912c4cf9d3",
      "type": "DESARROLLO",
      "prompt": "Razona cómo la Inteligencia Artificial puede contribuir a la personalización de los diagnósticos en el ámbito sanitario.",
      "difficulty": 2,
      "tags": [
        "sistemas-cognitivos",
        "salud"
      ],
      "modelAnswer": "## IA en la Personalización de Diagnósticos Sanitarios\n\nLa IA permite avanzar desde la medicina estándar hacia la **medicina de precisión**: diagnósticos y tratamientos adaptados a cada paciente.\n\n### 1. Análisis de imagen médica personalizado\nCNN entrenadas en millones de imágenes (RMN, TAC, radiografías) detectan patologías con precisión equiparable a la humana. Al cruzar con el historial del paciente, el sistema prioriza diagnósticos según su perfil de riesgo individual.\n\n### 2. Análisis genómico y farmacogenómica\nAlgoritmos de ML analizan el perfil genómico del paciente para predecir predisposición a enfermedades y la respuesta a determinados fármacos, seleccionando el tratamiento óptimo para cada individuo.\n\n### 3. Extracción de información con NLP\nModelos de PLN extraen información de notas clínicas no estructuradas e informes de laboratorio, identificando patrones de síntomas que correlacionan con diagnósticos específicos a escala imposible de analizar manualmente.\n\n### 4. Predicción de riesgo y medicina preventiva\nModelos predictivos calculan la probabilidad de desarrollar enfermedades o sufrir complicaciones (sepsis, reingreso), permitiendo intervenciones preventivas antes de que el problema sea clínicamente evidente.\n\n### 5. Sistemas de apoyo a la decisión clínica (CDSS)\nIntegran guías clínicas, literatura científica y el perfil del paciente para recomendar opciones diagnósticas al médico, quien mantiene la decisión final.\n\n### Consideraciones éticas\n- **Explicabilidad**: El médico debe entender por qué la IA hace una recomendación.\n- **Privacidad**: Los datos sanitarios son categoría especial bajo el RGPD.\n- **Responsabilidad**: Claridad sobre quién responde ante un diagnóstico asistido erróneo.",
      "keywords": [
        "medicina de precisión",
        "CNN",
        "genómica",
        "farmacogenómica",
        "NLP",
        "CDSS",
        "EHR"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:d35bc4e0b79dadf261028e10ccf0f218ed68ee28d2571f44d6bba1959e1b265a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "f7c64ab1-d5e7-4021-9481-79221fc81ec1",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Un científico de datos está trabajando en la evaluación de varios modelos de clasificación binaria para una tarea empresarial crítica. La empresa valora más la identificación correcta de casos positivos que la identificación de casos negativos, y se establece que un resultado falso positivo es 8 veces más costoso que un resultado falso negativo. Enumere dos métricas de evaluación de modelos que podrían ser relevantes, teniendo en cuenta que la tasa de falsos positivos debe ser máximo del 8 % y la proporción de casos positivos reales identificados por el algoritmo debe ser superior al 80%.",
      "explanation": "✅ A. Sensibilidad y tasa de falsos positivos.\n\nPor qué las otras no:\n\nB: “tasa de verdaderos positivos” es sensibilidad; aquí te exigen además controlar explícitamente la tasa de falsos positivos (≤ 8%).\n\nC: exactitud no es clave con costes asimétricos y restricciones sobre TPR/FPR.\n\nD: especificidad = 1−FPR, pero no incluye la condición de TPR (sensibilidad) ≥ 80%.",
      "difficulty": 3,
      "options": [
        {
          "id": "6e16bd8f-abb0-436a-a1c3-c3406d3ba95f",
          "text": "Sensibilidad y tasa de falsos positivos."
        },
        {
          "id": "43b7c847-07e8-4bbd-80da-96c92f6781fe",
          "text": "Especificidad y tasa de verdaderos positivos."
        },
        {
          "id": "2096db5d-62dd-4203-a7cb-4dea6d849776",
          "text": "Exactitud y tasa de falsos positivos."
        },
        {
          "id": "8c11f259-49d9-4a0d-bdc6-e3f127e70922",
          "text": "Especificidad y tasa de falsos positivos."
        }
      ],
      "correctOptionIds": [
        "6e16bd8f-abb0-436a-a1c3-c3406d3ba95f"
      ],
      "createdBy": "",
      "sourcePackId": "778c30fd-9df1-4385-9961-39a237b103e9",
      "contentHash": "sha256:e05257cee8b676e37f2cec45a613cb3d20aad994be37fed628ba0aa0614a1238",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "f7ebc0c0-4dfe-43d1-aaa4-fe7ba2aea58d",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "¿Cuál de las siguientes afirmaciones sobre el parámetro de regularización **$C$** en SVM es **falsa**?",
      "explanation": "Aumentar $C$ puede mejorar el ajuste en entrenamiento pero también incrementar el sobreajuste y empeorar la generalización; no garantiza mejora en datos no vistos.",
      "difficulty": 2,
      "tags": [
        "svm",
        "C",
        "regularizacion",
        "generalizacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "El parámetro de regularización $C$ en SVM controla el equilibrio entre maximizar el margen y minimizar el error de clasificación en los datos de entrenamiento."
        },
        {
          "id": "b",
          "text": "Un valor más pequeño de $C$ conduce a un margen más amplio, pero puede dar lugar a más errores de entrenamiento permitidos por el modelo."
        },
        {
          "id": "c",
          "text": "Un valor mayor de $C$ da como resultado un margen más estrecho, pero reduce la cantidad de errores de entrenamiento tolerados por el modelo, lo que podría provocar un sobreajuste de los datos de entrenamiento."
        },
        {
          "id": "d",
          "text": "Aumentar el valor de $C$ en SVM siempre mejora el rendimiento del modelo en datos no vistos."
        }
      ],
      "correctOptionIds": [
        "d"
      ],
      "contentHash": "sha256:0f8a5e5f0c6fdb3c4c7d14a1e0f7e8f5a9b6a8c9f0d1e2c3b4a5d6e7f8c9b0a1",
      "createdBy": "Luis",
      "sourcePackId": "f7a50bfe-3e7d-490a-8e9c-83ba7b00b08a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T14:24:21.019Z",
      "updatedAt": "2026-02-21T14:24:21.019Z"
    },
    {
      "id": "f90f20a1-d0ef-4673-b71e-fdd7955fa784",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "d2ab0f5c-fef4-4458-ad2e-209fd21cf452",
      "type": "TEST",
      "prompt": "El kernel lineal es la única opción eficaz en SVM para manejar conjuntos de datos no linealmente separables.",
      "explanation": "✅ **A.** **Falso**: SVM puede usar **kernels no lineales** (polinómico, RBF, etc.) para manejar datos no linealmente separables.\n\nPor qué no las otras:\n- **B/D:** afirman *verdadero* para un caso donde el kernel lineal no tiene por qué funcionar.\n- **C:** mezcla conceptos: el kernel lineal **no** introduce una transformación no lineal; es el caso más simple.",
      "difficulty": 2,
      "options": [
        {
          "id": "6e7e941d-66fd-47c9-89aa-3511fa948173",
          "text": "Falso. SVM con kernels no lineales, como el polinómico o el radial, son opciones efectivas para manejar conjuntos de datos no linealmente separables."
        },
        {
          "id": "133c2185-3187-4f8c-9231-cfa9f7e882c2",
          "text": "Verdadero. Las funciones de kernel lineal en SVM, a pesar de su aparente simplicidad, demuestran ser eficaces en escenarios donde la relación entre las características no es lineal."
        },
        {
          "id": "f1fe06ce-2890-4135-ab1f-c0e3c326612b",
          "text": "Falso. El kernel lineal realiza una transformación en los datos de entrada para trabajar con datos complejos y con relaciones no lineales."
        },
        {
          "id": "c274223c-979c-4f15-ad28-e101068bc8f1",
          "text": "Verdadero. Las funciones de kernel lineal en Máquinas de Soporte Vectorial (SVM) ofrecen simplicidad y eficiencia computacional al proporcionar una solución elegante para conjuntos de datos no linealmente separables."
        }
      ],
      "correctOptionIds": [
        "6e7e941d-66fd-47c9-89aa-3511fa948173"
      ],
      "createdBy": "",
      "sourcePackId": "aa1821f9-18ef-4a2c-aabc-27494a5f97b1",
      "contentHash": "sha256:9ee76d82b91c224c2f8f74d0203442f51723d3e7fb60d7783e94571c9d86b80a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "f9154f52-15b4-4be6-99b5-7c51d5039edd",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "PRACTICO",
      "prompt": "Supongamos que hemos utilizado un clasificador (p. ej. **SVM**) para distinguir entre personas **enfermas** (`Enf`) y **no enfermas** (`No`).\n\nA partir de los siguientes resultados:\n\n| Transacción | Clase real | Clase predicha |\n|---|---|---|\n| Tran1 | Enf | Enf |\n| Tran2 | Enf | Enf |\n| Tran3 | No | No |\n| Tran4 | No | No |\n| Tran5 | Enf | No |\n| Tran6 | No | No |\n| Tran7 | No | No |\n| Tran8 | Enf | Enf |\n| Tran9 | Enf | No |\n| Tran10 | No | Enf |\n\n1. Calcula **precision**, **recall** y **F1** para **ambas clases**.  \n2. En base a los resultados, explica el comportamiento del clasificador y si serviría para detectar enfermedad.\n\n**Nota:** puedes usar las fórmulas estándar (TP/FP/TN/FN).",
      "explanation": "Se espera que el alumno compute métricas por clase y razone sobre el impacto de **FN** en tareas médicas (sensibilidad/recall suele ser prioritaria).",
      "difficulty": 3,
      "tags": [
        "evaluación",
        "matriz de confusión",
        "precision",
        "recall",
        "F1"
      ],
      "modelAnswer": "Primero construimos la matriz de confusión tomando **Enf** como clase positiva:\n\n- **TP (Enf→Enf)**: 3 (Tran1, Tran2, Tran8)\n- **FN (Enf→No)**: 2 (Tran5, Tran9)\n- **TN (No→No)**: 4 (Tran3, Tran4, Tran6, Tran7)\n- **FP (No→Enf)**: 1 (Tran10)\n\n## Métricas para la clase **Enf** (positiva = Enf)\n- **Precision** = TP / (TP+FP) = 3 / (3+1) = **0.75**\n- **Recall** = TP / (TP+FN) = 3 / (3+2) = **0.60**\n- **F1** = 2·P·R / (P+R) = 2·0.75·0.60 / (0.75+0.60) = **0.667**\n\n## Métricas para la clase **No** (positiva = No)\nSi tratamos **No** como clase positiva:\n- TP(No) = 4, FP(No) = 2, FN(No) = 1\n\n- **Precision(No)** = 4 / (4+2) = **0.667**\n- **Recall(No)** = 4 / (4+1) = **0.80**\n- **F1(No)** = 2·0.667·0.80 / (0.667+0.80) = **0.727**\n\n## Interpretación\n- El modelo es **mejor identificando `No`** (recall 0.80) que `Enf` (recall 0.60).\n- Para **detección de enfermedad**, el problema crítico son los **falsos negativos** (Enf clasificados como No): aquí hay **2/5** enfermos perdidos (40%).\n- En un contexto clínico suele preferirse **subir sensibilidad/recall de `Enf`**, aunque baje algo la precision, ajustando el **umbral**, usando **class weights**, **re-muestreo** (over/under-sampling) o eligiendo un modelo/ajuste que optimice recall/F1/ROC-AUC.",
      "keywords": [
        "matriz de confusión",
        "TP",
        "FP",
        "TN",
        "FN",
        "precision",
        "recall",
        "F1",
        "sensibilidad",
        "especificidad"
      ],
      "createdBy": "Luis",
      "sourcePackId": "c28801ab-40f1-46bb-938b-9d886992b1a0",
      "contentHash": "sha256:7e2a8d07d9b607991972f0eb213274edbadef60f7792de3b388368ba36d98f64",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "fa8ee4f1-35d8-4e87-8780-9275fa29d832",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f59e591e-9b7d-47ab-942c-d343fbf9517d",
      "type": "TEST",
      "prompt": "Dados dos clasificadores binarios, si se equivocan en las clases más probables de las mismas instancias, significa que:",
      "explanation": "Si ambos fallan en las **mismas instancias**, a nivel de **acierto/fallo** pueden parecer equivalentes, pero si evaluamos las **probabilidades** (p. ej., *log-loss*), un modelo **muy seguro y equivocado** se penaliza más que uno **incierto**. Por eso, ante el mismo error en etiqueta, **mayor incertidumbre** suele implicar **mejor** comportamiento probabilístico.",
      "difficulty": 3,
      "tags": [
        "tema-5",
        "clasificacion",
        "evaluacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "Son igual de buenos."
        },
        {
          "id": "b",
          "text": "Si uno tiene una mayor incertidumbre que el otro, es peor clasificador."
        },
        {
          "id": "c",
          "text": "Si uno tiene una mayor incertidumbre que el otro es mejor clasificador."
        },
        {
          "id": "d",
          "text": "Ninguna de las anteriores."
        }
      ],
      "correctOptionIds": [
        "c"
      ],
      "contentHash": "sha256:5429d71e7b3d0d67aa2cd9c2d2c88a22a0e51dc63f5f92e8512c2411b591dcf9",
      "createdBy": "Luis",
      "sourcePackId": "880351b1-8284-4ec1-92c3-a51fdc07a803",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T23:55:43.364Z",
      "updatedAt": "2026-02-20T23:55:43.364Z"
    },
    {
      "id": "fb5b1721-aeef-4682-8d9a-3031698543ae",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "8f5d239d-251a-4f0c-b03e-3d300f5cd4b5",
      "type": "TEST",
      "prompt": "Señala la afirmación válida sobre el método de cartesian grid search:",
      "explanation": "Se puede paralelizar. El método de búsqueda en cuadrícula (cartesian grid search) puede paralelizarse eficientemente, lo que significa que puede distribuirse entre múltiples recursos de computación para acelerar el proceso de búsqueda y encontrar la combinación óptima de hiperparámetros de manera más rápida.",
      "difficulty": 2,
      "tags": [
        "tema-11",
        "optimizacion-hiperparametros",
        "grid-search",
        "paralelizacion"
      ],
      "origin": "test",
      "options": [
        {
          "id": "a",
          "text": "No se puede paralelizar."
        },
        {
          "id": "b",
          "text": "Se puede paralelizar."
        },
        {
          "id": "c",
          "text": "Se puede calcular de forma distribuida."
        },
        {
          "id": "d",
          "text": "Requiere entrenamiento del modelo en múltiples secuencias."
        }
      ],
      "correctOptionIds": [
        "b"
      ],
      "contentHash": "sha256:9d2d8e5c1f4a7b3c2d1e0f9a8b7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b9c",
      "createdBy": "Luis",
      "sourcePackId": "ee9187e5-8176-43cc-9a96-3ad398bdbf82",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-21T15:53:49.934Z",
      "updatedAt": "2026-02-21T15:53:49.934Z"
    },
    {
      "id": "fd8070be-bab8-4145-b310-6fd090195ba9",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "119c1fc3-3c0a-40fb-89de-d8018d4cf018",
      "type": "TEST",
      "prompt": "Un científico de datos está desarrollando un modelo de clasificación utilizando Naïve Bayes para predecir si un correo electrónico es spam o no spam. Ha calculado la tabla de verosimilitud para dos palabras clave: \"oferta\" y \"urgente\". Los resultados se presentan a continuación: Basándose en esta información y haciendo uso de la fórmula de la probabilidad a posteriori: P(A|B)=P(A)·P(B|A)/P(B). Responda la siguiente pregunta: ¿Cuál es la probabilidad a posteriori de que un correo electrónico sea spam dado que contiene la palabra clave \"oferta\"?",
      "explanation": "✅ D. 0.8\n\nCálculo (Bayes):\n- P(spam)=20/100=0.2; P(no spam)=0.8\n- P(\"oferta\"|spam)=4/20=0.2; P(\"oferta\"|no spam)=1/80=0.0125\n- P(\"oferta\")=0.2·0.2 + 0.8·0.0125 = 0.05\n- P(spam|\"oferta\") = (0.2·0.2)/0.05 = 0.8",
      "difficulty": 3,
      "options": [
        {
          "id": "3a53be38-80ed-4e83-ab1a-77ff1fc87665",
          "text": "0.12"
        },
        {
          "id": "d310d3b1-67c5-473e-9ecf-a6b123eb9b43",
          "text": "3.63"
        },
        {
          "id": "a5802ae4-50b6-410c-a141-71dfd14fe7d3",
          "text": "4.65"
        },
        {
          "id": "11f9ae7f-3587-4633-bd57-0a54158c3cec",
          "text": "0.8"
        }
      ],
      "correctOptionIds": [
        "11f9ae7f-3587-4633-bd57-0a54158c3cec"
      ],
      "createdBy": "",
      "sourcePackId": "9a48d918-0ffe-4d28-9f78-0c2350dcfe9c",
      "contentHash": "sha256:535229561e85012a54de87a8781faeb413f7591764fc1e758bd41503796ae422",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "fdcd005e-bdfb-45d5-902f-34b5955b2c43",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "Señale la afirmación falsa sobre el aprendizaje automático:",
      "explanation": "✅ **A. Existe un solo algoritmo...** (falsa)\n\nNo hay un “algoritmo universal” que sirva para todo: el rendimiento depende del tipo de datos, ruido, dimensionalidad, sesgo-varianza, etc.\n\n**Las otras son correctas:**\n- **B**: ML es un subcampo de IA.\n- **C**: el aprendizaje profundo es parte de ML.\n- **D**: *machine learning* y *aprendizaje automático* son sinónimos.",
      "difficulty": 1,
      "options": [
        {
          "id": "c73770ac-46b4-45d5-a519-a9d27ff98845",
          "text": "Existe un solo algoritmo de aprendizaje automático que se puede adaptar a cualquier circunstancia."
        },
        {
          "id": "57dfff53-d4f7-4aab-8e3b-53da8fc95201",
          "text": "El aprendizaje automático es una de las áreas de la inteligencia artificial."
        },
        {
          "id": "ffebe8c2-bb83-4e67-aec7-1dcfbe28debd",
          "text": "El aprendizaje profundo es un área del aprendizaje automático."
        },
        {
          "id": "df23e115-155b-49be-9173-02479e47c080",
          "text": "Aprendizaje automático y machine learning hacen referencia a lo mismo."
        }
      ],
      "correctOptionIds": [
        "c73770ac-46b4-45d5-a519-a9d27ff98845"
      ],
      "createdBy": "",
      "sourcePackId": "contribution-2026-02-18-julio-modelosB-C-new-6f543832",
      "contentHash": "sha256:7c987d0bd864f80bcbb51d6edecf16b1e79820333964059246e28b752d80c33a",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "fdda792a-7aa3-47f3-9d73-ba6c69aca163",
      "subjectId": "befc803a-db6a-49f5-a451-941ee8738c59",
      "topicId": "f70bfda8-a13c-4b49-ac0b-c407bcf62f59",
      "type": "TEST",
      "prompt": "Un científico de datos está utilizando Máquinas de Vectores de Soporte (SVM) para un problema de clasificación binaria. Después de entrenar el modelo, observa que hay un pequeño margen de separación entre las clases y sospecha que el modelo podría beneficiarse de una transformación no lineal de las características. ¿Qué técnica sería más apropiada para introducir no linealidades en el espacio de características y mejorar la capacidad del SVM para clasificar datos más complejos?",
      "explanation": "Por qué las otras no:\n\nA: ajustar C cambia el compromiso margen/errores, pero no introduce no linealidad por sí mismo.\n\nC: “incrementar la dimensión” es el efecto típico del kernel (a menudo implícito), pero la técnica apropiada en SVM para no linealidades es usar kernel.\n\nD: reducir ruido puede ayudar, pero no es “la técnica” para meter no linealidad",
      "options": [
        {
          "id": "db2d627b-4137-4fc6-97ae-a10dcad7760f",
          "text": "Ajustar el parámetro de regularización (C)."
        },
        {
          "id": "77d48980-3161-483e-8f4a-1bafddaf2a3b",
          "text": "Utilizar la función de kernel"
        },
        {
          "id": "2eefc0ac-64a3-4f55-be3b-06f61eea5a59",
          "text": "Incrementar la dimensión del espacio de características"
        },
        {
          "id": "05b62e8a-3a62-47bc-9b9a-1ad6ba917197",
          "text": "Reducir el ruido en los datos de entrenamiento."
        }
      ],
      "correctOptionIds": [
        "77d48980-3161-483e-8f4a-1bafddaf2a3b"
      ],
      "createdBy": "",
      "contentHash": "sha256:621ef41d254fba0ce2569f07fadaa8136de7dc50359915a362d6e90896ad2651",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    },
    {
      "id": "fe26d8d7-1994-41d8-b2bf-959ded43d2cc",
      "subjectId": "56b8ad06-ccf5-4b02-8a3f-f504446f5aca",
      "topicId": "a1245be8-e251-419a-bcdc-c822fd0e4750",
      "type": "DESARROLLO",
      "prompt": "En el caso de realizar un experimento para ver si el lanzamiento de una nueva web mejora la experiencia de usuario online y facilita el proceso de compra digital, explica qué variables serían las dependientes, cuáles las independientes y qué variables podrían considerarse como intervinientes (contaminadoras).",
      "difficulty": 2,
      "tags": [
        "metodologia",
        "experimento"
      ],
      "modelAnswer": "## Variables del Experimento de la Nueva Web\n\n### Variables Dependientes (VD) — lo que se mide\n- **Tasa de conversión**: porcentaje de visitantes que completan una compra.\n- **Tiempo hasta completar la compra**: desde entrada hasta checkout finalizado.\n- **Satisfacción del usuario**: cuestionarios post-compra (escala Likert, NPS).\n- **Tasa de abandono del carrito**: usuarios que añaden pero no finalizan.\n\n### Variables Independientes (VI) — lo que se manipula\n- Diseño visual de la web (distribución, colores, tipografía).\n- Número de pasos hasta el carrito (simplificación del flujo).\n- Cantidad y calidad de las imágenes de producto.\n- Métodos de pago disponibles (Bizum, PayPal, criptomonedas).\n- Velocidad de carga de la página.\n\n### Variables Intervinientes / Contaminadoras — no controladas\n- **Dispositivo utilizado** (móvil, tablet, PC): la experiencia varía independientemente del diseño.\n- **Nivel de experiencia digital del usuario**: comportamiento atípico de usuarios menos habituados.\n- **Momento del día o día de la semana**: el tráfico y la intención de compra varían temporalmente.\n- **Ventanas emergentes de terceros**: interrumpen el proceso de compra.\n- **Velocidad de conexión del usuario**: afecta la percepción de rendimiento al margen del diseño.",
      "keywords": [
        "variable dependiente",
        "variable independiente",
        "interviniente",
        "contaminadora",
        "experimento",
        "UX",
        "tasa conversión"
      ],
      "createdBy": "Claude - Recopilatorio IGPIA 2020-2025",
      "sourcePackId": "35a01deb-e402-4a70-9b30-0381f94dd5cb",
      "contentHash": "sha256:f7781ff6e479e1fcbc9bef94a3b5863bbd5fdb06e5976f85a63f843367cfed74",
      "stats": {
        "seen": 0,
        "correct": 0,
        "wrong": 0
      },
      "createdAt": "2026-02-20T14:48:47.946Z",
      "updatedAt": "2026-02-20T14:48:47.946Z"
    }
  ],
  "pdfAnchors": []
}